    <!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <link rel="canonical" href="https://blog.csdn.net/java1314777/article/details/134432710"/>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="renderer" content="webkit"/>
    <meta name="force-rendering" content="webkit"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="report" content='{"pid": "blog", "spm":"1001.2101"}'>
    <meta name="referrer" content="always">
    <meta http-equiv="Cache-Control" content="no-siteapp" /><link rel="alternate" media="handheld" href="#" />
    <meta name="shenma-site-verification" content="5a59773ab8077d4a62bf469ab966a63b_1497598848">
    <meta name="applicable-device" content="pc">
    <link  href="https://g.csdnimg.cn/static/logo/favicon32.ico"  rel="shortcut icon" type="image/x-icon" />
    <title>YOLOv8改进 | 如何在网络结构中添加注意力机制、C2f、卷积、Neck、检测头_修改网络结构、添加注意力模块、修改损失函数、修改label assignment策略-CSDN博客</title>
    <script>
      (function(){ 
        var el = document.createElement("script"); 
        el.src = "https://s3a.pstatp.com/toutiao/push.js?1abfa13dfe74d72d41d83c86d240de427e7cac50c51ead53b2e79d40c7952a23ed7716d05b4a0f683a653eab3e214672511de2457e74e99286eb2c33f4428830"; 
        el.id = "ttzz"; 
        var s = document.getElementsByTagName("script")[0]; 
        s.parentNode.insertBefore(el, s);
      })(window)
    </script>
        <meta name="keywords" content="修改网络结构、添加注意力模块、修改损失函数、修改label assignment策略">
        <meta name="csdn-baidu-search"  content='{"autorun":true,"install":true,"keyword":"修改网络结构、添加注意力模块、修改损失函数、修改label assignment策略"}'>
    <meta name="description" content="文章浏览阅读8.2k次，点赞78次，收藏168次。本篇文章的内容是在大家得到一个改进版本的C2f一个新的注意力机制、或者一个新的卷积模块、或者是检测头的时候如何替换我们YOLOv8模型中的原有的模块，从而用你的模块去进行训练模型或者检测。因为最近开了一个专栏里面涉及到挺多改进的地方，不能每篇文章都去讲解一遍如何修改，就想着在这里单独出一期文章进行一个总结性教程大家可以从我的其它文章中拿到修改后的代码，从这篇文章学会如何去添加到你的模型结构中去。YOLOv8改进有效涨点专栏-&gt;持续复现各种最新机制本文的讲解举例都以最新的YOLOv8。_修改网络结构、添加注意力模块、修改损失函数、修改label assignment策略">
        <link rel="stylesheet" type="text/css" href="https://csdnimg.cn/release/blogv2/dist/pc/css/detail_enter-38ddee24dc.min.css">
    <style>
        #content_views{
            -webkit-touch-callout: none;
            -webkit-user-select: none;
            -khtml-user-select: none;
            -moz-user-select: none;
            -ms-user-select: none; 
            user-select: none; 
        }
    </style>
    <script type="application/ld+json">{"@context":"https://ziyuan.baidu.com/contexts/cambrian.jsonld","@id":"https://blog.csdn.net/java1314777/article/details/134432710","appid":"1638831770136827","pubDate":"2023-11-16T01:42:21","title":"YOLOv8改进 | 如何在网络结构中添加注意力机制、C2f、卷积、Neck、检测头_修改网络结构、添加注意力模块、修改损失函数、修改label assignment策略-CSDN博客","upDate":"2023-11-16T23:29:15"}</script>
        <link rel="stylesheet" type="text/css" href="https://csdnimg.cn/release/blogv2/dist/pc/themesSkin/skin-blackwhale/skin-blackwhale-fcd12bc8ae.min.css">
    <script src="https://csdnimg.cn/public/common/libs/jquery/jquery-1.9.1.min.js" type="text/javascript"></script>
    <script type="text/javascript">
        var isCorporate = false;//注释删除enterprise
        var username =  "java1314777";
        var skinImg = "white";
        var blog_address = "https://snu77.blog.csdn.net";
        var currentUserName = "DreamSun527";
        var isOwner = false;
        var loginUrl = "http://passport.csdn.net/account/login?from=https://blog.csdn.net/java1314777/article/details/134432710";
        var blogUrl = "https://blog.csdn.net/";
        var avatar = "https://profile-avatar.csdnimg.cn/27160f4941a54d07b535ceabcfa4a800_java1314777.jpg!1";
        var articleTitle = "YOLOv8改进 | 如何在网络结构中添加注意力机制、C2f、卷积、Neck、检测头";
        var articleDesc = "文章浏览阅读8.2k次，点赞78次，收藏168次。本篇文章的内容是在大家得到一个改进版本的C2f一个新的注意力机制、或者一个新的卷积模块、或者是检测头的时候如何替换我们YOLOv8模型中的原有的模块，从而用你的模块去进行训练模型或者检测。因为最近开了一个专栏里面涉及到挺多改进的地方，不能每篇文章都去讲解一遍如何修改，就想着在这里单独出一期文章进行一个总结性教程大家可以从我的其它文章中拿到修改后的代码，从这篇文章学会如何去添加到你的模型结构中去。YOLOv8改进有效涨点专栏-&gt;持续复现各种最新机制本文的讲解举例都以最新的YOLOv8。_修改网络结构、添加注意力模块、修改损失函数、修改label assignment策略";
        var articleTitles = "YOLOv8改进 | 如何在网络结构中添加注意力机制、C2f、卷积、Neck、检测头_修改网络结构、添加注意力模块、修改损失函数、修改label assignment策略-CSDN博客";
        var nickName = "Snu77";
        var articleDetailUrl = "https://snu77.blog.csdn.net/article/details/134432710";
        var vipUrlV = "https://mall.csdn.net/svip?utm_source=learningVIPX";
        if(window.location.host.split('.').length == 3) {
            blog_address = blogUrl + username;
        }
        var skinStatus = "Black";
        var robotModule = '';
        var robotModuleJs = '';
        var blogStaticHost = "https://csdnimg.cn/release/blogv2/"
        var mallTestStyle = "control"
    </script>
        <meta name="toolbar" content='{"type":"1","fixModel":"1"}'>
        <script>
            window.csdn = window.csdn ? window.csdn : {};
            window.csdn.toolbarIsBlack = true;
            window.csdn.sideToolbar = {
                options: {
                    theme : "black"
                }
            }
        </script>
    <script src="https://g.csdnimg.cn/??fixed-sidebar/1.1.7/fixed-sidebar.js" type="text/javascript"></script>
    <script src='//g.csdnimg.cn/common/csdn-report/report.js' type='text/javascript'></script>
    <link rel="stylesheet" type="text/css" href="https://csdnimg.cn/public/sandalstrap/1.4/css/sandalstrap.min.css">
    <style>
        .MathJax, .MathJax_Message, .MathJax_Preview{
            display: none
        }
    </style>
    <script src="https://dup.baidustatic.com/js/ds.js"></script>
</head>
  <body class="nodata is_black_skin " style="">
    <div id="toolbarBox" style="min-height: 48px;"></div>
        <script>
            var toolbarSearchExt = '{"landingWord":["修改网络结构、添加注意力模块、修改损失函数、修改label assignment策略"],"queryWord":"","tag":["YOLO","深度学习","机器学习","人工智能","pytorch","python","目标检测"],"title":"YOLOv8改进 | 如何在网络结构中添加注意力机制、C2f、卷积、Neck、检测头"}';
        </script>
    <script src="https://g.csdnimg.cn/common/csdn-toolbar/csdn-toolbar.js" type="text/javascript"></script>
    <script>
    (function(){
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
    </script>

    <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/pc/css/blog_code-01256533b5.min.css">
    <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/chart-3456820cac.css" />
    <link rel="stylesheet" href="https://g.csdnimg.cn/lib/swiper/6.0.4/css/swiper.css" />
    <script src="https://g.csdnimg.cn/lib/swiper/6.0.4/js/swiper.js" async></script>
    <script>
      var articleId = 134432710;
      var commentscount = 79;
      var commentAuth = 2;
      var curentUrl = "https://blog.csdn.net/java1314777/article/details/134432710";
      var myUrl = "https://my.csdn.net/";
        var highlight = ["pytorch","python","assign","注意力机制","label","损失函数","目标检测","机器学习","人工智能","yolo","深度学习","neck","ment","网络结构","c2f","注意力","策略","修改","v8","检测","添加","改进","卷积","模块","中","头"];//高亮数组
        var isRecommendModule = true;
          var isBaiduPre = true;
          var baiduCount = 2;
          var setBaiduJsCount = 10;
      var share_card_url = "https://app-blog.csdn.net/share?article_id=134432710&username=java1314777"
      var mallVipUrl = "https://mall.csdn.net/vip?vipSource=article"
      var vipArticleAbStyle = "t_2"
      var vipArticleCpStyle = "t_2"
      var articleType = 1;
      var baiduKey = "修改网络结构、添加注意力模块、修改损失函数、修改label assignment策略";
      var copyPopSwitch = true;
      var needInsertBaidu = true;
      var recommendRegularDomainArr = ["blog.csdn.net/.+/article/details/","download.csdn.net/download/","edu.csdn.net/course/detail/","ask.csdn.net/questions/","bbs.csdn.net/topics/","www.csdn.net/gather_.+/"]
      var codeStyle = "tomorrow-night";
      var baiduSearchType = "baidulandingword";
      var sharData = "{\"hot\":[{\"id\":1,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/a5f4260710904e538002a6ab337939b3.png\"},{\"id\":2,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/188b37199a2c4b74b1d9ffc39e0d52de.png\"},{\"id\":3,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/14ded358b631444581edd98a256bc5af.png\"},{\"id\":4,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/1470f23a770444d986ad551b9c33c5be.png\"},{\"id\":5,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/c329f5181dc74f6c9bd28c982bb9f91d.png\"},{\"id\":6,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/ccd8a3305e81460f9c505c95b432a65f.png\"},{\"id\":7,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/bc89d8283389440d97fc4d30e30f45e1.png\"},{\"id\":8,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/452d485b4a654f5592390550d2445edf.png\"},{\"id\":9,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/f8b9939db2ed474a8f43a643015fc8b7.png\"},{\"id\":10,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/6de8864187ab4ed3b1db0856369c36ff.png\"},{\"id\":11,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/673cc3470ff74072acba958dc0c46e2d.png\"},{\"id\":12,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/930c119760ac4491804db80f9c6d4e3f.png\"},{\"id\":13,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/15e6befb05a24233bc2b65e96aa8d972.png\"},{\"id\":14,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/2075fd6822184b95a41e214de4daec13.png\"},{\"id\":15,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/859b1552db244eb6891a809263a5c657.png\"},{\"id\":16,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/0be2f920f1f74290a98921974a9613fd.png\"},{\"id\":17,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/2e97e00b43f14afab494ea55ef3f4a6e.png\"},{\"id\":18,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/ff4ab252f46e444686f5135d6ebbfec0.png\"},{\"id\":19,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/ae029bbe99564e79911657912d36524f.png\"},{\"id\":20,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/b3ece39963de440388728e9e7b9bf427.png\"},{\"id\":21,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/6f14651a99ba486e926d63b6fa692997.png\"},{\"id\":22,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/83ceddf050084875a341e32dcceca721.png\"},{\"id\":23,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/b90368b8fd5d4c6c8c79a707d877cf7c.png\"},{\"id\":24,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/aeffae14ecf14e079b2616528c9a393b.png\"},{\"id\":25,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/c5a06b5a13d44d16bed868fc3384897a.png\"},{\"id\":26,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/08b697658b844b318cea3b119e9541ef.png\"},{\"id\":27,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/68ccb0b8d09346ac961d2b5c1a8c77bf.png\"},{\"id\":28,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/a2227a247e37418cbe0ea972ba6a859b.png\"},{\"id\":29,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/3a42825fede748f9993e5bb844ad350d.png\"},{\"id\":30,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/8882abc1dd484224b636966ea38555c3.png\"},{\"id\":31,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/4f6a5f636a3e444d83cf8cc06d87a159.png\"},{\"id\":32,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/1953ef79c56b4407b78d7181bdff11c3.png\"},{\"id\":33,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/c04a2a4f772948ed85b5b0380ed36287.png\"},{\"id\":34,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/5b4fecd05091405ea04d8c0f53e9f2c7.png\"},{\"id\":35,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/b89f576d700344e280d6ceb2a66c2420.png\"},{\"id\":36,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/1c65780e11804bbd9971ebadb3d78bcf.png\"},{\"id\":37,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/d590db2055f345db9706eb68a7ec151a.png\"},{\"id\":38,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/fe602f80700b4f6fb3c4a9e4c135510e.png\"},{\"id\":39,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/39ff2fcd31e04feba301a071976a0ba7.png\"},{\"id\":40,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/f9b61b3d113f436b828631837f89fb39.png\"},{\"id\":41,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/df1aca5f610c4ad48cd16da88c9c8499.png\"},{\"id\":42,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/d7acf73a1e6b41399a77a85040e10961.png\"},{\"id\":43,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/b7f1b63542524b97962ff649ab4e7e23.png\"}],\"vip\":[{\"id\":1,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101150.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101154.png\"},{\"id\":2,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101204.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101208.png\"},{\"id\":3,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101211.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101215.png\"},{\"id\":4,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101218.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101220.png\"},{\"id\":5,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101223.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101226.png\"},{\"id\":6,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220922100635.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220922100639.png\"},{\"id\":7,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220922100642.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220922100644.png\"},{\"id\":8,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220922100647.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220922100649.png\"},{\"id\":9,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220922100652.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220922100655.png\"},{\"id\":10,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/55de67481fde4b04b97ad78f11fe369a.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/bb2418fb537e4d78b10d8765ccd810c5.png\"},{\"id\":11,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/579c713394584d128104ef1044023954.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/f420d9fbcf5548079d31b5e809b6d6cd.png\"},{\"id\":12,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/75b7f3155ba642f5a4cc16b7baf44122.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/a9030f5877be401f8b340b80b0d91e64.png\"},{\"id\":13,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/0903d33cafa54934be3780aa54ae958d.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/2cd8c8929f5a42fca5da2a0aeb456203.png\"},{\"id\":14,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/949fd7c22884439fbfc3c0e9c3b8dee7.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/dafbea9bd9eb4f3b962b48dc41657f89.png\"},{\"id\":15,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/4119cfddd71d4e6a8a27a18dbb74d90e.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/c56310c8b6384d9e85388e4e342ce508.png\"},{\"id\":16,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/121575274da142bcbbbbc2e8243dd411.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/5013993de06542f881018bb9abe2edf7.png\"},{\"id\":17,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/4d97aa6dd4fe4f09a6bef5bdf8a6abcd.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/76f23877b6ad4066ad45ce8e31b4b977.png\"},{\"id\":18,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/fdb619daf21b4c829de63b9ebc78859d.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/a1abe5d27a5441f599adfe662f510243.png\"},{\"id\":19,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/676b7707bb11410f8f56bc0ed2b2345c.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/7ac5b467fbf24e1d8c2de3f3332c4f54.png\"},{\"id\":20,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/0becb8cc227e4723b765bdd69a20fd4a.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/fdec85b26091486b9a89d0b8d45c3749.png\"},{\"id\":21,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/1a6c06235ad44941b38c54cbc25a370c.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/410a06cda2d44b0c84578f88275caf70.png\"}],\"map\":{\"hot\":\"热门\",\"vip\":\"VIP\"}}";
      
      var canRead = true;
      var blogMoveHomeArticle = false;
      var showSearchText = "";
      var articleSource = 1;
      var articleReport = '{"pid": "blog", "spm":"1001.2101"}';
        var baiduSearchChannel = 'pc_relevant'
        var baiduSearchIdentification = '.235^v43^pc_blog_bottom_relevance_base5'
        var distRequestId = '1709121948981_66381'
        var initRewardObject = {
          giver: "DreamSun527",
          anchor: "java1314777",
          articleId: "134432710",
          sign: "2a4ff693732b7ad6f7db0ffca43495d6",
        }
        var isLikeStatus = false;
        var isUnLikeStatus = false;
        var studyLearnWord = "";
        var unUseCount = 0;
        var codeMaxSize = 0;
        var overCost = true;
        var isCurrentUserVip = false;
        var contentViewsHeight = 0;
        var contentViewsCount = 0;
        var contentViewsCountLimit = 5;
        var isShowConcision = true
      var isCookieConcision = false
      var isHasDirectoryModel = false
      var isShowSideModel = false
      var isShowDirectoryModel = true
      function getCookieConcision(sName){
        var allCookie = document.cookie.split("; ");
        for (var i=0; i < allCookie.length; i++){
          var aCrumb = allCookie[i].split("=");
          if (sName == aCrumb[0])
            return aCrumb[1];
        }
        return null;
      }
      if (getCookieConcision('blog_details_concision') && getCookieConcision('blog_details_concision') == 0){
        isCookieConcision = true
        isShowSideModel = true
        isShowDirectoryModel = false
      }
    </script>
        <div class="main_father clearfix d-flex justify-content-center mainfather-concision" style="height:100%;">
          <div class="container clearfix container-concision" id="mainBox">
          <script>
          if (!isCookieConcision) {
            $('.main_father').removeClass('mainfather-concision')
            $('.main_father .container').removeClass('container-concision')
          } else {
            $('#mainBox').css('margin-right', '0')
          }
          </script>
          <main>
<script type="text/javascript">
    var resourceId =  "";
    function getQueryString(name) {   
      var reg = new RegExp("(^|&)" + name + "=([^&]*)(&|$)"); //构造一个含有目标参数的正则表达式对象  
      var r = window.location.search.substr(1).match(reg);  //匹配目标参数
      if( r != null ) return decodeURIComponent( r[2] ); return '';   
    }
    function stripscript(s){ 
      var pattern = new RegExp("[`~!@#$^&*()=|{}':;',\\[\\].<>/?~！@#￥……&*（）——|{}【】‘；：”“'。，、？%]") 
      var rs = ""; 
      for (var i = 0; i < s.length; i++) { 
        rs = rs+s.substr(i, 1).replace(pattern, ''); 
      } 
      return rs;
    }
    var blogHotWords = stripscript(getQueryString('utm_term')).length > 1 ? stripscript(getQueryString('utm_term')) : ''
</script>
<div class="blog-content-box">
    <div class="article-header-box">
        <div class="article-header">
            <div class="article-title-box">
                <h1 class="title-article" id="articleContentId">YOLOv8改进 | 如何在网络结构中添加注意力机制、C2f、卷积、Neck、检测头</h1>
            </div>
            <div class="article-info-box">
                <div class="article-bar-top">
                    <img class="article-type-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/original.png" alt="">
                    <div class="bar-content">
                      <a class="follow-nickName vip-name" href="https://snu77.blog.csdn.net" target="_blank" rel="noopener" title="Snu77">Snu77</a>
                    <img class="article-time-img article-heard-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newUpTime2.png" alt="">
                    <span class="time">已于&nbsp;2024-02-13 23:12:22&nbsp;修改</span>
                   <div class="read-count-box">
                      <img class="article-read-img article-heard-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/articleReadEyes2.png" alt="">
                      <span class="read-count">阅读量8.2k</span>
                      <a id="blog_detail_zk_collection" class="un-collection" data-report-click='{"mod":"popu_823","spm":"1001.2101.3001.4232","ab":"new"}'>
                          <img class="article-collect-img article-heard-img un-collect-status isdefault" style="display:inline-block" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarCollect2.png" alt="">
                          <img class="article-collect-img article-heard-img collect-status isactive" style="display:none" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarCollectionActive2.png" alt="">
                          <span class="name">收藏</span>
                          <span class="get-collection">
                              168
                          </span>
                      </a>
                      <div class="read-count-box is-like">
                        <img class="article-read-img article-heard-img" style="display:none" id="is-like-imgactive-new" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newHeart2023Active.png" alt="">
                        <img class="article-read-img article-heard-img" style="display:block" id="is-like-img-new" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newHeart2023Black.png" alt="">
                        <span class="read-count" id="blog-digg-num">点赞数
                            78
                        </span>
                      </div>
                    </div>
                  </div>
                </div>
                <div class="blog-tags-box">
                    <div class="tags-box artic-tag-box">
                            <span class="label">分类专栏：</span>
                                <a class="tag-link" href="https://blog.csdn.net/java1314777/category_12483754.html" target="_blank" rel="noopener">YOLOv8有效涨点专栏</a>
                            <span class="label">文章标签：</span>
                                <a rel="nofollow" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"YOLO","ab":"new","extra":"{\"searchword\":\"YOLO\"}"}' class="tag-link" href="https://so.csdn.net/so/search/s.do?q=YOLO&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank" rel="noopener">YOLO</a>
                                <a rel="nofollow" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"深度学习","ab":"new","extra":"{\"searchword\":\"深度学习\"}"}' class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank" rel="noopener">深度学习</a>
                                <a rel="nofollow" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"机器学习","ab":"new","extra":"{\"searchword\":\"机器学习\"}"}' class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank" rel="noopener">机器学习</a>
                                <a rel="nofollow" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"人工智能","ab":"new","extra":"{\"searchword\":\"人工智能\"}"}' class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank" rel="noopener">人工智能</a>
                                <a rel="nofollow" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"pytorch","ab":"new","extra":"{\"searchword\":\"pytorch\"}"}' class="tag-link" href="https://so.csdn.net/so/search/s.do?q=pytorch&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank" rel="noopener">pytorch</a>
                                <a rel="nofollow" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"python","ab":"new","extra":"{\"searchword\":\"python\"}"}' class="tag-link" href="https://so.csdn.net/so/search/s.do?q=python&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank" rel="noopener">python</a>
                                <a rel="nofollow" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"目标检测","ab":"new","extra":"{\"searchword\":\"目标检测\"}"}' class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank" rel="noopener">目标检测</a>
                    </div>
                </div>
                <div class="up-time"><span>于&nbsp;2023-11-16 23:29:15&nbsp;首次发布</span></div>
                <div class="slide-content-box">
                    <div class="article-copyright">
                        <div class="creativecommons">
                            版权声明：本文为博主原创文章，遵循<a href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="noopener"> CC 4.0 BY-SA </a>版权协议，转载请附上原文出处链接和本声明。
                        </div>
                        <div class="article-source-link">
                            本文链接：<a href="https://blog.csdn.net/java1314777/article/details/134432710" target="_blank">https://blog.csdn.net/java1314777/article/details/134432710</a>
                        </div>
                    </div>
                </div>
                
                <div class="operating">
                    <a class="href-article-edit slide-toggle">版权</a>
                </div>
            </div>
        </div>
    </div>
    <div id="blogHuaweiyunAdvert"></div>
        <div id="blogColumnPayAdvert">
            <div class="column-group">
                <div class="column-group-item column-group0 column-group-item-one">
                    <div class="item-l">
                        <a class="item-target" href="https://blog.csdn.net/java1314777/category_12483754.html" target="_blank" title="YOLOv8有效涨点专栏"
                        data-report-view='{"spm":"1001.2101.3001.6332"}'
                        data-report-click='{"spm":"1001.2101.3001.6332"}'>
                            <img class="item-target" src="https://img-blog.csdnimg.cn/direct/d0d498bd4f0c4e17b48ff54e86b67668.png?x-oss-process=image/resize,m_fixed,h_224,w_224" alt="">
                            <span class="title item-target">
                                <span>
                                <span class="tit">YOLOv8有效涨点专栏</span>
                                    <span class="dec">专栏收录该内容</span>
                                </span>
                                <span class="rank"><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/columnHotIcon2.png" alt="">该专栏为热销专栏榜&nbsp;第1名</span>
                            </span>
                        </a>
                    </div>
                    <div class="item-m">
                        <span>125 篇文章</span>
                        <span>341 订阅</span>
                        <span class="old-add-new-box">
                            <span class="price price-style">¥199.90</span>
                            <span class="oldprice price-style">¥99.00</span>
                        </span>
                    </div>
                    <div class="item-r">
                                <a class="item-target article-column-subscribe">已订阅</a>
                    </div>
                </div>
            </div>
        </div>
    <article class="baidu_pl">
        <div id="article_content" class="article_content clearfix">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/kdoc_html_views-1a98987dfd.css">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-044f2cf1dc.css">
                <div id="content_views" class="htmledit_views">
                    <h2 id="%E4%B8%80%E3%80%81%E6%9C%AC%E6%96%87%E4%BB%8B%E7%BB%8D">一、本文介绍</h2> 
<p>本篇文章的内容是在大家得到一个<span style="color:#ff9900;">改进版本的</span>C2f一个新的注意力机制、或者一个新的卷积模块、或者是检测头的时候如何替换我们YOLOv8模型中的原有的模块&#xff0c;从而用你的模块去进行训练模型或者检测。因为最近开了一个专栏里面涉及到挺多改进的地方&#xff0c;不能每篇文章都去讲解一遍如何修改&#xff0c;就想着在这里单独出一期文章进行一个<span style="color:#ff9900;">总结性教程</span>&#xff0c;<span style="color:#ed7976;">大家可以从我的其它文章中拿到修改后的代码&#xff0c;从这篇文章学会如何去添加到你的模型结构中去。</span></p> 
<p><span style="color:#fe2c24;"><strong>本文目前的改进教程包括&#xff1a;</strong></span><span style="color:#ff9900;"><strong>注意力机制、C2f(改进后的)、卷积(主干上的)、Neck、检测头、损失函数。</strong></span></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81%E6%9C%AC%E6%96%87%E4%BB%8B%E7%BB%8D-toc" style="margin-left:0px;"><strong><a href="#%E4%B8%80%E3%80%81%E6%9C%AC%E6%96%87%E4%BB%8B%E7%BB%8D" rel="nofollow">一、本文介绍</a></strong></p> 
<p id="%E4%BA%8C%E3%80%81%E5%AF%BC%E5%85%A5%E4%BF%AE%E6%94%B9%E5%86%85%E5%AE%B9-toc" style="margin-left:0px;"><strong><a href="#%E4%BA%8C%E3%80%81%E5%AF%BC%E5%85%A5%E4%BF%AE%E6%94%B9%E5%86%85%E5%AE%B9" rel="nofollow">二、导入修改内容</a></strong></p> 
<p id="2.1%E5%88%9B%E5%BB%BA%E6%96%B0%E6%96%87%E4%BB%B6%E5%AF%BC%E5%85%A5%E6%96%B0%E6%A8%A1%E5%9D%97-toc" style="margin-left:40px;"><strong><a href="#2.1%E5%88%9B%E5%BB%BA%E6%96%B0%E6%96%87%E4%BB%B6%E5%AF%BC%E5%85%A5%E6%96%B0%E6%A8%A1%E5%9D%97" rel="nofollow">2.1创建新文件导入新模块</a></strong></p> 
<p id="2.1.1%E6%83%85%E5%86%B5%E4%B8%80-toc" style="margin-left:80px;"><strong><a href="#2.1.1%E6%83%85%E5%86%B5%E4%B8%80" rel="nofollow">2.1.1情况一</a></strong></p> 
<p id="2.1.2%E6%83%85%E5%86%B5%E4%BA%8C%C2%A0-toc" style="margin-left:80px;"><strong><a href="#2.1.2%E6%83%85%E5%86%B5%E4%BA%8C%C2%A0" rel="nofollow">2.1.2情况二 </a></strong></p> 
<p id="%E4%B8%89%E3%80%81Conv%E6%A8%A1%E5%9D%97-toc" style="margin-left:0px;"><strong><a href="#%E4%B8%89%E3%80%81Conv%E6%A8%A1%E5%9D%97" rel="nofollow">三、Conv模块</a></strong></p> 
<p id="3.1%E4%BF%AE%E6%94%B9%E4%B8%80-toc" style="margin-left:40px;"><strong><a href="#3.1%E4%BF%AE%E6%94%B9%E4%B8%80" rel="nofollow">3.1修改一</a></strong></p> 
<p id="3.2%E4%BF%AE%E6%94%B9%E4%BA%8C-toc" style="margin-left:40px;"><strong><a href="#3.2%E4%BF%AE%E6%94%B9%E4%BA%8C" rel="nofollow">3.2修改二</a></strong></p> 
<p id="3.3%E4%BF%AE%E6%94%B9%E4%B8%89%C2%A0-toc" style="margin-left:40px;"><strong><a href="#3.3%E4%BF%AE%E6%94%B9%E4%B8%89%C2%A0" rel="nofollow">3.3修改三 </a></strong></p> 
<p id="%E5%9B%9B%E3%80%81C2f%E3%80%81Bottleneck%E6%A8%A1%E5%9D%97-toc" style="margin-left:0px;"><strong><a href="#%E5%9B%9B%E3%80%81C2f%E3%80%81Bottleneck%E6%A8%A1%E5%9D%97" rel="nofollow">四、C2f、Bottleneck模块</a></strong></p> 
<p id="4.1%E4%BF%AE%E6%94%B9%E4%B8%80-toc" style="margin-left:40px;"><strong><a href="#4.1%E4%BF%AE%E6%94%B9%E4%B8%80" rel="nofollow">4.1修改一</a></strong></p> 
<p id="4.2%E6%AD%A5%E9%AA%A4%E4%BA%8C%C2%A0-toc" style="margin-left:40px;"><strong><a href="#4.2%E6%AD%A5%E9%AA%A4%E4%BA%8C%C2%A0" rel="nofollow">4.2步骤二 </a></strong></p> 
<p id="4.3%E4%BF%AE%E6%94%B9%E4%B8%89-toc" style="margin-left:40px;"><strong><a href="#4.3%E4%BF%AE%E6%94%B9%E4%B8%89" rel="nofollow">4.3修改三</a></strong></p> 
<p id="4.4%E4%BF%AE%E6%94%B9%E5%9B%9B-toc" style="margin-left:40px;"><strong><a href="#4.4%E4%BF%AE%E6%94%B9%E5%9B%9B" rel="nofollow">4.4修改四</a></strong></p> 
<p id="4.5%E4%BF%AE%E6%94%B9%E4%BA%94-toc" style="margin-left:40px;"><strong><a href="#4.5%E4%BF%AE%E6%94%B9%E4%BA%94" rel="nofollow">4.5修改五</a></strong></p> 
<p id="4.6%E4%BF%AE%E6%94%B9%E5%85%AD-toc" style="margin-left:40px;"><strong><a href="#4.6%E4%BF%AE%E6%94%B9%E5%85%AD" rel="nofollow">4.6修改六</a></strong></p> 
<p id="4.7%E4%BF%AE%E6%94%B9%E4%B8%83-toc" style="margin-left:40px;"><strong><a href="#4.7%E4%BF%AE%E6%94%B9%E4%B8%83" rel="nofollow">4.7修改七</a></strong></p> 
<p id="%E5%9B%9B%E3%80%81%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-toc" style="margin-left:0px;"><strong><a href="#%E5%9B%9B%E3%80%81%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6" rel="nofollow">五、注意力机制(上采样修改方法同此处有参数注意力机制)</a></strong></p> 
<p id="4.1%E4%BF%AE%E6%94%B9%E4%B8%80%C2%A0-toc" style="margin-left:40px;"><strong><a href="#4.1%E4%BF%AE%E6%94%B9%E4%B8%80%C2%A0" rel="nofollow">5.1修改一 </a></strong></p> 
<p id="4.2%E4%BF%AE%E6%94%B9%E4%BA%8C-toc" style="margin-left:40px;"><strong><a href="#4.2%E4%BF%AE%E6%94%B9%E4%BA%8C" rel="nofollow">5.2修改二</a></strong></p> 
<p id="5.3%E4%BF%AE%E6%94%B9%E4%B8%89-toc" style="margin-left:40px;"><strong><a href="#5.3%E4%BF%AE%E6%94%B9%E4%B8%89" rel="nofollow">5.3修改三</a></strong></p> 
<p id="4.2.1%E6%9C%89%E5%8F%82%E6%95%B0%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BF%AE%E6%94%B9-toc" style="margin-left:80px;"><strong><a href="#4.2.1%E6%9C%89%E5%8F%82%E6%95%B0%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BF%AE%E6%94%B9" rel="nofollow">5.2.1有参数的注意力机制修改</a></strong></p> 
<p id="4.2.2%E6%97%A0%E5%8F%82%E6%95%B0%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BF%AE%E6%94%B9-toc" style="margin-left:80px;"><strong><a href="#4.2.2%E6%97%A0%E5%8F%82%E6%95%B0%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BF%AE%E6%94%B9" rel="nofollow">5.2.2无参数的注意力机制修改</a></strong></p> 
<p id="4.4%E9%85%8D%E7%BD%AE%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-toc" style="margin-left:40px;"><strong><a href="#4.4%E9%85%8D%E7%BD%AE%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6" rel="nofollow">5.4配置注意力机制</a></strong></p> 
<p id="%E4%BA%94%E3%80%81Neck%E9%83%A8%E5%88%86-toc" style="margin-left:0px;"><strong><a href="#%E4%BA%94%E3%80%81Neck%E9%83%A8%E5%88%86" rel="nofollow">六、Neck部分</a></strong></p> 
<p id="%E5%85%AD%E3%80%81%E6%A3%80%E6%B5%8B%E5%A4%B4-toc" style="margin-left:0px;"><strong><a href="#%E5%85%AD%E3%80%81%E6%A3%80%E6%B5%8B%E5%A4%B4" rel="nofollow">七、检测头</a></strong></p> 
<p id="6.1%20%E4%BF%AE%E6%94%B9%E4%B8%80-toc" style="margin-left:40px;"><strong><a href="#6.1%20%E4%BF%AE%E6%94%B9%E4%B8%80" rel="nofollow">7.1 修改一</a></strong></p> 
<p id="6.2%20%E4%BF%AE%E6%94%B9%E4%BA%8C-toc" style="margin-left:40px;"><strong><a href="#6.2%20%E4%BF%AE%E6%94%B9%E4%BA%8C" rel="nofollow">7.2 修改二</a></strong></p> 
<p id="6.3%20%E4%BF%AE%E6%94%B9%E4%B8%89%C2%A0-toc" style="margin-left:40px;"><strong><a href="#6.3%20%E4%BF%AE%E6%94%B9%E4%B8%89%C2%A0" rel="nofollow">7.3 修改三 </a></strong></p> 
<p id="6.4%20%E4%BF%AE%E6%94%B9%E5%9B%9B%C2%A0-toc" style="margin-left:40px;"><strong><a href="#6.4%20%E4%BF%AE%E6%94%B9%E5%9B%9B%C2%A0" rel="nofollow">7.4 修改四 </a></strong></p> 
<p id="6.5%20%E4%BF%AE%E6%94%B9%E4%BA%94%C2%A0-toc" style="margin-left:40px;"><strong><a href="#6.5%20%E4%BF%AE%E6%94%B9%E4%BA%94%C2%A0" rel="nofollow">7.5 修改五 </a></strong></p> 
<p id="6.6%20%E4%BF%AE%E6%94%B9%E5%85%AD%C2%A0-toc" style="margin-left:40px;"><strong><a href="#6.6%20%E4%BF%AE%E6%94%B9%E5%85%AD%C2%A0" rel="nofollow">7.6 修改六 </a></strong></p> 
<p id="%E2%80%8B%E7%BC%96%E8%BE%91-toc" style="margin-left:40px;"><strong><a href="#%E2%80%8B%E7%BC%96%E8%BE%91" rel="nofollow">​编辑</a></strong></p> 
<p id="6.7%20%E4%BF%AE%E6%94%B9%E4%B8%83%C2%A0-toc" style="margin-left:40px;"><strong><a href="#6.7%20%E4%BF%AE%E6%94%B9%E4%B8%83%C2%A0" rel="nofollow">7.7 修改七 </a></strong></p> 
<p id="6.8%20%E4%BF%AE%E6%94%B9%E5%85%AB-toc" style="margin-left:40px;"><strong><a href="#6.8%20%E4%BF%AE%E6%94%B9%E5%85%AB" rel="nofollow">7.8 修改八</a></strong></p> 
<p id="6.9%20%E4%BF%AE%E6%94%B9%E4%B9%9D%C2%A0-toc" style="margin-left:40px;"><strong><a href="#6.9%20%E4%BF%AE%E6%94%B9%E4%B9%9D%C2%A0" rel="nofollow">7.9 修改九 </a></strong></p> 
<p id="6.10%20%E4%BF%AE%E6%94%B9%E5%8D%81%C2%A0-toc" style="margin-left:40px;"><strong><a href="#6.10%20%E4%BF%AE%E6%94%B9%E5%8D%81%C2%A0" rel="nofollow">7.10 修改十 </a></strong></p> 
<p id="%E4%B8%83%E3%80%81%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-toc" style="margin-left:0px;"><strong><a href="#%E4%B8%83%E3%80%81%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0" rel="nofollow">八、损失函数</a></strong></p> 
<p id="7.1%20%E4%BF%AE%E6%94%B9%E4%B8%80-toc" style="margin-left:40px;"><strong><a href="#7.1%20%E4%BF%AE%E6%94%B9%E4%B8%80" rel="nofollow">8.1 修改一</a></strong></p> 
<p id="7.2%20%E4%BF%AE%E6%94%B9%E4%BA%8C-toc" style="margin-left:40px;"><strong><a href="#7.2%20%E4%BF%AE%E6%94%B9%E4%BA%8C" rel="nofollow">8.2 修改二</a></strong></p> 
<p id="7.3%20%E4%BF%AE%E6%94%B9%E4%B8%89-toc" style="margin-left:40px;"><strong><a href="#7.3%20%E4%BF%AE%E6%94%B9%E4%B8%89" rel="nofollow">8.3 修改三</a></strong></p> 
<p id="%E5%85%AB%E3%80%81Backbone(%E4%B8%BB%E5%B9%B2)-toc" style="margin-left:0px;"><strong><a href="#%E5%85%AB%E3%80%81Backbone%28%E4%B8%BB%E5%B9%B2%29" rel="nofollow">九、Backbone(主干)</a></strong></p> 
<p id="%E4%BF%AE%E6%94%B9%E4%B8%80-toc" style="margin-left:40px;"><strong><a href="#%E4%BF%AE%E6%94%B9%E4%B8%80" rel="nofollow">修改一</a></strong></p> 
<p id="%E4%BF%AE%E6%94%B9%E4%BA%8C-toc" style="margin-left:40px;"><strong><a href="#%E4%BF%AE%E6%94%B9%E4%BA%8C" rel="nofollow">修改二</a></strong></p> 
<p id="%E4%BF%AE%E6%94%B9%E4%B8%89%C2%A0-toc" style="margin-left:40px;"><strong><a href="#%E4%BF%AE%E6%94%B9%E4%B8%89%C2%A0" rel="nofollow">修改三 </a></strong></p> 
<p id="%E4%BF%AE%E6%94%B9%E5%9B%9B-toc" style="margin-left:40px;"><strong><a href="#%E4%BF%AE%E6%94%B9%E5%9B%9B" rel="nofollow">修改四</a></strong></p> 
<p id="%E4%BF%AE%E6%94%B9%E4%BA%94%C2%A0-toc" style="margin-left:40px;"><strong><a href="#%E4%BF%AE%E6%94%B9%E4%BA%94%C2%A0" rel="nofollow">修改五 </a></strong></p> 
<p id="%E4%BF%AE%E6%94%B9%E5%85%AD%C2%A0-toc" style="margin-left:40px;"><strong><a href="#%E4%BF%AE%E6%94%B9%E5%85%AD%C2%A0" rel="nofollow">修改六 </a></strong></p> 
<p id="%E4%BF%AE%E6%94%B9%E4%B8%83-toc" style="margin-left:40px;"><strong><a href="#%E4%BF%AE%E6%94%B9%E4%B8%83" rel="nofollow">修改七</a></strong></p> 
<p id="%E4%BF%AE%E6%94%B9%E5%85%AB-toc" style="margin-left:40px;"><strong><a href="#%E4%BF%AE%E6%94%B9%E5%85%AB" rel="nofollow">修改八</a></strong></p> 
<p id="%E4%BA%94%E3%80%81EfficientViT2023yaml%E6%96%87%E4%BB%B6-toc" style="margin-left:40px;"><strong><a href="#%E4%BA%94%E3%80%81EfficientViT2023yaml%E6%96%87%E4%BB%B6" rel="nofollow">修改九</a></strong></p> 
<p id="%E5%85%AD%E3%80%81%E6%9C%AC%E6%96%87%E6%80%BB%E7%BB%93-toc" style="margin-left:0px;"><strong><a href="#%E5%85%AD%E3%80%81%E6%9C%AC%E6%96%87%E6%80%BB%E7%BB%93" rel="nofollow">十、本文总结</a></strong></p> 
<hr id="hr-toc" /> 
<p></p> 
<blockquote> 
 <p><strong><span style="color:#fe2c24;">专栏目录&#xff1a;</span><strong><strong><strong><a href="https://snu77.blog.csdn.net/article/details/135309007" rel="nofollow" title="YOLOv8改进有效系列目录 | 包含卷积、主干、检测头、注意力机制、Neck上百种创新机制">YOLOv8改进有效系列目录 | 包含卷积、主干、检测头、注意力机制、Neck上百种创新机制</a></strong></strong></strong></strong></p> 
</blockquote> 
<blockquote> 
 <p><strong><span style="color:#fe2c24;">YOLOv8专栏&#xff1a;</span><a class="link-info" href="https://blog.csdn.net/java1314777/category_12483754.html" title="YOLOv8改进有效涨点专栏-&gt;持续复现各种最新机制">YOLOv8改进有效涨点专栏-&gt;持续复现各种最新机制</a></strong></p> 
</blockquote> 
<p>本文的讲解举例都以<span style="color:#4da8ee;"><strong>最新的YOLOv8</strong></span>的目录结构为例&#xff0c;老版本的其实方法都一样只是目录构造不一样找到同样的文件名即可。 </p> 
<p><span style="color:#fe2c24;"><strong>适用对象-&gt;</strong></span><span style="color:#511b78;"><strong>本文适合那些拿到源码却不知道如何添加到网络结构中的朋友</strong></span></p> 
<p id="main-toc"></p> 
<h2 id="%E4%BA%8C%E3%80%81%E5%AF%BC%E5%85%A5%E4%BF%AE%E6%94%B9%E5%86%85%E5%AE%B9">二、导入修改内容</h2> 
<p>大家拿到任何一个代码&#xff0c;想要加入到模型的内部&#xff0c;我们都需要先将其导入到模型的内部&#xff0c;才可以将其添加到模型的结构中去&#xff0c;下面的代码是一个ODConv&#xff0c;和我创建的一个ODConv_yolo的类(<span style="color:#1c7892;"><strong>官方的代码报错进行一定的处理想知道为啥可以看我单独讲解它的博客)</strong></span>&#xff0c; <span style="color:#fe2c24;"><strong>我们先拿其进行举例。</strong></span></p> 
<pre><code>import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.autograd


class Attention(nn.Module):
    def __init__(self, in_planes, out_planes, kernel_size, groups&#61;1, reduction&#61;0.0625, kernel_num&#61;4, min_channel&#61;16):
        super(Attention, self).__init__()
        attention_channel &#61; max(int(in_planes * reduction), min_channel)
        self.kernel_size &#61; kernel_size
        self.kernel_num &#61; kernel_num
        self.temperature &#61; 1.0

        self.avgpool &#61; nn.AdaptiveAvgPool2d(1)
        self.fc &#61; nn.Conv2d(in_planes, attention_channel, 1, bias&#61;False)
        self.bn &#61; nn.BatchNorm2d(attention_channel)
        self.relu &#61; nn.ReLU(inplace&#61;True)

        self.channel_fc &#61; nn.Conv2d(attention_channel, in_planes, 1, bias&#61;True)
        self.func_channel &#61; self.get_channel_attention

        if in_planes &#61;&#61; groups and in_planes &#61;&#61; out_planes:  # depth-wise convolution
            self.func_filter &#61; self.skip
        else:
            self.filter_fc &#61; nn.Conv2d(attention_channel, out_planes, 1, bias&#61;True)
            self.func_filter &#61; self.get_filter_attention

        if kernel_size &#61;&#61; 1:  # point-wise convolution
            self.func_spatial &#61; self.skip
        else:
            self.spatial_fc &#61; nn.Conv2d(attention_channel, kernel_size * kernel_size, 1, bias&#61;True)
            self.func_spatial &#61; self.get_spatial_attention

        if kernel_num &#61;&#61; 1:
            self.func_kernel &#61; self.skip
        else:
            self.kernel_fc &#61; nn.Conv2d(attention_channel, kernel_num, 1, bias&#61;True)
            self.func_kernel &#61; self.get_kernel_attention

        self._initialize_weights()

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode&#61;&#39;fan_out&#39;, nonlinearity&#61;&#39;relu&#39;)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            if isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def update_temperature(self, temperature):
        self.temperature &#61; temperature

    &#64;staticmethod
    def skip(_):
        return 1.0

    def get_channel_attention(self, x):
        channel_attention &#61; torch.sigmoid(self.channel_fc(x).view(x.size(0), -1, 1, 1) / self.temperature)
        return channel_attention

    def get_filter_attention(self, x):
        filter_attention &#61; torch.sigmoid(self.filter_fc(x).view(x.size(0), -1, 1, 1) / self.temperature)
        return filter_attention

    def get_spatial_attention(self, x):
        spatial_attention &#61; self.spatial_fc(x).view(x.size(0), 1, 1, 1, self.kernel_size, self.kernel_size)
        spatial_attention &#61; torch.sigmoid(spatial_attention / self.temperature)
        return spatial_attention

    def get_kernel_attention(self, x):
        kernel_attention &#61; self.kernel_fc(x).view(x.size(0), -1, 1, 1, 1, 1)
        kernel_attention &#61; F.softmax(kernel_attention / self.temperature, dim&#61;1)
        return kernel_attention

    def forward(self, x):
        x &#61; self.avgpool(x)
        x &#61; self.fc(x)
        # x &#61; self.bn(x) # 在外面我提供了一个bn这里会报错
        x &#61; self.relu(x)
        return self.func_channel(x), self.func_filter(x), self.func_spatial(x), self.func_kernel(x)


class ODConv2d(nn.Module):
    def __init__(self, in_planes, out_planes, kernel_size, stride&#61;1, padding&#61;1, dilation&#61;1, groups&#61;1,
                 reduction&#61;0.0625, kernel_num&#61;4):
        super(ODConv2d, self).__init__()
        kernel_size &#61; kernel_size[0]
        in_planes &#61; in_planes
        self.in_planes &#61; in_planes
        self.out_planes &#61; out_planes
        self.kernel_size &#61; kernel_size
        self.stride &#61; stride
        self.padding &#61; padding
        self.dilation &#61; dilation
        self.groups &#61; groups
        self.kernel_num &#61; kernel_num
        self.attention &#61; Attention(in_planes, out_planes, kernel_size, groups&#61;groups,
                                   reduction&#61;reduction, kernel_num&#61;kernel_num)
        self.weight &#61; nn.Parameter(torch.randn(kernel_num, out_planes, in_planes//groups, kernel_size, kernel_size),
                                   requires_grad&#61;True)
        self._initialize_weights()

        if self.kernel_size &#61;&#61; 1 and self.kernel_num &#61;&#61; 1:
            self._forward_impl &#61; self._forward_impl_pw1x
        else:
            self._forward_impl &#61; self._forward_impl_common

    def _initialize_weights(self):
        for i in range(self.kernel_num):
            nn.init.kaiming_normal_(self.weight[i], mode&#61;&#39;fan_out&#39;, nonlinearity&#61;&#39;relu&#39;)

    def update_temperature(self, temperature):
        self.attention.update_temperature(temperature)

    def _forward_impl_common(self, x):
        # Multiplying channel attention (or filter attention) to weights and feature maps are equivalent,
        # while we observe that when using the latter method the models will run faster with less gpu memory cost.
        channel_attention, filter_attention, spatial_attention, kernel_attention &#61; self.attention(x)
        batch_size, in_planes, height, width &#61; x.size()
        x &#61; x * channel_attention
        x &#61; x.reshape(1, -1, height, width)
        aggregate_weight &#61; spatial_attention * kernel_attention * self.weight.unsqueeze(dim&#61;0)
        aggregate_weight &#61; torch.sum(aggregate_weight, dim&#61;1).view(
            [-1, self.in_planes // self.groups, self.kernel_size, self.kernel_size])
        output &#61; F.conv2d(x, weight&#61;aggregate_weight, bias&#61;None, stride&#61;self.stride, padding&#61;self.padding,
                          dilation&#61;self.dilation, groups&#61;self.groups * batch_size)
        output &#61; output.view(batch_size, self.out_planes, output.size(-2), output.size(-1))
        output &#61; output * filter_attention
        return output

    def _forward_impl_pw1x(self, x):
        channel_attention, filter_attention, spatial_attention, kernel_attention &#61; self.attention(x)
        x &#61; x * channel_attention
        output &#61; F.conv2d(x, weight&#61;self.weight.squeeze(dim&#61;0), bias&#61;None, stride&#61;self.stride, padding&#61;self.padding,
                          dilation&#61;self.dilation, groups&#61;self.groups)
        output &#61; output * filter_attention
        return output

    def forward(self, x):
        return self._forward_impl(x)

</code></pre> 
<p>拿到这种代码之后&#xff0c;一般都很长&#xff0c;有一些博主推荐直接将其复制粘贴到YOLOv8的&#34;ultralytics/nn/modules/conv.py&#34;或者&#34;ultralytics/nn/modules/block.py&#34;目录下面&#xff0c;这种方法可不可以&#xff1f;答案是可以的&#xff0c;但是我建议大家最好新建一个文件在conv.py的同级目录下&#xff0c;为什么这么做&#xff0c;因为我们修改的模块越来越多&#xff0c;你往conv.py文件或则block.py文件里面加的代码越来越多很容易就把代码改崩溃了&#xff0c;最后就跌卸载进行重新下载包&#xff0c;我们通过建立文件导入其中类的形式&#xff0c;如果我们不用了&#xff0c;也不会对我们的代码做出任何影响&#xff0c;实在不行把新建立的文件删除了都可以&#xff0c;下面开始进行实际操作的讲解。</p> 
<hr /> 
<h3 id="2.1%E5%88%9B%E5%BB%BA%E6%96%B0%E6%96%87%E4%BB%B6%E5%AF%BC%E5%85%A5%E6%96%B0%E6%A8%A1%E5%9D%97"><strong>2.1创建新文件导入新模块</strong></h3> 
<p>我们将我们得到的任何一个Conv或者想要修改的任何一个模块都可以像下面的图片一样直接建立一个文件复制粘贴进去即可。</p> 
<p class="img-center"><img alt="" height="326" src="https://img-blog.csdnimg.cn/ce4f8d312ef545e9a768fa6b06b69b43.png" width="429" /></p> 
<p>建立好上面的文件之后&#xff0c;我们此时呢有两种情况&#xff0c;一周呢官方的代码可以直接使用&#xff0c;另一种呢需要进行一定的处理&#xff0c;我们下面分别进行讲解两种情况。</p> 
<h4 id="2.1.1%E6%83%85%E5%86%B5%E4%B8%80">2.1.1情况一</h4> 
<p>这种情况是官方的代码可以直接使用&#xff0c;此时我们直接修改&#34;ultralytics/nn/modules/__init__.py&#34;文件就可以了&#xff0c;<span style="color:#fe2c24;"><strong>修改如下-&gt;</strong></span></p> 
<p><img alt="" height="401" src="https://img-blog.csdnimg.cn/eebd7993421342cc9c108e9dd77d456d.png" width="1007" /></p> 
<h4 id="2.1.2%E6%83%85%E5%86%B5%E4%BA%8C%C2%A0">2.1.2情况二 </h4> 
<p><span style="color:#fe2c24;"><strong>另一种情况(绝大多数)&#xff1a;</strong></span>官方的代码不能直接使用我们本文的例子ODConv就是这种情况&#xff0c;所以我们需要对其进行一定的处理&#xff0c;<span style="color:#1c7892;"><strong>我们找到如下的文件-&gt;&#34;ultralytics/nn/modules/conv.py&#34;</strong></span><span style="color:#fe2c24;"><strong>对其进行修改如下-&gt; </strong></span> </p> 
<p><strong>修改一、导入模块</strong></p> 
<p><img alt="" height="161" src="https://img-blog.csdnimg.cn/e2852f1a374a42008ea6f512e61e4b06.png" width="1023" /></p> 
<p><strong>修改二、将额外处理代码添加至conv模块 </strong></p> 
<p><span style="color:#fe2c24;"><strong>将如下代码添加至该文件中的末尾处-&gt; </strong></span></p> 
<pre><code>
class ODConv2d_yolo(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size&#61;1, stride&#61;1, groups&#61;1, dilation&#61;1):
        super().__init__()
        self.conv &#61; Conv(in_channels, out_channels, k&#61;1)
        self.dcnv3 &#61; ODConv2d(out_channels,out_channels, kernel_size&#61;kernel_size, stride&#61;stride, groups&#61;groups,
                                   dilation&#61;dilation)
        self.bn &#61; nn.BatchNorm2d(out_channels)
        self.gelu &#61; nn.GELU()

    def forward(self, x):
        x &#61; self.conv(x)

        x &#61; self.dcnv3(x)

        x &#61; self.gelu(self.bn(x))
        return x
</code></pre> 
<p><strong>修改三、配置头文件</strong></p> 
<p><strong>修改如下-&gt;</strong></p> 
<p><img alt="" height="151" src="https://img-blog.csdnimg.cn/9403dabab53549e584d09095d0285d35.png" width="1039" /></p> 
<p><strong>修改四 、重复情况一的步骤</strong></p> 
<p>修改&#34;ultralytics/nn/modules/__init__.py&#34;文件如下</p> 
<p class="img-center"><img alt="" height="369" src="https://img-blog.csdnimg.cn/5da07a515e4749689bec635dce5aee81.png" width="1014" /></p> 
<blockquote> 
 <p>总结&#xff1a;通过建立文件这种方法导入想要加入到模型中的模块(这里举例的是ODConv2d)其已经在我们新创建的.py文件中定义好了然后直接导过来就可以用了&#xff0c;从而不修改原有的conv.py文件就做到了&#xff0c;这样就算我们随时不用了&#xff0c;直接删除文件然后需要改的地方也很直观&#xff0c;否则时间久了代码早晚跌崩溃。</p> 
</blockquote> 
<p></p> 
<hr /> 
<h2 id="%E4%B8%89%E3%80%81Conv%E6%A8%A1%E5%9D%97"><strong>三、Conv模块</strong></h2> 
<p>上面我们已经把定义好的卷积模块代码中了&#xff0c;此时我们还需要配置其位置&#xff0c;当然不同的模块导入的方式也有可能略有不同。</p> 
<h3 id="3.1%E4%BF%AE%E6%94%B9%E4%B8%80">3.1修改一</h3> 
<p>我们找到如下的文件&#34;ultralytics/nn/tasks.py&#34;&#xff0c;<span style="color:#fe2c24;"><strong>图片如下-&gt;</strong></span></p> 
<p class="img-center"><img alt="" height="351" src="https://img-blog.csdnimg.cn/c6285b309a9543c293cdbda304530fb1.png" width="479" /></p> 
<p>我们先把我们在上面&#34;ultralytics/nn/modules/__init__.py&#34; 文件的函数头中导入的类&#xff0c;在下面的地方导入进&#34;ultralytics/nn/tasks.py&#34;文件中&#xff0c;<span style="color:#fe2c24;"><strong>修改内容如下-&gt;</strong></span> </p> 
<p><img alt="" height="315" src="https://img-blog.csdnimg.cn/7b55e7634ed84ab2a3cd770b557437b2.png" width="1015" /></p> 
<h3 id="3.2%E4%BF%AE%E6%94%B9%E4%BA%8C">3.2修改二</h3> 
<p>我们在这个文件中找到一个方法(def定义的就叫方法)&#xff0c;因为其代码很长&#xff0c;我们一行一行搜索很麻烦&#xff0c;我们适用文件搜索功能(快捷键Ctrl &#43; F)&#xff0c;<span style="color:#fe2c24;"><strong>弹出快捷栏如下-&gt;</strong></span></p> 
<p class="img-center"><img alt="" height="326" src="https://img-blog.csdnimg.cn/dbed0272f4384e20bd10935d52b7e582.png" width="1200" /></p> 
<p>我们搜索下面这个代码&#34;parse_model&#34; 然后进行翻滚很容易就找到了下面的部分&#xff0c;同时进行红框内部的修改<img alt="" height="786" src="https://img-blog.csdnimg.cn/cc2cf56e682c4e70b77d643d5ae73339.png" width="1082" /></p> 
<h3 id="3.3%E4%BF%AE%E6%94%B9%E4%B8%89%C2%A0">3.3修改三 </h3> 
<p>到此我们就已经将我们定义的三个模块添加到我们的模型中了&#xff0c;已经可以修改yaml文件进行网络结构的配置了&#xff0c;<span style="color:#1c7892;"><strong>我们找到该文件&#34;ultralytics/cfg/models/v8/yolov8.yaml&#34;进行配置。</strong></span></p> 
<p>我们可以在其中的任何一个位置进行替换&#xff0c;当然我们的替换要符合逻辑&#xff0c;类似于之前这个位置是Conv那么你可以将你修改的卷积替换上&#xff0c;之前这个位置是C2f那么你就将修改后的C2f替换上。</p> 
<p>我们在yaml文件中进行了如下修改。</p> 
<p class="img-center"><img alt="" height="283" src="https://img-blog.csdnimg.cn/a0650ef92bfa4ede8a0742b2c63b0864.png" width="606" /></p> 
<p>到此我们就配置完成了此时进行训练就可以开始训练了~</p> 
<p class="img-center"><img alt="" height="373" src="https://img-blog.csdnimg.cn/1b203dfd520c485abff413ec42c82e6f.png" width="976" /></p> 
<p></p> 
<hr /> 
<h2 id="%E5%9B%9B%E3%80%81C2f%E3%80%81Bottleneck%E6%A8%A1%E5%9D%97">四、C2f、Bottleneck模块</h2> 
<p>下面我们拿修改后的C2f、和Bottleneck举例&#xff0c;这两个模块定义在该文件中&#34;ultralytics/nn/modules/block.py&#34;&#xff0c;所以如果我们想添加修改后的C2f和Bottleneck<span style="color:#fe2c24;"><strong>(这俩一般配套使用)&#xff0c;就需要在该文件中进行修改&#xff0c;修改步骤如下-&gt;</strong></span></p> 
<h3 id="4.1%E4%BF%AE%E6%94%B9%E4%B8%80"><strong>4.1修改一</strong></h3> 
<p>找到该文件&#34;ultralytics/nn/modules/block.py&#34;&#xff0c;进行如下修改-&gt;</p> 
<p><img alt="" height="163" src="https://img-blog.csdnimg.cn/ce5daec01b9145b89f69d8b693807a7b.png" width="761" /></p> 
<h3 id="4.2%E6%AD%A5%E9%AA%A4%E4%BA%8C%C2%A0">4.2步骤二 </h3> 
<p>添加修改后的C2f和Bottleneck模块&#xff0c;这里起名为C2f_ODConv和Bottleneck_ODConv&#xff0c;</p> 
<pre><code>class Bottleneck_ODConv(nn.Module):
    &#34;&#34;&#34;Standard bottleneck.&#34;&#34;&#34;

    def __init__(self, c1, c2, shortcut&#61;True, g&#61;1, k&#61;(3, 3), e&#61;0.5):
        &#34;&#34;&#34;Initializes a bottleneck module with given input/output channels, shortcut option, group, kernels, and
        expansion.
        &#34;&#34;&#34;
        super().__init__()
        c_ &#61; int(c2 * e)  # hidden channels
        self.cv1 &#61; Conv(c1, c_, k[0], 1)
        self.cv2 &#61; ODConv2d_yolo(c_, c2, k[1], 1, groups&#61;g)
        self.add &#61; shortcut and c1 &#61;&#61; c2

    def forward(self, x):
        &#34;&#34;&#34;&#39;forward()&#39; applies the YOLO FPN to input data.&#34;&#34;&#34;
        return x &#43; self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))


class C2f_ODConv(nn.Module):
    &#34;&#34;&#34;Faster Implementation of CSP Bottleneck with 2 convolutions.&#34;&#34;&#34;

    def __init__(self, c1, c2, n&#61;1, shortcut&#61;False, g&#61;1, e&#61;0.5):
        &#34;&#34;&#34;Initialize CSP bottleneck layer with two convolutions with arguments ch_in, ch_out, number, shortcut, groups,
        expansion.
        &#34;&#34;&#34;
        super().__init__()
        self.c &#61; int(c2 * e)  # hidden channels
        self.cv1 &#61; Conv(c1, 2 * self.c, 1, 1)
        self.cv2 &#61; Conv((2 &#43; n) * self.c, c2, 1)  # optional act&#61;FReLU(c2)
        self.m &#61; nn.ModuleList(Bottleneck_ODConv(self.c, self.c, shortcut, g, k&#61;((3, 3), (3, 3)), e&#61;1.0) for _ in range(n))

    def forward(self, x):
        &#34;&#34;&#34;Forward pass through C2f layer.&#34;&#34;&#34;
        y &#61; list(self.cv1(x).chunk(2, 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))

    def forward_split(self, x):
        &#34;&#34;&#34;Forward pass using split() instead of chunk().&#34;&#34;&#34;
        y &#61; list(self.cv1(x).split((self.c, self.c), 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))</code></pre> 
<p>将以上代码复制到文件&#34;ultralytics/nn/modules/block.py&#34;的末尾&#xff0c; </p> 
<h3 id="4.3%E4%BF%AE%E6%94%B9%E4%B8%89">4.3修改三</h3> 
<p>修改头文件如下-&gt;</p> 
<p><img alt="" height="135" src="https://img-blog.csdnimg.cn/137b6bb3442e4176a8d737c6e977df32.png" width="1084" /></p> 
<h3 id="4.4%E4%BF%AE%E6%94%B9%E5%9B%9B">4.4修改四</h3> 
<p>找到文件&#34;ultralytics/nn/modules/__init__.py&#34;&#xff0c;修改如下-&gt;</p> 
<p><img alt="" height="378" src="https://img-blog.csdnimg.cn/cd33a227588f4579a03f7f4090a296c4.png" width="1046" /></p> 
<h3 id="4.5%E4%BF%AE%E6%94%B9%E4%BA%94">4.5修改五</h3> 
<p>找到该文件我们找到如下的文件&#34;ultralytics/nn/tasks.py&#34;进行修改<span style="color:#1c7892;"><strong>(其实和卷积模块的一模一样)&#xff0c;</strong></span></p> 
<p><img alt="" height="236" src="https://img-blog.csdnimg.cn/44360406bdca4f4680b90965aeacb719.png" width="967" /></p> 
<h3 id="4.6%E4%BF%AE%E6%94%B9%E5%85%AD">4.6修改六</h3> 
<p>我们在这个文件中找到一个方法(def定义的就叫方法)&#xff0c;因为其代码很长&#xff0c;我们一行一行搜索很麻烦&#xff0c;我们适用文件搜索功能(快捷键Ctrl &#43; F)&#xff0c;<span style="color:#fe2c24;"><strong>弹出快捷栏如下-&gt;</strong></span></p> 
<p class="img-center"><img alt="" height="326" src="https://img-blog.csdnimg.cn/dbed0272f4384e20bd10935d52b7e582.png" width="1200" /></p> 
<p>我们搜索下面这个代码&#34;parse_model&#34; 然后进行翻滚很容易就找到了下面的部分&#xff0c;同时进行红框内部的修改</p> 
<p><img alt="" height="791" src="https://img-blog.csdnimg.cn/0151bad9da5b4bd4bc30afb661d3ab10.png" width="1066" /></p> 
<h3 id="4.7%E4%BF%AE%E6%94%B9%E4%B8%83">4.7修改七</h3> 
<p>到此我们就已经将我们定义的三个模块添加到我们的模型中了&#xff0c;已经可以修改yaml文件进行网络结构的配置了&#xff0c;<span style="color:#1c7892;"><strong>我们找到该文件&#34;ultralytics/cfg/models/v8/yolov8.yaml&#34;进行配置。</strong></span></p> 
<p>我们可以在其中的任何一个位置进行替换&#xff0c;当然我们的替换要符合逻辑&#xff0c;类似于之前这个位置是Conv那么你可以将你修改的卷积替换上&#xff0c;之前这个位置是C2f那么你就将修改后的C2f替换上。</p> 
<p><span style="color:#1c7892;"><strong>在yaml文件中进行了如下修改。</strong></span></p> 
<p class="img-center"><img alt="" height="289" src="https://img-blog.csdnimg.cn/ba32db68de6f4dd5afd652ad24232e5b.png" width="469" /></p> 
<p>到此就完成了修改C2f和Bottleneck模块了&#xff0c;已经可以开始进行训练了~</p> 
<p class="img-center"><img alt="" height="348" src="https://img-blog.csdnimg.cn/69793fb0635c40ef8ab41f0a5e772b54.png" width="1005" /></p> 
<blockquote> 
 <p>至于修改这个ODConv的 效果如何可以看我的其它博客里面有详细的讲解~</p> 
</blockquote> 
<p></p> 
<hr /> 
<h2 id="%E5%9B%9B%E3%80%81%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6">五、注意力机制(上采样修改方法同此处有参数注意力机制)</h2> 
<p>修改注意力机制的部分其实和上面都是类似只是在修改如下文件的时候有点不一样&#34;ultralytics/nn/tasks.py&#34;&#xff0c;但是需要注意的是<span style="color:#fe2c24;"><strong>注意力机制分为两种&#xff0c;</strong></span>一种是有参数的注意力机制我们需要像其中传入参数&#xff0c;一种是无参数的注意力机制这两种机制的添加呢稍微有一些不同&#xff0c;<span style="color:#1c7892;"><strong>我会在下面进行标注大家仔细看</strong></span></p> 
<h3 id="4.1%E4%BF%AE%E6%94%B9%E4%B8%80%C2%A0">5.1修改一 </h3> 
<p>这里我们拿Biformer注意力机制为例(我们拿有参数的注意力机制为例)&#xff0c;首先我们找到该目录&#39;ultralytics/nn/modules&#39;该目录的构造如下-&gt;</p> 
<p class="img-center"><img alt="" height="400" src="https://img-blog.csdnimg.cn/a03d6ec7b75a477fa76c753bdfcce0b0.png" width="321" /></p> 
<p>我们在其中创建一个名字为Biformer的py文件如图所示&#xff0c;我们在其中复制如下代码即可</p> 
<pre><code class="language-python">&#34;&#34;&#34;
Bi-Level Routing Attention.
&#34;&#34;&#34;
from typing import Tuple, Optional
import torch
import torch.nn as nn
import torch.nn.functional as F
from einops import rearrange
from torch import Tensor, LongTensor

class TopkRouting(nn.Module):
    &#34;&#34;&#34;
    differentiable topk routing with scaling
    Args:
        qk_dim: int, feature dimension of query and key
        topk: int, the &#39;topk&#39;
        qk_scale: int or None, temperature (multiply) of softmax activation
        with_param: bool, wether inorporate learnable params in routing unit
        diff_routing: bool, wether make routing differentiable
        soft_routing: bool, wether make output value multiplied by routing weights
    &#34;&#34;&#34;

    def __init__(self, qk_dim, topk&#61;4, qk_scale&#61;None, param_routing&#61;False, diff_routing&#61;False):
        super().__init__()
        self.topk &#61; topk
        self.qk_dim &#61; qk_dim
        self.scale &#61; qk_scale or qk_dim ** -0.5
        self.diff_routing &#61; diff_routing
        # TODO: norm layer before/after linear?
        self.emb &#61; nn.Linear(qk_dim, qk_dim) if param_routing else nn.Identity()
        # routing activation
        self.routing_act &#61; nn.Softmax(dim&#61;-1)

    def forward(self, query: Tensor, key: Tensor) -&gt; Tuple[Tensor]:
        &#34;&#34;&#34;
        Args:
            q, k: (n, p^2, c) tensor
        Return:
            r_weight, topk_index: (n, p^2, topk) tensor
        &#34;&#34;&#34;
        if not self.diff_routing:
            query, key &#61; query.detach(), key.detach()
        query_hat, key_hat &#61; self.emb(query), self.emb(key)  # per-window pooling -&gt; (n, p^2, c)
        attn_logit &#61; (query_hat * self.scale) &#64; key_hat.transpose(-2, -1)  # (n, p^2, p^2)
        topk_attn_logit, topk_index &#61; torch.topk(attn_logit, k&#61;self.topk, dim&#61;-1)  # (n, p^2, k), (n, p^2, k)
        r_weight &#61; self.routing_act(topk_attn_logit)  # (n, p^2, k)

        return r_weight, topk_index


class KVGather(nn.Module):
    def __init__(self, mul_weight&#61;&#39;none&#39;):
        super().__init__()
        assert mul_weight in [&#39;none&#39;, &#39;soft&#39;, &#39;hard&#39;]
        self.mul_weight &#61; mul_weight

    def forward(self, r_idx: Tensor, r_weight: Tensor, kv: Tensor):
        &#34;&#34;&#34;
        r_idx: (n, p^2, topk) tensor
        r_weight: (n, p^2, topk) tensor
        kv: (n, p^2, w^2, c_kq&#43;c_v)

        Return:
            (n, p^2, topk, w^2, c_kq&#43;c_v) tensor
        &#34;&#34;&#34;
        # select kv according to routing index
        n, p2, w2, c_kv &#61; kv.size()
        topk &#61; r_idx.size(-1)
        # print(r_idx.size(), r_weight.size())
        # FIXME: gather consumes much memory (topk times redundancy), write cuda kernel?
        topk_kv &#61; torch.gather(kv.view(n, 1, p2, w2, c_kv).expand(-1, p2, -1, -1, -1),
                               # (n, p^2, p^2, w^2, c_kv) without mem cpy
                               dim&#61;2,
                               index&#61;r_idx.view(n, p2, topk, 1, 1).expand(-1, -1, -1, w2, c_kv)
                               # (n, p^2, k, w^2, c_kv)
                               )

        if self.mul_weight &#61;&#61; &#39;soft&#39;:
            topk_kv &#61; r_weight.view(n, p2, topk, 1, 1) * topk_kv  # (n, p^2, k, w^2, c_kv)
        elif self.mul_weight &#61;&#61; &#39;hard&#39;:
            raise NotImplementedError(&#39;differentiable hard routing TBA&#39;)
        # else: #&#39;none&#39;
        #     topk_kv &#61; topk_kv # do nothing

        return topk_kv


class QKVLinear(nn.Module):
    def __init__(self, dim, qk_dim, bias&#61;True):
        super().__init__()
        self.dim &#61; dim
        self.qk_dim &#61; qk_dim
        self.qkv &#61; nn.Linear(dim, qk_dim &#43; qk_dim &#43; dim, bias&#61;bias)

    def forward(self, x):
        q, kv &#61; self.qkv(x).split([self.qk_dim, self.qk_dim &#43; self.dim], dim&#61;-1)
        return q, kv
        # q, k, v &#61; self.qkv(x).split([self.qk_dim, self.qk_dim, self.dim], dim&#61;-1)
        # return q, k, v


class BiLevelRoutingAttention(nn.Module):
    &#34;&#34;&#34;
    n_win: number of windows in one side (so the actual number of windows is n_win*n_win)
    kv_per_win: for kv_downsample_mode&#61;&#39;ada_xxxpool&#39; only, number of key/values per window. Similar to n_win, the actual number is kv_per_win*kv_per_win.
    topk: topk for window filtering
    param_attention: &#39;qkvo&#39;-linear for q,k,v and o, &#39;none&#39;: param free attention
    param_routing: extra linear for routing
    diff_routing: wether to set routing differentiable
    soft_routing: wether to multiply soft routing weights
    &#34;&#34;&#34;

    def __init__(self, dim, n_win&#61;7, num_heads&#61;8, qk_dim&#61;None, qk_scale&#61;None,
                 kv_per_win&#61;4, kv_downsample_ratio&#61;4, kv_downsample_kernel&#61;None, kv_downsample_mode&#61;&#39;identity&#39;,
                 topk&#61;4, param_attention&#61;&#34;qkvo&#34;, param_routing&#61;False, diff_routing&#61;False, soft_routing&#61;False,
                 side_dwconv&#61;3,
                 auto_pad&#61;True):
        super().__init__()
        # local attention setting
        self.dim &#61; dim
        self.n_win &#61; n_win  # Wh, Ww
        self.num_heads &#61; num_heads
        self.qk_dim &#61; qk_dim or dim
        assert self.qk_dim % num_heads &#61;&#61; 0 and self.dim % num_heads &#61;&#61; 0, &#39;qk_dim and dim must be divisible by num_heads!&#39;
        self.scale &#61; qk_scale or self.qk_dim ** -0.5

        ################side_dwconv (i.e. LCE in ShuntedTransformer)###########
        self.lepe &#61; nn.Conv2d(dim, dim, kernel_size&#61;side_dwconv, stride&#61;1, padding&#61;side_dwconv // 2,
                              groups&#61;dim) if side_dwconv &gt; 0 else \
            lambda x: torch.zeros_like(x)

        ################ global routing setting #################
        self.topk &#61; topk
        self.param_routing &#61; param_routing
        self.diff_routing &#61; diff_routing
        self.soft_routing &#61; soft_routing
        # router
        assert not (self.param_routing and not self.diff_routing)  # cannot be with_param&#61;True and diff_routing&#61;False
        self.router &#61; TopkRouting(qk_dim&#61;self.qk_dim,
                                  qk_scale&#61;self.scale,
                                  topk&#61;self.topk,
                                  diff_routing&#61;self.diff_routing,
                                  param_routing&#61;self.param_routing)
        if self.soft_routing:  # soft routing, always diffrentiable (if no detach)
            mul_weight &#61; &#39;soft&#39;
        elif self.diff_routing:  # hard differentiable routing
            mul_weight &#61; &#39;hard&#39;
        else:  # hard non-differentiable routing
            mul_weight &#61; &#39;none&#39;
        self.kv_gather &#61; KVGather(mul_weight&#61;mul_weight)

        # qkv mapping (shared by both global routing and local attention)
        self.param_attention &#61; param_attention
        if self.param_attention &#61;&#61; &#39;qkvo&#39;:
            self.qkv &#61; QKVLinear(self.dim, self.qk_dim)
            self.wo &#61; nn.Linear(dim, dim)
        elif self.param_attention &#61;&#61; &#39;qkv&#39;:
            self.qkv &#61; QKVLinear(self.dim, self.qk_dim)
            self.wo &#61; nn.Identity()
        else:
            raise ValueError(f&#39;param_attention mode {self.param_attention} is not surpported!&#39;)

        self.kv_downsample_mode &#61; kv_downsample_mode
        self.kv_per_win &#61; kv_per_win
        self.kv_downsample_ratio &#61; kv_downsample_ratio
        self.kv_downsample_kenel &#61; kv_downsample_kernel
        if self.kv_downsample_mode &#61;&#61; &#39;ada_avgpool&#39;:
            assert self.kv_per_win is not None
            self.kv_down &#61; nn.AdaptiveAvgPool2d(self.kv_per_win)
        elif self.kv_downsample_mode &#61;&#61; &#39;ada_maxpool&#39;:
            assert self.kv_per_win is not None
            self.kv_down &#61; nn.AdaptiveMaxPool2d(self.kv_per_win)
        elif self.kv_downsample_mode &#61;&#61; &#39;maxpool&#39;:
            assert self.kv_downsample_ratio is not None
            self.kv_down &#61; nn.MaxPool2d(self.kv_downsample_ratio) if self.kv_downsample_ratio &gt; 1 else nn.Identity()
        elif self.kv_downsample_mode &#61;&#61; &#39;avgpool&#39;:
            assert self.kv_downsample_ratio is not None
            self.kv_down &#61; nn.AvgPool2d(self.kv_downsample_ratio) if self.kv_downsample_ratio &gt; 1 else nn.Identity()
        elif self.kv_downsample_mode &#61;&#61; &#39;identity&#39;:  # no kv downsampling
            self.kv_down &#61; nn.Identity()
        elif self.kv_downsample_mode &#61;&#61; &#39;fracpool&#39;:
            # assert self.kv_downsample_ratio is not None
            # assert self.kv_downsample_kenel is not None
            # TODO: fracpool
            # 1. kernel size should be input size dependent
            # 2. there is a random factor, need to avoid independent sampling for k and v
            raise NotImplementedError(&#39;fracpool policy is not implemented yet!&#39;)
        elif kv_downsample_mode &#61;&#61; &#39;conv&#39;:
            # TODO: need to consider the case where k !&#61; v so that need two downsample modules
            raise NotImplementedError(&#39;conv policy is not implemented yet!&#39;)
        else:
            raise ValueError(f&#39;kv_down_sample_mode {self.kv_downsaple_mode} is not surpported!&#39;)

        # softmax for local attention
        self.attn_act &#61; nn.Softmax(dim&#61;-1)

        self.auto_pad &#61; auto_pad

    def forward(self, x, ret_attn_mask&#61;False):
        &#34;&#34;&#34;
        x: NHWC tensor

        Return:
            NHWC tensor
        &#34;&#34;&#34;
        x &#61; rearrange(x, &#34;n c h w -&gt; n h w c&#34;)
        # NOTE: use padding for semantic segmentation
        ###################################################
        if self.auto_pad:
            N, H_in, W_in, C &#61; x.size()

            pad_l &#61; pad_t &#61; 0
            pad_r &#61; (self.n_win - W_in % self.n_win) % self.n_win
            pad_b &#61; (self.n_win - H_in % self.n_win) % self.n_win
            x &#61; F.pad(x, (0, 0,  # dim&#61;-1
                          pad_l, pad_r,  # dim&#61;-2
                          pad_t, pad_b))  # dim&#61;-3
            _, H, W, _ &#61; x.size()  # padded size
        else:
            N, H, W, C &#61; x.size()
            assert H % self.n_win &#61;&#61; 0 and W % self.n_win &#61;&#61; 0  #
        ###################################################

        # patchify, (n, p^2, w, w, c), keep 2d window as we need 2d pooling to reduce kv size
        x &#61; rearrange(x, &#34;n (j h) (i w) c -&gt; n (j i) h w c&#34;, j&#61;self.n_win, i&#61;self.n_win)

        #################qkv projection###################
        # q: (n, p^2, w, w, c_qk)
        # kv: (n, p^2, w, w, c_qk&#43;c_v)
        # NOTE: separte kv if there were memory leak issue caused by gather
        q, kv &#61; self.qkv(x)

        # pixel-wise qkv
        # q_pix: (n, p^2, w^2, c_qk)
        # kv_pix: (n, p^2, h_kv*w_kv, c_qk&#43;c_v)
        q_pix &#61; rearrange(q, &#39;n p2 h w c -&gt; n p2 (h w) c&#39;)
        kv_pix &#61; self.kv_down(rearrange(kv, &#39;n p2 h w c -&gt; (n p2) c h w&#39;))
        kv_pix &#61; rearrange(kv_pix, &#39;(n j i) c h w -&gt; n (j i) (h w) c&#39;, j&#61;self.n_win, i&#61;self.n_win)

        q_win, k_win &#61; q.mean([2, 3]), kv[..., 0:self.qk_dim].mean(
            [2, 3])  # window-wise qk, (n, p^2, c_qk), (n, p^2, c_qk)

        ##################side_dwconv(lepe)##################
        # NOTE: call contiguous to avoid gradient warning when using ddp
        lepe &#61; self.lepe(rearrange(kv[..., self.qk_dim:], &#39;n (j i) h w c -&gt; n c (j h) (i w)&#39;, j&#61;self.n_win,
                                   i&#61;self.n_win).contiguous())
        lepe &#61; rearrange(lepe, &#39;n c (j h) (i w) -&gt; n (j h) (i w) c&#39;, j&#61;self.n_win, i&#61;self.n_win)

        ############ gather q dependent k/v #################

        r_weight, r_idx &#61; self.router(q_win, k_win)  # both are (n, p^2, topk) tensors

        kv_pix_sel &#61; self.kv_gather(r_idx&#61;r_idx, r_weight&#61;r_weight, kv&#61;kv_pix)  # (n, p^2, topk, h_kv*w_kv, c_qk&#43;c_v)
        k_pix_sel, v_pix_sel &#61; kv_pix_sel.split([self.qk_dim, self.dim], dim&#61;-1)
        # kv_pix_sel: (n, p^2, topk, h_kv*w_kv, c_qk)
        # v_pix_sel: (n, p^2, topk, h_kv*w_kv, c_v)

        ######### do attention as normal ####################
        k_pix_sel &#61; rearrange(k_pix_sel, &#39;n p2 k w2 (m c) -&gt; (n p2) m c (k w2)&#39;,
                              m&#61;self.num_heads)  # flatten to BMLC, (n*p^2, m, topk*h_kv*w_kv, c_kq//m) transpose here?
        v_pix_sel &#61; rearrange(v_pix_sel, &#39;n p2 k w2 (m c) -&gt; (n p2) m (k w2) c&#39;,
                              m&#61;self.num_heads)  # flatten to BMLC, (n*p^2, m, topk*h_kv*w_kv, c_v//m)
        q_pix &#61; rearrange(q_pix, &#39;n p2 w2 (m c) -&gt; (n p2) m w2 c&#39;,
                          m&#61;self.num_heads)  # to BMLC tensor (n*p^2, m, w^2, c_qk//m)

        # param-free multihead attention
        attn_weight &#61; (
                                  q_pix * self.scale) &#64; k_pix_sel  # (n*p^2, m, w^2, c) &#64; (n*p^2, m, c, topk*h_kv*w_kv) -&gt; (n*p^2, m, w^2, topk*h_kv*w_kv)
        attn_weight &#61; self.attn_act(attn_weight)
        out &#61; attn_weight &#64; v_pix_sel  # (n*p^2, m, w^2, topk*h_kv*w_kv) &#64; (n*p^2, m, topk*h_kv*w_kv, c) -&gt; (n*p^2, m, w^2, c)
        out &#61; rearrange(out, &#39;(n j i) m (h w) c -&gt; n (j h) (i w) (m c)&#39;, j&#61;self.n_win, i&#61;self.n_win,
                        h&#61;H // self.n_win, w&#61;W // self.n_win)

        out &#61; out &#43; lepe
        # output linear
        out &#61; self.wo(out)

        # NOTE: use padding for semantic segmentation
        # crop padded region
        if self.auto_pad and (pad_r &gt; 0 or pad_b &gt; 0):
            out &#61; out[:, :H_in, :W_in, :].contiguous()

        if ret_attn_mask:
            return out, r_weight, r_idx, attn_weight
        else:
            return rearrange(out, &#34;n h w c -&gt; n c h w&#34;)</code></pre> 
<h3 id="4.2%E4%BF%AE%E6%94%B9%E4%BA%8C">5.2修改二</h3> 
<p>我们找到该文件&#39;ultralytics/nn/tasks.py&#39;在其中添加如下一行代码</p> 
<pre><code class="language-python">from ultralytics.nn.modules.Biformer import BiLevelRoutingAttention as Biformer</code></pre> 
<p>添加完之后的效果如下图-&gt;</p> 
<p><img alt="" height="343" src="https://img-blog.csdnimg.cn/a316b651b57644c1af46020f5c4b37db.png" width="992" /></p> 
<h3 id="5.3%E4%BF%AE%E6%94%B9%E4%B8%89">5.3修改三</h3> 
<p><span style="color:#fe2c24;"><strong>这里需要注意体现出两种注意力机制的修改方式~</strong></span></p> 
<h4 id="4.2.1%E6%9C%89%E5%8F%82%E6%95%B0%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BF%AE%E6%94%B9">5.2.1有参数的注意力机制修改</h4> 
<p>现在我们已经将Biformer文件导入了模型中了&#xff0c;下一步我们就需要添加该机制到模型中让我们可以使用它&#xff0c;我们在步骤二的文件中&#39;&#39;ultralytics/nn/tasks.py&#39;&#39;按快捷键Ctrl&#43;F可以进行文件搜索。</p> 
<p><img alt="" height="154" src="https://img-blog.csdnimg.cn/9830d7746d6644a2a0371b21b62a3d73.png" width="933" /></p> 
<p>当然如果你不想用快捷键也可以自己寻找大概在 650行左右&#xff0c;有一个方法的名字叫&#34;parse_model&#34;</p> 
<p>我们找到该方法对其进行修改&#xff0c;添加如下图所示内容。</p> 
<p><img alt="" height="674" src="https://img-blog.csdnimg.cn/5205e02daf914fcf8bf92cc79af7d654.png" width="1117" /></p> 
<p>这里我们定义了一个字典&#xff0c;我们以后在想导入其它的注意力机制就可以重复步骤一和步骤二&#xff0c;然后在步骤三这里定义的字典中添加你导入的注意力机制名字即可。 </p> 
<h4 id="4.2.2%E6%97%A0%E5%8F%82%E6%95%B0%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BF%AE%E6%94%B9">5.2.2无参数的注意力机制修改</h4> 
<p>无参数的注意力机制直接修改完步骤二就可以&#xff0c;直接跳过本步骤的修改直接进行配置注意力机制即可&#xff0c;无参数的注意力机制的修改三不用进行任何修改~</p> 
<h3 id="4.4%E9%85%8D%E7%BD%AE%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6">5.4配置注意力机制</h3> 
<p>恭喜你&#xff0c;到这里我们就已经成功的导入了注意力机制&#xff0c;离修改模型只差最后一步&#xff0c;我们需要找到如下文件进行修改&#34;ultralytics/cfg/models/v8/yolov8.yaml&#34;,找到这个文件之后初始如下所示&#xff0c;</p> 
<p><img alt="" height="730" src="https://img-blog.csdnimg.cn/f8eb256281234a99b6384b35c0fb452b.png" width="709" /></p> 
<p>我们可以在某一层中添加Biformer注意力机制&#xff0c;具体添加到哪里由你自己决定&#xff0c;我这里建议添加到  Neck层&#xff0c;也就是我们的特征融合层&#xff0c;添加之后的效果如下&#xff0c;这里我在三个地方添加了Biformer注意力机制。</p> 
<p class="img-center"><img alt="" height="751" src="https://img-blog.csdnimg.cn/758406743b2e4a09a1ea90b016933e69.png" width="770" /></p> 
<p><strong>OK到此我们就添加了注意力机制到我们的模型里面了&#xff0c;下面我来讲一下添加的注意力机制中的参数是如何来的&#xff0c;</strong></p> 
<ul><li>首先-1这里我们不用管&#xff0c; 它代表上一个层的输入输入-1就是让模型自动帮我们算输入的大小&#xff01;</li><li>数字1代表这里我们的Biformer注意力机制执行一次</li><li>Biformer代表我们的注意力机制名字&#xff0c;本来类的名字不是这个我在前面导入的时候给他另命名了前面有讲到</li><li>[7&#xff0c;8]这里是根据Biformer定义的时候来的&#xff0c;你只需要输入前两个即可<span style="color:#fe2c24;"><strong>(需要注意的是无参数的注意力机制这里什么都不用填写可以看看你的无参数注意力机制需要什么那种超参数你给予赋值即可&#xff0c;不用从模型中获取任何的其它参数)。</strong></span></li></ul> 
<p><img alt="" height="118" src="https://img-blog.csdnimg.cn/3904a1bfffa541b4a48ac49b3af96fb6.png" width="889" /></p> 
<p>当然这两个参数你可以换&#xff0c;调成其它的试试效果。</p> 
<hr /> 
<h2 id="%E4%BA%94%E3%80%81Neck%E9%83%A8%E5%88%86">六、Neck部分</h2> 
<p>持续更新~</p> 
<hr /> 
<h2 id="%E5%85%AD%E3%80%81%E6%A3%80%E6%B5%8B%E5%A4%B4">七、检测头</h2> 
<p>对于检测头部分的更新&#xff0c;比其它的部分都要复杂一点&#xff0c;需要修改的地方也比较多&#xff0c;所以希望大家仔细看好每一步&#xff0c;如果有报错也可以在评论区提问&#xff0c;我的修改教程在其它的文章里都有运行截图和结果对比&#xff0c;是肯定能够完美运行的。</p> 
<p><span style="color:#fe2c24;"><strong>代码块</strong></span></p> 
<p>这里举例的代码是我对于2023年新提出的AFPN进行了修改然后适配YOLOv8的整体结构提出的检测头&#xff0c;本来该结构是四个检测头部分&#xff0c;但是我去除掉了一个适配yolov8&#xff0c;当然在我单独AFPN的文章里会用到四头的&#xff08;增加辅助训练头&#xff0c;针对小目标检测&#xff09;讲解&#xff0c;但这里是添加类教程需要具有通用性所以给大家介绍的是正常三个检测头的。</p> 
<pre><code>import math
from collections import OrderedDict
import torch
import torch.nn as nn
import torch.nn.functional as F
from ultralytics.nn.modules import DFL
from ultralytics.nn.modules.conv import Conv
from ultralytics.utils.tal import dist2bbox, make_anchors

__all__ &#61;[&#39;Detect_AFPN&#39;]

def BasicConv(filter_in, filter_out, kernel_size, stride&#61;1, pad&#61;None):
    if not pad:
        pad &#61; (kernel_size - 1) // 2 if kernel_size else 0
    else:
        pad &#61; pad
    return nn.Sequential(OrderedDict([
        (&#34;conv&#34;, nn.Conv2d(filter_in, filter_out, kernel_size&#61;kernel_size, stride&#61;stride, padding&#61;pad, bias&#61;False)),
        (&#34;bn&#34;, nn.BatchNorm2d(filter_out)),
        (&#34;relu&#34;, nn.ReLU(inplace&#61;True)),
    ]))


class BasicBlock(nn.Module):
    expansion &#61; 1

    def __init__(self, filter_in, filter_out):
        super(BasicBlock, self).__init__()
        self.conv1 &#61; nn.Conv2d(filter_in, filter_out, 3, padding&#61;1)
        self.bn1 &#61; nn.BatchNorm2d(filter_out, momentum&#61;0.1)
        self.relu &#61; nn.ReLU(inplace&#61;True)
        self.conv2 &#61; nn.Conv2d(filter_out, filter_out, 3, padding&#61;1)
        self.bn2 &#61; nn.BatchNorm2d(filter_out, momentum&#61;0.1)

    def forward(self, x):
        residual &#61; x

        out &#61; self.conv1(x)
        out &#61; self.bn1(out)
        out &#61; self.relu(out)

        out &#61; self.conv2(out)
        out &#61; self.bn2(out)

        out &#43;&#61; residual
        out &#61; self.relu(out)

        return out


class Upsample(nn.Module):
    def __init__(self, in_channels, out_channels, scale_factor&#61;2):
        super(Upsample, self).__init__()

        self.upsample &#61; nn.Sequential(
            BasicConv(in_channels, out_channels, 1),
            nn.Upsample(scale_factor&#61;scale_factor, mode&#61;&#39;bilinear&#39;)
        )


    def forward(self, x):
        x &#61; self.upsample(x)

        return x


class Downsample_x2(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(Downsample_x2, self).__init__()

        self.downsample &#61; nn.Sequential(
            BasicConv(in_channels, out_channels, 2, 2, 0)
        )

    def forward(self, x, ):
        x &#61; self.downsample(x)

        return x


class Downsample_x4(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(Downsample_x4, self).__init__()

        self.downsample &#61; nn.Sequential(
            BasicConv(in_channels, out_channels, 4, 4, 0)
        )

    def forward(self, x, ):
        x &#61; self.downsample(x)

        return x


class Downsample_x8(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(Downsample_x8, self).__init__()

        self.downsample &#61; nn.Sequential(
            BasicConv(in_channels, out_channels, 8, 8, 0)
        )

    def forward(self, x, ):
        x &#61; self.downsample(x)

        return x


class ASFF_2(nn.Module):
    def __init__(self, inter_dim&#61;512):
        super(ASFF_2, self).__init__()

        self.inter_dim &#61; inter_dim
        compress_c &#61; 8

        self.weight_level_1 &#61; BasicConv(self.inter_dim, compress_c, 1, 1)
        self.weight_level_2 &#61; BasicConv(self.inter_dim, compress_c, 1, 1)

        self.weight_levels &#61; nn.Conv2d(compress_c * 2, 2, kernel_size&#61;1, stride&#61;1, padding&#61;0)

        self.conv &#61; BasicConv(self.inter_dim, self.inter_dim, 3, 1)

    def forward(self, input1, input2):
        level_1_weight_v &#61; self.weight_level_1(input1)
        level_2_weight_v &#61; self.weight_level_2(input2)

        levels_weight_v &#61; torch.cat((level_1_weight_v, level_2_weight_v), 1)
        levels_weight &#61; self.weight_levels(levels_weight_v)
        levels_weight &#61; F.softmax(levels_weight, dim&#61;1)

        fused_out_reduced &#61; input1 * levels_weight[:, 0:1, :, :] &#43; \
                            input2 * levels_weight[:, 1:2, :, :]

        out &#61; self.conv(fused_out_reduced)

        return out


class ASFF_3(nn.Module):
    def __init__(self, inter_dim&#61;512):
        super(ASFF_3, self).__init__()

        self.inter_dim &#61; inter_dim
        compress_c &#61; 8

        self.weight_level_1 &#61; BasicConv(self.inter_dim, compress_c, 1, 1)
        self.weight_level_2 &#61; BasicConv(self.inter_dim, compress_c, 1, 1)
        self.weight_level_3 &#61; BasicConv(self.inter_dim, compress_c, 1, 1)

        self.weight_levels &#61; nn.Conv2d(compress_c * 3, 3, kernel_size&#61;1, stride&#61;1, padding&#61;0)

        self.conv &#61; BasicConv(self.inter_dim, self.inter_dim, 3, 1)

    def forward(self, input1, input2, input3):
        level_1_weight_v &#61; self.weight_level_1(input1)
        level_2_weight_v &#61; self.weight_level_2(input2)
        level_3_weight_v &#61; self.weight_level_3(input3)

        levels_weight_v &#61; torch.cat((level_1_weight_v, level_2_weight_v, level_3_weight_v), 1)
        levels_weight &#61; self.weight_levels(levels_weight_v)
        levels_weight &#61; F.softmax(levels_weight, dim&#61;1)

        fused_out_reduced &#61; input1 * levels_weight[:, 0:1, :, :] &#43; \
                            input2 * levels_weight[:, 1:2, :, :] &#43; \
                            input3 * levels_weight[:, 2:, :, :]

        out &#61; self.conv(fused_out_reduced)

        return out


class ASFF_4(nn.Module):
    def __init__(self, inter_dim&#61;512):
        super(ASFF_4, self).__init__()

        self.inter_dim &#61; inter_dim
        compress_c &#61; 8

        self.weight_level_0 &#61; BasicConv(self.inter_dim, compress_c, 1, 1)
        self.weight_level_1 &#61; BasicConv(self.inter_dim, compress_c, 1, 1)
        self.weight_level_2 &#61; BasicConv(self.inter_dim, compress_c, 1, 1)

        self.weight_levels &#61; nn.Conv2d(compress_c * 3, 3, kernel_size&#61;1, stride&#61;1, padding&#61;0)

        self.conv &#61; BasicConv(self.inter_dim, self.inter_dim, 3, 1)

    def forward(self, input0, input1, input2):
        level_0_weight_v &#61; self.weight_level_0(input0)
        level_1_weight_v &#61; self.weight_level_1(input1)
        level_2_weight_v &#61; self.weight_level_2(input2)


        levels_weight_v &#61; torch.cat((level_0_weight_v, level_1_weight_v, level_2_weight_v), 1)
        levels_weight &#61; self.weight_levels(levels_weight_v)
        levels_weight &#61; F.softmax(levels_weight, dim&#61;1)

        fused_out_reduced &#61; input0 * levels_weight[:, 0:1, :, :] &#43; \
                            input1 * levels_weight[:, 1:2, :, :] &#43; \
                            input2 * levels_weight[:, 2:3, :, :]


        out &#61; self.conv(fused_out_reduced)

        return out


class BlockBody(nn.Module):
    def __init__(self, channels&#61;[64, 128, 256, 512]):
        super(BlockBody, self).__init__()

        self.blocks_scalezero1 &#61; nn.Sequential(
            BasicConv(channels[0], channels[0], 1),
        )
        self.blocks_scaleone1 &#61; nn.Sequential(
            BasicConv(channels[1], channels[1], 1),
        )
        self.blocks_scaletwo1 &#61; nn.Sequential(
            BasicConv(channels[2], channels[2], 1),
        )


        self.downsample_scalezero1_2 &#61; Downsample_x2(channels[0], channels[1])
        self.upsample_scaleone1_2 &#61; Upsample(channels[1], channels[0], scale_factor&#61;2)

        self.asff_scalezero1 &#61; ASFF_2(inter_dim&#61;channels[0])
        self.asff_scaleone1 &#61; ASFF_2(inter_dim&#61;channels[1])

        self.blocks_scalezero2 &#61; nn.Sequential(
            BasicBlock(channels[0], channels[0]),
            BasicBlock(channels[0], channels[0]),
            BasicBlock(channels[0], channels[0]),
            BasicBlock(channels[0], channels[0]),
        )
        self.blocks_scaleone2 &#61; nn.Sequential(
            BasicBlock(channels[1], channels[1]),
            BasicBlock(channels[1], channels[1]),
            BasicBlock(channels[1], channels[1]),
            BasicBlock(channels[1], channels[1]),
        )

        self.downsample_scalezero2_2 &#61; Downsample_x2(channels[0], channels[1])
        self.downsample_scalezero2_4 &#61; Downsample_x4(channels[0], channels[2])
        self.downsample_scaleone2_2 &#61; Downsample_x2(channels[1], channels[2])
        self.upsample_scaleone2_2 &#61; Upsample(channels[1], channels[0], scale_factor&#61;2)
        self.upsample_scaletwo2_2 &#61; Upsample(channels[2], channels[1], scale_factor&#61;2)
        self.upsample_scaletwo2_4 &#61; Upsample(channels[2], channels[0], scale_factor&#61;4)

        self.asff_scalezero2 &#61; ASFF_3(inter_dim&#61;channels[0])
        self.asff_scaleone2 &#61; ASFF_3(inter_dim&#61;channels[1])
        self.asff_scaletwo2 &#61; ASFF_3(inter_dim&#61;channels[2])

        self.blocks_scalezero3 &#61; nn.Sequential(
            BasicBlock(channels[0], channels[0]),
            BasicBlock(channels[0], channels[0]),
            BasicBlock(channels[0], channels[0]),
            BasicBlock(channels[0], channels[0]),
        )
        self.blocks_scaleone3 &#61; nn.Sequential(
            BasicBlock(channels[1], channels[1]),
            BasicBlock(channels[1], channels[1]),
            BasicBlock(channels[1], channels[1]),
            BasicBlock(channels[1], channels[1]),
        )
        self.blocks_scaletwo3 &#61; nn.Sequential(
            BasicBlock(channels[2], channels[2]),
            BasicBlock(channels[2], channels[2]),
            BasicBlock(channels[2], channels[2]),
            BasicBlock(channels[2], channels[2]),
        )

        self.downsample_scalezero3_2 &#61; Downsample_x2(channels[0], channels[1])
        self.downsample_scalezero3_4 &#61; Downsample_x4(channels[0], channels[2])
        self.upsample_scaleone3_2 &#61; Upsample(channels[1], channels[0], scale_factor&#61;2)
        self.downsample_scaleone3_2 &#61; Downsample_x2(channels[1], channels[2])
        self.upsample_scaletwo3_4 &#61; Upsample(channels[2], channels[0], scale_factor&#61;4)
        self.upsample_scaletwo3_2 &#61; Upsample(channels[2], channels[1], scale_factor&#61;2)

        self.asff_scalezero3 &#61; ASFF_4(inter_dim&#61;channels[0])
        self.asff_scaleone3 &#61; ASFF_4(inter_dim&#61;channels[1])
        self.asff_scaletwo3 &#61; ASFF_4(inter_dim&#61;channels[2])

        self.blocks_scalezero4 &#61; nn.Sequential(
            BasicBlock(channels[0], channels[0]),
            BasicBlock(channels[0], channels[0]),
            BasicBlock(channels[0], channels[0]),
            BasicBlock(channels[0], channels[0]),
        )
        self.blocks_scaleone4 &#61; nn.Sequential(
            BasicBlock(channels[1], channels[1]),
            BasicBlock(channels[1], channels[1]),
            BasicBlock(channels[1], channels[1]),
            BasicBlock(channels[1], channels[1]),
        )
        self.blocks_scaletwo4 &#61; nn.Sequential(
            BasicBlock(channels[2], channels[2]),
            BasicBlock(channels[2], channels[2]),
            BasicBlock(channels[2], channels[2]),
            BasicBlock(channels[2], channels[2]),
        )


    def forward(self, x):
        x0, x1, x2 &#61; x

        x0 &#61; self.blocks_scalezero1(x0)
        x1 &#61; self.blocks_scaleone1(x1)
        x2 &#61; self.blocks_scaletwo1(x2)


        scalezero &#61; self.asff_scalezero1(x0, self.upsample_scaleone1_2(x1))
        scaleone &#61; self.asff_scaleone1(self.downsample_scalezero1_2(x0), x1)

        x0 &#61; self.blocks_scalezero2(scalezero)
        x1 &#61; self.blocks_scaleone2(scaleone)

        scalezero &#61; self.asff_scalezero2(x0, self.upsample_scaleone2_2(x1), self.upsample_scaletwo2_4(x2))
        scaleone &#61; self.asff_scaleone2(self.downsample_scalezero2_2(x0), x1, self.upsample_scaletwo2_2(x2))
        scaletwo &#61; self.asff_scaletwo2(self.downsample_scalezero2_4(x0), self.downsample_scaleone2_2(x1), x2)

        x0 &#61; self.blocks_scalezero3(scalezero)
        x1 &#61; self.blocks_scaleone3(scaleone)
        x2 &#61; self.blocks_scaletwo3(scaletwo)

        scalezero &#61; self.asff_scalezero3(x0, self.upsample_scaleone3_2(x1), self.upsample_scaletwo3_4(x2))
        scaleone &#61; self.asff_scaleone3(self.downsample_scalezero3_2(x0), x1, self.upsample_scaletwo3_2(x2))
        scaletwo &#61; self.asff_scaletwo3(self.downsample_scalezero3_4(x0), self.downsample_scaleone3_2(x1), x2)


        scalezero &#61; self.blocks_scalezero4(scalezero)
        scaleone &#61; self.blocks_scaleone4(scaleone)
        scaletwo &#61; self.blocks_scaletwo4(scaletwo)


        return scalezero, scaleone, scaletwo

class AFPN(nn.Module):
    def __init__(self,
                 in_channels&#61;[256, 512, 1024, 2048],
                 out_channels&#61;128):
        super(AFPN, self).__init__()

        self.fp16_enabled &#61; False

        self.conv0 &#61; BasicConv(in_channels[0], in_channels[0] // 8, 1)
        self.conv1 &#61; BasicConv(in_channels[1], in_channels[1] // 8, 1)
        self.conv2 &#61; BasicConv(in_channels[2], in_channels[2] // 8, 1)
        # self.conv3 &#61; BasicConv(in_channels[3], in_channels[3] // 8, 1)

        self.body &#61; nn.Sequential(
            BlockBody([in_channels[0] // 8, in_channels[1] // 8, in_channels[2] // 8])
        )

        self.conv00 &#61; BasicConv(in_channels[0] // 8, out_channels, 1)
        self.conv11 &#61; BasicConv(in_channels[1] // 8, out_channels, 1)
        self.conv22 &#61; BasicConv(in_channels[2] // 8, out_channels, 1)
        # self.conv33 &#61; BasicConv(in_channels[3] // 8, out_channels, 1)

        # init weight
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.xavier_normal_(m.weight, gain&#61;0.02)
            elif isinstance(m, nn.BatchNorm2d):
                torch.nn.init.normal_(m.weight.data, 1.0, 0.02)
                torch.nn.init.constant_(m.bias.data, 0.0)

    def forward(self, x):
        x0, x1, x2 &#61; x

        x0 &#61; self.conv0(x0)
        x1 &#61; self.conv1(x1)
        x2 &#61; self.conv2(x2)
        # x3 &#61; self.conv3(x3)

        out0, out1, out2 &#61; self.body([x0, x1, x2])

        out0 &#61; self.conv00(out0)
        out1 &#61; self.conv11(out1)
        out2 &#61; self.conv22(out2)


        return out0, out1, out2


class Detect_AFPN(nn.Module):
    &#34;&#34;&#34;YOLOv8 Detect head for detection models.&#34;&#34;&#34;
    dynamic &#61; False  # force grid reconstruction
    export &#61; False  # export mode
    shape &#61; None
    anchors &#61; torch.empty(0)  # init
    strides &#61; torch.empty(0)  # init

    def __init__(self, nc&#61;80, channel&#61;128,  ch&#61;()):
        &#34;&#34;&#34;Initializes the YOLOv8 detection layer with specified number of classes and channels.&#34;&#34;&#34;
        super().__init__()
        self.nc &#61; nc  # number of classes
        self.nl &#61; len(ch)  # number of detection layers
        self.reg_max &#61; 16  # DFL channels (ch[0] // 16 to scale 4/8/12/16/20 for n/s/m/l/x)
        self.no &#61; nc &#43; self.reg_max * 4  # number of outputs per anchor
        self.stride &#61; torch.zeros(self.nl)  # strides computed during build
        c2, c3 &#61; max((16, ch[0] // 4, self.reg_max * 4)), max(ch[0], min(self.nc, 100))  # channels
        self.cv2 &#61; nn.ModuleList(
            nn.Sequential(Conv(channel, c2, 3), Conv(c2, c2, 3), nn.Conv2d(c2, 4 * self.reg_max, 1)) for x in ch)
        self.cv3 &#61; nn.ModuleList(nn.Sequential(Conv(channel, c3, 3), Conv(c3, c3, 3), nn.Conv2d(c3, self.nc, 1)) for x in ch)
        self.dfl &#61; DFL(self.reg_max) if self.reg_max &gt; 1 else nn.Identity()
        self.AFPN &#61; AFPN(ch, channel)

    def forward(self, x):
        &#34;&#34;&#34;Concatenates and returns predicted bounding boxes and class probabilities.&#34;&#34;&#34;
        x &#61; list(self.AFPN(x))
        shape &#61; x[0].shape  # BCHW
        for i in range(self.nl):
            x[i] &#61; torch.cat((self.cv2[i](x[i]), self.cv3[i](x[i])), 1)
        if self.training:
            return x
        elif self.dynamic or self.shape !&#61; shape:
            self.anchors, self.strides &#61; (x.transpose(0, 1) for x in make_anchors(x, self.stride, 0.5))
            self.shape &#61; shape

        x_cat &#61; torch.cat([xi.view(shape[0], self.no, -1) for xi in x], 2)
        if self.export and self.format in (&#39;saved_model&#39;, &#39;pb&#39;, &#39;tflite&#39;, &#39;edgetpu&#39;, &#39;tfjs&#39;):  # avoid TF FlexSplitV ops
            box &#61; x_cat[:, :self.reg_max * 4]
            cls &#61; x_cat[:, self.reg_max * 4:]
        else:
            box, cls &#61; x_cat.split((self.reg_max * 4, self.nc), 1)
        dbox &#61; dist2bbox(self.dfl(box), self.anchors.unsqueeze(0), xywh&#61;True, dim&#61;1) * self.strides

        if self.export and self.format in (&#39;tflite&#39;, &#39;edgetpu&#39;):
            # Normalize xywh with image size to mitigate quantization error of TFLite integer models as done in YOLOv5:
            # https://github.com/ultralytics/yolov5/blob/0c8de3fca4a702f8ff5c435e67f378d1fce70243/models/tf.py#L307-L309
            # See this PR for details: https://github.com/ultralytics/ultralytics/pull/1695
            img_h &#61; shape[2] * self.stride[0]
            img_w &#61; shape[3] * self.stride[0]
            img_size &#61; torch.tensor([img_w, img_h, img_w, img_h], device&#61;dbox.device).reshape(1, 4, 1)
            dbox /&#61; img_size

        y &#61; torch.cat((dbox, cls.sigmoid()), 1)
        return y if self.export else (y, x)

    def bias_init(self):
        &#34;&#34;&#34;Initialize Detect() biases, WARNING: requires stride availability.&#34;&#34;&#34;
        m &#61; self  # self.model[-1]  # Detect() module
        # cf &#61; torch.bincount(torch.tensor(np.concatenate(dataset.labels, 0)[:, 0]).long(), minlength&#61;nc) &#43; 1
        # ncf &#61; math.log(0.6 / (m.nc - 0.999999)) if cf is None else torch.log(cf / cf.sum())  # nominal class frequency
        for a, b, s in zip(m.cv2, m.cv3, m.stride):  # from
            a[-1].bias.data[:] &#61; 1.0  # box
            b[-1].bias.data[:m.nc] &#61; math.log(5 / m.nc / (640 / s) ** 2)  # cls (.01 objects, 80 classes, 640 img)
</code></pre> 
<h3 id="6.1%20%E4%BF%AE%E6%94%B9%E4%B8%80">7.1 修改一</h3> 
<p>首先我们将上面的代码复制粘贴到&#39;ultralytics/nn/modules&#39; 目录下新建一个py文件复制粘贴进去&#xff0c;具体名字自己来定&#xff0c;我这里起名为AFPN.py。</p> 
<p>(在这里说一下大家可以看到我每个修改教程都会单独拿出来一个新的未修改任何东西yolov8仓库&#xff0c;避免因为之前其它的修改而导致给大家的修改教程有问题&#xff0c;所以有的时候大家部分的代码不能跑可能是因为大家修改了其它的机制&#xff0c;导致修改了源代码可能会导致跑不了&#xff0c;所以有的错误我没有大家的代码实在是不好给大家解决问题&#xff0c;后期针对这个问题我会上传修改好了的文件&#xff0c;<span style="color:#1a439c;"><strong>我收集了大概80余种YOLOv8的改进方式&#xff0c;到时候大家直接可以拿着我代码进行组合从而避免各种的报错问题&#xff0c;所以大家可以提早关注本专栏。</strong></span>)</p> 
<p class="img-center"><img alt="" height="341" src="https://img-blog.csdnimg.cn/direct/0716362c915841f7bd31d777b4e124cb.png" width="488" /></p> 
<p></p> 
<h3 id="6.2%20%E4%BF%AE%E6%94%B9%E4%BA%8C">7.2 修改二</h3> 
<p>我们新建完上面的文件之后&#xff0c;找到如下的文件&#39;ultralytics/nn/tasks.py&#39;。这里需要修改的地方有点多&#xff0c;总共有7处&#xff0c;但都很简单。首先我们在该文件的头部导入我们AFPN文件中的检测头。</p> 
<p class="img-center"><img alt="" height="347" src="https://img-blog.csdnimg.cn/direct/a1c04986e6c6425e9e6b1f8e9a2a888a.png" width="1061" /></p> 
<p></p> 
<h3 id="6.3%20%E4%BF%AE%E6%94%B9%E4%B8%89%C2%A0">7.3 修改三 </h3> 
<p>找到如下的代码进行将检测头添加进去&#xff0c;这里给大家推荐个快速搜索的方法用ctrl&#43;f然后搜索Detect然后就能快速查找了。</p> 
<p class="img-center"><img alt="" height="178" src="https://img-blog.csdnimg.cn/direct/0bc972e1c7254424afb3f87713c1938b.png" width="722" /></p> 
<p></p> 
<h3 id="6.4%20%E4%BF%AE%E6%94%B9%E5%9B%9B%C2%A0">7.4 修改四 </h3> 
<p>同理将我们的检测头添加到如下的代码里。</p> 
<p><img alt="" height="226" src="https://img-blog.csdnimg.cn/direct/d8723f55d2934ab4a86461627b06278e.png" width="989" /></p> 
<p></p> 
<h3 id="6.5%20%E4%BF%AE%E6%94%B9%E4%BA%94%C2%A0">7.5 修改五 </h3> 
<p>同理</p> 
<p><img alt="" height="179" src="https://img-blog.csdnimg.cn/direct/c732ad32ac664a359fce26ff86f8d2fb.png" width="984" /></p> 
<p></p> 
<h3 id="6.6%20%E4%BF%AE%E6%94%B9%E5%85%AD%C2%A0">7.6 修改六 </h3> 
<p>同理</p> 
<h3 id="%E2%80%8B%E7%BC%96%E8%BE%91"><img alt="" height="176" src="https://img-blog.csdnimg.cn/direct/b456089e45af49159edc2c733300a61b.png" width="992" /></h3> 
<p></p> 
<h3 id="6.7%20%E4%BF%AE%E6%94%B9%E4%B8%83%C2%A0">7.7 修改七 </h3> 
<p>同理</p> 
<p><img alt="" height="181" src="https://img-blog.csdnimg.cn/direct/c9c08db5c011416cb00ba0d543959587.png" width="839" /></p> 
<p></p> 
<h3 id="6.8%20%E4%BF%AE%E6%94%B9%E5%85%AB">7.8 修改八</h3> 
<p>这里有一些不一样&#xff0c;我们需要加一行代码</p> 
<pre><code>        else:
            return &#39;detect&#39;</code></pre> 
<p>为啥呢不一样&#xff0c;因为这里的m在代码执行过程中会将你的代码自动转换为小写&#xff0c;所以直接else方便一点&#xff0c;以后出现一些其它分割或者其它的教程的时候在提供其它的修改教程。 </p> 
<p><img alt="" height="309" src="https://img-blog.csdnimg.cn/direct/1db90013ad2a4205aeff11a4b9f2b03b.png" width="874" /></p> 
<h3 id="6.9%20%E4%BF%AE%E6%94%B9%E4%B9%9D%C2%A0">7.9 修改九 </h3> 
<p>这里也有一些不一样&#xff0c;需要自己手动添加一个括号&#xff0c;提醒一下大家不要直接添加&#xff0c;和我下面保持一致。</p> 
<p><img alt="" height="220" src="https://img-blog.csdnimg.cn/direct/9f3d2394f61b48eba100bc2b49c5429d.png" width="875" /></p> 
<p></p> 
<h3 id="6.10%20%E4%BF%AE%E6%94%B9%E5%8D%81%C2%A0">7.10 修改十 </h3> 
<p>这个代码的yaml文件和正常的对比也需要修改一下&#xff0c;<span style="color:#fe2c24;"><strong>如下-&gt;</strong></span></p> 
<pre><code># Ultralytics YOLO &#x1f680;, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 80  # number of classes
scales: # model compound scaling constants, i.e. &#39;model&#61;yolov8n.yaml&#39; will call yolov8.yaml with scale &#39;n&#39;
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [0.33, 0.50, 1024]  # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs
  m: [0.67, 0.75, 768]   # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs
  l: [1.00, 1.00, 512]   # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  x: [1.00, 1.25, 512]   # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs

# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]]  # 1-P2/4
  - [-1, 3, C2f, [128, True]]
  - [-1, 1, Conv, [256, 3, 2]]  # 3-P3/8
  - [-1, 6, C2f, [256, True]]
  - [-1, 1, Conv, [512, 3, 2]]  # 5-P4/16
  - [-1, 6, C2f, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]]  # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]]  # 9

# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, &#39;nearest&#39;]]
  - [[-1, 6], 1, Concat, [1]]  # cat backbone P4
  - [-1, 3, C2f, [512]]  # 12

  - [-1, 1, nn.Upsample, [None, 2, &#39;nearest&#39;]]
  - [[-1, 4], 1, Concat, [1]]  # cat backbone P3
  - [-1, 3, C2f, [256]]  # 15 (P3/8-small)

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 12], 1, Concat, [1]]  # cat head P4
  - [-1, 3, C2f, [512]]  # 18 (P4/16-medium)

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 9], 1, Concat, [1]]  # cat head P5
  - [-1, 3, C2f, [1024]]  # 21 (P5/32-large)

  - [[15, 18, 21], 1, Detect_AFPN, [nc, 256]]  # Detect(P3, P4, P5)
</code></pre> 
<p><span style="color:#fe2c24;"><strong>最后提供一下完美运行的图片。</strong></span></p> 
<p><img alt="" height="732" src="https://img-blog.csdnimg.cn/direct/918c93129d19436198dbbc4ece4ca8ce.png" width="1139" /></p> 
<p></p> 
<p></p> 
<p></p> 
<h2 id="%E4%B8%83%E3%80%81%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0">八、损失函数</h2> 
<p>当我们想要在YOLOv8中添加算是函数时候我们需要进行以下的操作&#xff0c;同时我我们引入Focus的思想时候需要进行如何的操作&#xff0c;大家可以按照如下的步骤进行操作即可。</p> 
<p>我们提供的代码是最新的Inner实现的各种损失的思想&#xff0c;给大家进行尝试。</p> 
<p>大家可以用下面的代码块一和代码块二进行操作。</p> 
<p><strong>代码块一</strong></p> 
<pre><code>
class WIoU_Scale:
    &#39;&#39;&#39; monotonous: {
            None: origin v1
            True: monotonic FM v2
            False: non-monotonic FM v3
        }
        momentum: The momentum of running mean&#39;&#39;&#39;

    iou_mean &#61; 1.
    monotonous &#61; False
    _momentum &#61; 1 - 0.5 ** (1 / 7000)
    _is_train &#61; True

    def __init__(self, iou):
        self.iou &#61; iou
        self._update(self)

    &#64;classmethod
    def _update(cls, self):
        if cls._is_train: cls.iou_mean &#61; (1 - cls._momentum) * cls.iou_mean &#43; \
                                         cls._momentum * self.iou.detach().mean().item()

    &#64;classmethod
    def _scaled_loss(cls, self, gamma&#61;1.9, delta&#61;3):
        if isinstance(self.monotonous, bool):
            if self.monotonous:
                return (self.iou.detach() / self.iou_mean).sqrt()
            else:
                beta &#61; self.iou.detach() / self.iou_mean
                alpha &#61; delta * torch.pow(gamma, beta - delta)
                return beta / alpha
        return 1


def bbox_iou(box1, box2, xywh&#61;True, ratio&#61;1, GIoU&#61;False, DIoU&#61;False, CIoU&#61;False, SIoU&#61;False,
             EIoU&#61;False, WIoU&#61;False, MPDIoU&#61;False, LMPDIoU&#61;False, Inner&#61;False, Focal&#61;False, alpha&#61;1, gamma&#61;0.5,
             scale&#61;False, eps&#61;1e-7):
    if Inner:
        (x1, y1, w1, h1), (x2, y2, w2, h2) &#61; box1.chunk(4, -1), box2.chunk(4, -1)
        w1_, h1_, w2_, h2_ &#61; w1 / 2, h1 / 2, w2 / 2, h2 / 2

        # Inner-IoU      #Inner-IoU        #Inner-IoU        #Inner-IoU        #Inner-IoU        #Inner-IoU        #Inner-IoU
        b1_x1, b1_x2, b1_y1, b1_y2 &#61; x1 - w1_ * ratio, x1 &#43; w1_ * ratio, \
                                     y1 - h1_ * ratio, y1 &#43; h1_ * ratio
        b2_x1, b2_x2, b2_y1, b2_y2 &#61; x2 - w2_ * ratio, x2 &#43; w2_ * ratio, \
                                     y2 - h2_ * ratio, y2 &#43; h2_ * ratio
        inter &#61; (torch.min(b1_x2, b2_x2) - torch.max(b1_x1, b2_x1)).clamp(0) * \
                (torch.min(b1_y2, b2_y2) - torch.max(b1_y1, b2_y1)).clamp(0)
        union &#61; w1 * ratio * h1 * ratio &#43; w2 * ratio * h2 * ratio - inter &#43; eps

        iou &#61; inter / union  # inner_iou

    else:
        # Returns the IoU of box1 to box2. box1 is 4, box2 is nx4
        if xywh:  # transform from xywh to xyxy
            (x1, y1, w1, h1), (x2, y2, w2, h2) &#61; box1.chunk(4, -1), box2.chunk(4, -1)
            w1_, h1_, w2_, h2_ &#61; w1 / 2, h1 / 2, w2 / 2, h2 / 2
            b1_x1, b1_x2, b1_y1, b1_y2 &#61; x1 - w1_, x1 &#43; w1_, y1 - h1_, y1 &#43; h1_
            b2_x1, b2_x2, b2_y1, b2_y2 &#61; x2 - w2_, x2 &#43; w2_, y2 - h2_, y2 &#43; h2_
        else:  # x1, y1, x2, y2 &#61; box1
            b1_x1, b1_y1, b1_x2, b1_y2 &#61; box1.chunk(4, -1)
            b2_x1, b2_y1, b2_x2, b2_y2 &#61; box2.chunk(4, -1)
            w1, h1 &#61; b1_x2 - b1_x1, b1_y2 - b1_y1 &#43; eps
            w2, h2 &#61; b2_x2 - b2_x1, b2_y2 - b2_y1 &#43; eps

            # Intersection area
        inter &#61; (b1_x2.minimum(b2_x2) - b1_x1.maximum(b2_x1)).clamp_(0) * \
                (b1_y2.minimum(b2_y2) - b1_y1.maximum(b2_y1)).clamp_(0)

        # Union Area
        union &#61; w1 * h1 &#43; w2 * h2 - inter &#43; eps

        # IoU
        iou &#61; inter / union



    if CIoU or DIoU or GIoU or EIoU or SIoU or WIoU or MPDIoU or LMPDIoU:
        cw &#61; b1_x2.maximum(b2_x2) - b1_x1.minimum(
            b2_x1)  # convex (smallest enclosing box) width
        ch &#61; b1_y2.maximum(b2_y2) - b1_y1.minimum(b2_y1)  # convex height
        if CIoU or DIoU or EIoU or SIoU or WIoU or MPDIoU or LMPDIoU:  # Distance or Complete IoU
            # https://arxiv.org/abs/1911.08287v1
            c2 &#61; (cw ** 2 &#43; ch ** 2) ** alpha &#43; eps  # convex diagonal squared
            rho2 &#61; (((b2_x1 &#43; b2_x2 - b1_x1 - b1_x2) ** 2 &#43; (
                    b2_y1 &#43; b2_y2 - b1_y1 - b1_y2) ** 2) / 4) ** alpha  # center dist ** 2
            if CIoU:  # https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47
                v &#61; (4 / math.pi ** 2) * (torch.atan(w2 / h2) - torch.atan(w1 / h1)).pow(2)
                with torch.no_grad():
                    alpha_ciou &#61; v / (v - iou &#43; (1 &#43; eps))
                if Focal:
                    return iou - (rho2 / c2 &#43; torch.pow(v * alpha_ciou &#43; eps, alpha)), torch.pow(
                        inter / (union &#43; eps),
                        gamma)  # Focal_CIoU
                else:
                    return iou - (rho2 / c2 &#43; torch.pow(v * alpha_ciou &#43; eps, alpha))  # CIoU
            elif MPDIoU:
                d1 &#61; (b2_x1 - b1_x1) ** 2 &#43; (b2_y1 - b1_y1) ** 2
                d2 &#61; (b2_x2 - b1_x2) ** 2 &#43; (b2_y2 - b1_y2) ** 2
                w &#61; (b2_x2 - b2_x1)  # x2 - x1
                h &#61; (b2_y2 - b2_y1)  # y2 - y1
                if Focal:
                    return iou - ((d1 &#43; d2) / (w ** 2 &#43; h ** 2)), torch.pow(inter / (union &#43; eps),
                                                                            gamma)  # Focal_MPDIoU
                else:
                    return iou - (d1 &#43; d2) / (w ** 2 &#43; h ** 2)
            elif LMPDIoU:
                d1 &#61; (b2_x1 - b1_x1) ** 2 &#43; (b2_y1 - b1_y1) ** 2
                d2 &#61; (b2_x2 - b1_x2) ** 2 &#43; (b2_y2 - b1_y2) ** 2
                w &#61; (b2_x2 - b2_x1)  # x2 - x1
                h &#61; (b2_y2 - b2_y1)  # y2 - y1
                if Focal:
                    return 1 - (iou - (d1 &#43; d2) / (w ** 2 &#43; h ** 2)), torch.pow(inter / (union &#43; eps),
                                                                                gamma)  # Focal_MPDIo  # MPDIoU
                else:
                    return 1 - iou &#43; d1 / (w ** 2 &#43; h ** 2) &#43; d2 / (w ** 2 &#43; h ** 2)
            elif EIoU:
                rho_w2 &#61; ((b2_x2 - b2_x1) - (b1_x2 - b1_x1)) ** 2
                rho_h2 &#61; ((b2_y2 - b2_y1) - (b1_y2 - b1_y1)) ** 2
                cw2 &#61; torch.pow(cw ** 2 &#43; eps, alpha)
                ch2 &#61; torch.pow(ch ** 2 &#43; eps, alpha)
                if Focal:
                    return iou - (rho2 / c2 &#43; rho_w2 / cw2 &#43; rho_h2 / ch2), torch.pow(
                        inter / (union &#43; eps),
                        gamma)  # Focal_EIou
                else:
                    return iou - (rho2 / c2 &#43; rho_w2 / cw2 &#43; rho_h2 / ch2)  # EIou
            elif SIoU:
                # SIoU Loss https://arxiv.org/pdf/2205.12740.pdf
                s_cw &#61; (b2_x1 &#43; b2_x2 - b1_x1 - b1_x2) * 0.5 &#43; eps
                s_ch &#61; (b2_y1 &#43; b2_y2 - b1_y1 - b1_y2) * 0.5 &#43; eps
                sigma &#61; torch.pow(s_cw ** 2 &#43; s_ch ** 2, 0.5)
                sin_alpha_1 &#61; torch.abs(s_cw) / sigma
                sin_alpha_2 &#61; torch.abs(s_ch) / sigma
                threshold &#61; pow(2, 0.5) / 2
                sin_alpha &#61; torch.where(sin_alpha_1 &gt; threshold, sin_alpha_2, sin_alpha_1)
                angle_cost &#61; torch.cos(torch.arcsin(sin_alpha) * 2 - math.pi / 2)
                rho_x &#61; (s_cw / cw) ** 2
                rho_y &#61; (s_ch / ch) ** 2
                gamma &#61; angle_cost - 2
                distance_cost &#61; 2 - torch.exp(gamma * rho_x) - torch.exp(gamma * rho_y)
                omiga_w &#61; torch.abs(w1 - w2) / torch.max(w1, w2)
                omiga_h &#61; torch.abs(h1 - h2) / torch.max(h1, h2)
                shape_cost &#61; torch.pow(1 - torch.exp(-1 * omiga_w), 4) &#43; torch.pow(1 - torch.exp(-1 * omiga_h), 4)
                if Focal:
                    return iou - torch.pow(0.5 * (distance_cost &#43; shape_cost) &#43; eps, alpha), torch.pow(
                        inter / (union &#43; eps), gamma)  # Focal_SIou
                else:
                    return iou - torch.pow(0.5 * (distance_cost &#43; shape_cost) &#43; eps, alpha)  # SIou
            elif WIoU:
                self &#61; WIoU_Scale(1 - (inter / union))
                dist &#61; getattr(WIoU_Scale, &#39;_scaled_loss&#39;)(self)
                return iou * dist # WIoU https://arxiv.org/abs/2301.10051

            if Focal:
                return iou - rho2 / c2, torch.pow(inter / (union &#43; eps), gamma)  # Focal_DIoU
            else:
                return iou - rho2 / c2  # DIoU

        c_area &#61; cw * ch &#43; eps  # convex area
        if Focal:
            return iou - torch.pow((c_area - union) / c_area &#43; eps, alpha), torch.pow(
                inter / (union &#43; eps),
                gamma)  # Focal_GIoU https://arxiv.org/pdf/1902.09630.pdf
        else:
            return iou - torch.pow((c_area - union) / c_area &#43; eps,
                                   alpha)  # GIoU https://arxiv.org/pdf/1902.09630.pdf
    if Focal:
        return iou, torch.pow(inter / (union &#43; eps), gamma)  # Focal_IoU
    else:
        return iou  # IoU
</code></pre> 
<p><strong>代码块二 </strong></p> 
<pre><code class="language-python">        if type(iou) is tuple:
            if len(iou) &#61;&#61; 2:
                # Focus Loss 时返回的是元组类型,进行额外处理
                loss_iou &#61; ((1.0 - iou[0]) * iou[1].detach() * weight).sum() / target_scores_sum
            else:
                loss_iou &#61; (iou[0] * iou[1] * weight).sum() / target_scores_sum
 
        else:
            # 正常的损失函数
            loss_iou &#61; ((1.0 - iou) * weight).sum() / target_scores_sum</code></pre> 
<h3 id="7.1%20%E4%BF%AE%E6%94%B9%E4%B8%80">8.1 修改一</h3> 
<p>第一步我们需要找到如下的文件ultralytics/utils/metrics.py,找到如下的代码&#xff0c;下面的图片是原先的代码部分截图的正常样子&#xff0c;然后我们将整个代码块一将下面的<span style="color:#1c7892;"><strong>整个方法(这里这是部分截图)</strong></span><strong><span style="color:#ed7976;">内容全部替换</span></strong></p> 
<p><img alt="" height="448" src="https://img-blog.csdnimg.cn/e7a59a4795ac45e29c2ee02d373394e9.png" width="751" /></p> 
<h3 id="7.2%20%E4%BF%AE%E6%94%B9%E4%BA%8C">8.2 修改二</h3> 
<p>第二步我们找到另一个文件如下-&gt;&#34;ultralytics/utils/loss.py&#34;&#xff0c;我们找到如下的代码块&#xff0c;将代码块二替换其中的第74行&#xff0c;</p> 
<p><img alt="" height="558" src="https://img-blog.csdnimg.cn/8def94a1508f453eb2e075fcec50a7e9.png" width="1038" /></p> 
<p>同时在上面的第73行(我说的我图片这里的不一定代表你那里&#xff0c;替换成如下的形式&#xff0c;因为我们这里用的Inner的思想的IoU所以我们的红框内和原先的也是不一样需要修改的&#xff0c;大家可以看到这里用到的是Inner_CIoU如果你想使用其它的IoU可以直接将Innner_CIoU更改其他的如果都是False则默认适用Inner_IoU即普通版本。<strong><span style="color:#ed7976;">(这里可以使用Focus的思想如果你想使用则在下面的红框内添加Foucs&#61;True即可,Focus一般情况下精度会更高&#xff0c;但也有个别的例外)</span></strong></p> 
<p><img alt="" height="359" src="https://img-blog.csdnimg.cn/22c18495c50347cc8f5ab17d9535d5ec.png" width="1091" /></p> 
<h3 id="7.3%20%E4%BF%AE%E6%94%B9%E4%B8%89">8.3 修改三</h3> 
<p>修改完上面的第二步&#xff0c;我们需要找到如下文件&#34;ultralytics/utils/tal.py&#34;&#xff0c;在这个文件中我们找到如下的代码块&#xff0c;我这里已经修改完了<span style="color:#1c7892;"><strong>(这里不要开启Focus的如果步骤二开启这里也不要开启&#xff0c;同时现在修改了&#xff0c;如果你想要使用inner就设置inner为True&#xff0c;举例如果你使用WIoU&#xff0c;如果不设置inner则此时为WIoU&#xff0c;如果你设置inner为True&#xff0c;那么此时使用的就是inner_WIoU)</strong></span></p> 
<p><img alt="" height="479" src="https://img-blog.csdnimg.cn/81b4d3c028e04a49beb3c84fd8f5e256.png" width="1042" /></p> 
<h2 id="%E5%85%AB%E3%80%81Backbone(%E4%B8%BB%E5%B9%B2)">九、Backbone(主干)</h2> 
<p> 这个主干的网络结构添加起来算是所有的改进机制里最麻烦的了&#xff0c;因为有一些网略结构可以用yaml文件搭建出来&#xff0c;有一些网络结构其中的一些细节根本没有办法用yaml文件去搭建&#xff0c;用yaml文件去搭建会损失一些细节部分(而且一个网络结构设计很多细节的结构修改方式都不一样&#xff0c;一个一个去修改大家难免会出错)&#xff0c;所以这里让网络直接返回整个网络&#xff0c;然后修改部分 yolo代码以后就都以这种形式添加了&#xff0c;以后我提出的网络模型基本上都会通过这种方式修改&#xff0c;我也会进行一些模型细节改进。创新出新的网络结构大家直接拿来用就可以的。<strong>下面开始添加教程-&gt;</strong></p> 
<p><strong>(同时每一个后面都有代码&#xff0c;大家拿来复制粘贴替换即可&#xff0c;但是要看好了不要复制粘贴替换多了)</strong></p> 
<p></p> 
<p><span style="color:#1a439c;"><strong>EfficientViT的网络结构代码 </strong></span></p> 
<pre><code>import torch.nn as nn
import torch
from inspect import signature
from timm.models.efficientvit_mit import val2tuple, ResidualBlock
from torch.cuda.amp import autocast
import torch.nn.functional as F

class LayerNorm2d(nn.LayerNorm):
    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:
        out &#61; x - torch.mean(x, dim&#61;1, keepdim&#61;True)
        out &#61; out / torch.sqrt(torch.square(out).mean(dim&#61;1, keepdim&#61;True) &#43; self.eps)
        if self.elementwise_affine:
            out &#61; out * self.weight.view(1, -1, 1, 1) &#43; self.bias.view(1, -1, 1, 1)
        return out


REGISTERED_NORM_DICT: dict[str, type] &#61; {
    &#34;bn2d&#34;: nn.BatchNorm2d,
    &#34;ln&#34;: nn.LayerNorm,
    &#34;ln2d&#34;: LayerNorm2d,
}

# register activation function here
REGISTERED_ACT_DICT: dict[str, type] &#61; {
    &#34;relu&#34;: nn.ReLU,
    &#34;relu6&#34;: nn.ReLU6,
    &#34;hswish&#34;: nn.Hardswish,
    &#34;silu&#34;: nn.SiLU,
}


class FusedMBConv(nn.Module):
    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        kernel_size&#61;3,
        stride&#61;1,
        mid_channels&#61;None,
        expand_ratio&#61;6,
        groups&#61;1,
        use_bias&#61;False,
        norm&#61;(&#34;bn2d&#34;, &#34;bn2d&#34;),
        act_func&#61;(&#34;relu6&#34;, None),
    ):
        super().__init__()
        use_bias &#61; val2tuple(use_bias, 2)
        norm &#61; val2tuple(norm, 2)
        act_func &#61; val2tuple(act_func, 2)

        mid_channels &#61; mid_channels or round(in_channels * expand_ratio)

        self.spatial_conv &#61; ConvLayer(
            in_channels,
            mid_channels,
            kernel_size,
            stride,
            groups&#61;groups,
            use_bias&#61;use_bias[0],
            norm&#61;norm[0],
            act_func&#61;act_func[0],
        )
        self.point_conv &#61; ConvLayer(
            mid_channels,
            out_channels,
            1,
            use_bias&#61;use_bias[1],
            norm&#61;norm[1],
            act_func&#61;act_func[1],
        )

    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:
        x &#61; self.spatial_conv(x)
        x &#61; self.point_conv(x)
        return x


class DSConv(nn.Module):
    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        kernel_size&#61;3,
        stride&#61;1,
        use_bias&#61;False,
        norm&#61;(&#34;bn2d&#34;, &#34;bn2d&#34;),
        act_func&#61;(&#34;relu6&#34;, None),
    ):
        super(DSConv, self).__init__()

        use_bias &#61; val2tuple(use_bias, 2)
        norm &#61; val2tuple(norm, 2)
        act_func &#61; val2tuple(act_func, 2)

        self.depth_conv &#61; ConvLayer(
            in_channels,
            in_channels,
            kernel_size,
            stride,
            groups&#61;in_channels,
            norm&#61;norm[0],
            act_func&#61;act_func[0],
            use_bias&#61;use_bias[0],
        )
        self.point_conv &#61; ConvLayer(
            in_channels,
            out_channels,
            1,
            norm&#61;norm[1],
            act_func&#61;act_func[1],
            use_bias&#61;use_bias[1],
        )

    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:
        x &#61; self.depth_conv(x)
        x &#61; self.point_conv(x)
        return x


class MBConv(nn.Module):
    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        kernel_size&#61;3,
        stride&#61;1,
        mid_channels&#61;None,
        expand_ratio&#61;6,
        use_bias&#61;False,
        norm&#61;(&#34;bn2d&#34;, &#34;bn2d&#34;, &#34;bn2d&#34;),
        act_func&#61;(&#34;relu6&#34;, &#34;relu6&#34;, None),
    ):
        super(MBConv, self).__init__()

        use_bias &#61; val2tuple(use_bias, 3)
        norm &#61; val2tuple(norm, 3)
        act_func &#61; val2tuple(act_func, 3)
        mid_channels &#61; mid_channels or round(in_channels * expand_ratio)

        self.inverted_conv &#61; ConvLayer(
            in_channels,
            mid_channels,
            1,
            stride&#61;1,
            norm&#61;norm[0],
            act_func&#61;act_func[0],
            use_bias&#61;use_bias[0],
        )
        self.depth_conv &#61; ConvLayer(
            mid_channels,
            mid_channels,
            kernel_size,
            stride&#61;stride,
            groups&#61;mid_channels,
            norm&#61;norm[1],
            act_func&#61;act_func[1],
            use_bias&#61;use_bias[1],
        )
        self.point_conv &#61; ConvLayer(
            mid_channels,
            out_channels,
            1,
            norm&#61;norm[2],
            act_func&#61;act_func[2],
            use_bias&#61;use_bias[2],
        )

    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:
        x &#61; self.inverted_conv(x)
        x &#61; self.depth_conv(x)
        x &#61; self.point_conv(x)
        return x


class EfficientViTBlock(nn.Module):
    def __init__(
        self,
        in_channels: int,
        heads_ratio: float &#61; 1.0,
        dim&#61;32,
        expand_ratio: float &#61; 4,
        norm&#61;&#34;bn2d&#34;,
        act_func&#61;&#34;hswish&#34;,
    ):
        super(EfficientViTBlock, self).__init__()
        self.context_module &#61; ResidualBlock(
            LiteMLA(
                in_channels&#61;in_channels,
                out_channels&#61;in_channels,
                heads_ratio&#61;heads_ratio,
                dim&#61;dim,
                norm&#61;(None, norm),
            ),
            IdentityLayer(),
        )
        local_module &#61; MBConv(
            in_channels&#61;in_channels,
            out_channels&#61;in_channels,
            expand_ratio&#61;expand_ratio,
            use_bias&#61;(True, True, False),
            norm&#61;(None, None, norm),
            act_func&#61;(act_func, act_func, None),
        )
        self.local_module &#61; ResidualBlock(local_module, IdentityLayer())

    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:
        x &#61; self.context_module(x)
        x &#61; self.local_module(x)
        return x

class ResBlock(nn.Module):
    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        kernel_size&#61;3,
        stride&#61;1,
        mid_channels&#61;None,
        expand_ratio&#61;1,
        use_bias&#61;False,
        norm&#61;(&#34;bn2d&#34;, &#34;bn2d&#34;),
        act_func&#61;(&#34;relu6&#34;, None),
    ):
        super().__init__()
        use_bias &#61; val2tuple(use_bias, 2)
        norm &#61; val2tuple(norm, 2)
        act_func &#61; val2tuple(act_func, 2)

        mid_channels &#61; mid_channels or round(in_channels * expand_ratio)

        self.conv1 &#61; ConvLayer(
            in_channels,
            mid_channels,
            kernel_size,
            stride,
            use_bias&#61;use_bias[0],
            norm&#61;norm[0],
            act_func&#61;act_func[0],
        )
        self.conv2 &#61; ConvLayer(
            mid_channels,
            out_channels,
            kernel_size,
            1,
            use_bias&#61;use_bias[1],
            norm&#61;norm[1],
            act_func&#61;act_func[1],
        )

    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:
        x &#61; self.conv1(x)
        x &#61; self.conv2(x)
        return x



class LiteMLA(nn.Module):
    r&#34;&#34;&#34;Lightweight multi-scale linear attention&#34;&#34;&#34;

    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        heads: int or None &#61; None,
        heads_ratio: float &#61; 1.0,
        dim&#61;8,
        use_bias&#61;False,
        norm&#61;(None, &#34;bn2d&#34;),
        act_func&#61;(None, None),
        kernel_func&#61;&#34;relu6&#34;,
        scales: tuple[int, ...] &#61; (5,),
        eps&#61;1.0e-15,
    ):
        super(LiteMLA, self).__init__()
        self.eps &#61; eps
        heads &#61; heads or int(in_channels // dim * heads_ratio)

        total_dim &#61; heads * dim

        use_bias &#61; val2tuple(use_bias, 2)
        norm &#61; val2tuple(norm, 2)
        act_func &#61; val2tuple(act_func, 2)

        self.dim &#61; dim
        self.qkv &#61; ConvLayer(
            in_channels,
            3 * total_dim,
            1,
            use_bias&#61;use_bias[0],
            norm&#61;norm[0],
            act_func&#61;act_func[0],
        )
        self.aggreg &#61; nn.ModuleList(
            [
                nn.Sequential(
                    nn.Conv2d(
                        3 * total_dim,
                        3 * total_dim,
                        scale,
                        padding&#61;get_same_padding(scale),
                        groups&#61;3 * total_dim,
                        bias&#61;use_bias[0],
                    ),
                    nn.Conv2d(3 * total_dim, 3 * total_dim, 1, groups&#61;3 * heads, bias&#61;use_bias[0]),
                )
                for scale in scales
            ]
        )
        self.kernel_func &#61; build_act(kernel_func, inplace&#61;False)

        self.proj &#61; ConvLayer(
            total_dim * (1 &#43; len(scales)),
            out_channels,
            1,
            use_bias&#61;use_bias[1],
            norm&#61;norm[1],
            act_func&#61;act_func[1],
        )

    &#64;autocast(enabled&#61;False)
    def relu_linear_att(self, qkv: torch.Tensor) -&gt; torch.Tensor:
        B, _, H, W &#61; list(qkv.size())

        if qkv.dtype &#61;&#61; torch.float16:
            qkv &#61; qkv.float()

        qkv &#61; torch.reshape(
            qkv,
            (
                B,
                -1,
                3 * self.dim,
                H * W,
            ),
        )
        qkv &#61; torch.transpose(qkv, -1, -2)
        q, k, v &#61; (
            qkv[..., 0 : self.dim],
            qkv[..., self.dim : 2 * self.dim],
            qkv[..., 2 * self.dim :],
        )

        # lightweight linear attention
        q &#61; self.kernel_func(q)
        k &#61; self.kernel_func(k)

        # linear matmul
        trans_k &#61; k.transpose(-1, -2)

        v &#61; F.pad(v, (0, 1), mode&#61;&#34;constant&#34;, value&#61;1)
        kv &#61; torch.matmul(trans_k, v)
        out &#61; torch.matmul(q, kv)
        out &#61; torch.clone(out)
        out &#61; out[..., :-1] / (out[..., -1:] &#43; self.eps)

        out &#61; torch.transpose(out, -1, -2)
        out &#61; torch.reshape(out, (B, -1, H, W))
        return out

    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:
        # generate multi-scale q, k, v
        qkv &#61; self.qkv(x)
        multi_scale_qkv &#61; [qkv]
        device, types &#61; qkv.device, qkv.dtype
        for op in self.aggreg:
            if device.type &#61;&#61; &#39;cuda&#39; and types &#61;&#61; torch.float32:
                qkv &#61; qkv.to(torch.float16)
            x1 &#61; op(qkv)
            multi_scale_qkv.append(x1)
        multi_scale_qkv &#61; torch.cat(multi_scale_qkv, dim&#61;1)
        out &#61; self.relu_linear_att(multi_scale_qkv)
        out &#61; self.proj(out)
        return out

    &#64;staticmethod
    def configure_litemla(model: nn.Module, **kwargs) -&gt; None:
        eps &#61; kwargs.get(&#34;eps&#34;, None)
        for m in model.modules():
            if isinstance(m, LiteMLA):
                if eps is not None:
                    m.eps &#61; eps


def build_kwargs_from_config(config: dict, target_func: callable) -&gt; dict[str, any]:
    valid_keys &#61; list(signature(target_func).parameters)
    kwargs &#61; {}
    for key in config:
        if key in valid_keys:
            kwargs[key] &#61; config[key]
    return kwargs



def build_norm(name&#61;&#34;bn2d&#34;, num_features&#61;None, **kwargs) -&gt; nn.Module or None:
    if name in [&#34;ln&#34;, &#34;ln2d&#34;]:
        kwargs[&#34;normalized_shape&#34;] &#61; num_features
    else:
        kwargs[&#34;num_features&#34;] &#61; num_features
    if name in REGISTERED_NORM_DICT:
        norm_cls &#61; REGISTERED_NORM_DICT[name]
        args &#61; build_kwargs_from_config(kwargs, norm_cls)
        return norm_cls(**args)
    else:
        return None

def get_same_padding(kernel_size: int or tuple[int, ...]) -&gt; int or tuple[int, ...]:
    if isinstance(kernel_size, tuple):
        return tuple([get_same_padding(ks) for ks in kernel_size])
    else:
        assert kernel_size % 2 &gt; 0, &#34;kernel size should be odd number&#34;
        return kernel_size // 2


def build_act(name: str, **kwargs) -&gt; nn.Module or None:
    if name in REGISTERED_ACT_DICT:
        act_cls &#61; REGISTERED_ACT_DICT[name]
        args &#61; build_kwargs_from_config(kwargs, act_cls)
        return act_cls(**args)
    else:
        return None


class ConvLayer(nn.Module):
    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        kernel_size&#61;3,
        stride&#61;1,
        dilation&#61;1,
        groups&#61;1,
        use_bias&#61;False,
        dropout&#61;0,
        norm&#61;&#34;bn2d&#34;,
        act_func&#61;&#34;relu&#34;,
    ):
        super(ConvLayer, self).__init__()

        padding &#61; get_same_padding(kernel_size)
        padding *&#61; dilation

        self.dropout &#61; nn.Dropout2d(dropout, inplace&#61;False) if dropout &gt; 0 else None
        self.conv &#61; nn.Conv2d(
            in_channels,
            out_channels,
            kernel_size&#61;(kernel_size, kernel_size),
            stride&#61;(stride, stride),
            padding&#61;padding,
            dilation&#61;(dilation, dilation),
            groups&#61;groups,
            bias&#61;use_bias,
        )
        self.norm &#61; build_norm(norm, num_features&#61;out_channels)
        self.act &#61; build_act(act_func)

    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:
        if self.dropout is not None:
            x &#61; self.dropout(x)
        device, type &#61; x.device, x.dtype
        choose &#61; False
        if device.type &#61;&#61; &#39;cuda&#39; and type &#61;&#61; torch.float32:
            x &#61; x.to(torch.float16)
            choose &#61; True
        x &#61; self.conv(x)
        if self.norm:
            x &#61; self.norm(x)
        if self.act:
            x &#61; self.act(x)
        if choose:
            x &#61; x.to(torch.float16)
        return x


class IdentityLayer(nn.Module):
    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:
        return x


class OpSequential(nn.Module):
    def __init__(self, op_list: list[nn.Module or None]):
        super(OpSequential, self).__init__()
        valid_op_list &#61; []
        for op in op_list:
            if op is not None:
                valid_op_list.append(op)
        self.op_list &#61; nn.ModuleList(valid_op_list)

    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:
        for op in self.op_list:
            x &#61; op(x)
        return x



class EfficientViTBackbone(nn.Module):
    def __init__(
        self,
        width_list: list[int],
        depth_list: list[int],
        in_channels&#61;3,
        dim&#61;32,
        expand_ratio&#61;4,
        norm&#61;&#34;ln2d&#34;,
        act_func&#61;&#34;hswish&#34;,
    ) -&gt; None:
        super().__init__()

        self.width_list &#61; []
        # input stem
        self.input_stem &#61; [
            ConvLayer(
                in_channels&#61;3,
                out_channels&#61;width_list[0],
                stride&#61;2,
                norm&#61;norm,
                act_func&#61;act_func,
            )
        ]
        for _ in range(depth_list[0]):
            block &#61; self.build_local_block(
                in_channels&#61;width_list[0],
                out_channels&#61;width_list[0],
                stride&#61;1,
                expand_ratio&#61;1,
                norm&#61;norm,
                act_func&#61;act_func,
            )
            self.input_stem.append(ResidualBlock(block, IdentityLayer()))
        in_channels &#61; width_list[0]
        self.input_stem &#61; OpSequential(self.input_stem)
        self.width_list.append(in_channels)

        # stages
        self.stages &#61; []
        for w, d in zip(width_list[1:3], depth_list[1:3]):
            stage &#61; []
            for i in range(d):
                stride &#61; 2 if i &#61;&#61; 0 else 1
                block &#61; self.build_local_block(
                    in_channels&#61;in_channels,
                    out_channels&#61;w,
                    stride&#61;stride,
                    expand_ratio&#61;expand_ratio,
                    norm&#61;norm,
                    act_func&#61;act_func,
                )
                block &#61; ResidualBlock(block, IdentityLayer() if stride &#61;&#61; 1 else None)
                stage.append(block)
                in_channels &#61; w
            self.stages.append(OpSequential(stage))
            self.width_list.append(in_channels)

        for w, d in zip(width_list[3:], depth_list[3:]):
            stage &#61; []
            block &#61; self.build_local_block(
                in_channels&#61;in_channels,
                out_channels&#61;w,
                stride&#61;2,
                expand_ratio&#61;expand_ratio,
                norm&#61;norm,
                act_func&#61;act_func,
                fewer_norm&#61;True,
            )
            stage.append(ResidualBlock(block, None))
            in_channels &#61; w

            for _ in range(d):
                stage.append(
                    EfficientViTBlock(
                        in_channels&#61;in_channels,
                        dim&#61;dim,
                        expand_ratio&#61;expand_ratio,
                        norm&#61;norm,
                        act_func&#61;act_func,
                    )
                )
            self.stages.append(OpSequential(stage))
            self.width_list.append(in_channels)
        self.stages &#61; nn.ModuleList(self.stages)

    &#64;staticmethod
    def build_local_block(
        in_channels: int,
        out_channels: int,
        stride: int,
        expand_ratio: float,
        norm: str,
        act_func: str,
        fewer_norm: bool &#61; False,
    ) -&gt; nn.Module:
        if expand_ratio &#61;&#61; 1:
            block &#61; DSConv(
                in_channels&#61;in_channels,
                out_channels&#61;out_channels,
                stride&#61;stride,
                use_bias&#61;(True, False) if fewer_norm else False,
                norm&#61;(None, norm) if fewer_norm else norm,
                act_func&#61;(act_func, None),
            )
        else:
            block &#61; MBConv(
                in_channels&#61;in_channels,
                out_channels&#61;out_channels,
                stride&#61;stride,
                expand_ratio&#61;expand_ratio,
                use_bias&#61;(True, True, False) if fewer_norm else False,
                norm&#61;(None, None, norm) if fewer_norm else norm,
                act_func&#61;(act_func, act_func, None),
            )
        return block

    def forward(self, x: torch.Tensor) -&gt; dict[str, torch.Tensor]:
        outputs &#61; []
        for stage_id, stage in enumerate(self.stages):
            x &#61; stage(x)
            if x.device.type &#61;&#61; &#39;cuda&#39;:
                x &#61; x.to(torch.float16)
            outputs.append(x)
        return outputs


def efficientvit_backbone_b0(**kwargs) -&gt; EfficientViTBackbone:
    backbone &#61; EfficientViTBackbone(
        width_list&#61;[3, 16, 32, 64, 128],
        depth_list&#61;[1, 2, 2, 2, 2],
        dim&#61;16,
        **build_kwargs_from_config(kwargs, EfficientViTBackbone),
    )
    return backbone

def efficientvit_backbone_b1(**kwargs) -&gt; EfficientViTBackbone:
    backbone &#61; EfficientViTBackbone(
        width_list&#61;[3, 32, 64, 128, 256],
        depth_list&#61;[1, 2, 3, 3, 4],
        dim&#61;16,
        **build_kwargs_from_config(kwargs, EfficientViTBackbone),
    )
    return backbone


def efficientvit_backbone_b2(**kwargs) -&gt; EfficientViTBackbone:
    backbone &#61; EfficientViTBackbone(
        width_list&#61;[3, 48, 96, 192, 384],
        depth_list&#61;[1, 3, 4, 4, 6],
        dim&#61;32,
        **build_kwargs_from_config(kwargs, EfficientViTBackbone),
    )
    return backbone


def efficientvit_backbone_b3(**kwargs) -&gt; EfficientViTBackbone:
    backbone &#61; EfficientViTBackbone(
        width_list&#61;[3, 64, 128, 256, 512],
        depth_list&#61;[1, 4, 6, 6, 9],
        dim&#61;32,
        **build_kwargs_from_config(kwargs, EfficientViTBackbone),
    )
    return backbone
</code></pre> 
<p></p> 
<hr /> 
<h3 id="%E4%BF%AE%E6%94%B9%E4%B8%80">修改一</h3> 
<p>我们复制网络结构代码到“ultralytics/nn/modules”目录下创建一个py文件复制粘贴进去 &#xff0c;我这里起的名字是EfficientV2。</p> 
<p class="img-center"><img alt="" height="414" src="https://img-blog.csdnimg.cn/direct/46343640e06a4dcba3cc3536b1f44d9f.png" width="367" /></p> 
<p></p> 
<hr /> 
<h3 id="%E4%BF%AE%E6%94%B9%E4%BA%8C">修改二</h3> 
<p>找到如下的文件&#34;ultralytics/nn/tasks.py&#34; 在开始的部分导入我们的模型如下图。</p> 
<p><img alt="" height="212" src="https://img-blog.csdnimg.cn/direct/026f4c06acf14e6f94d01c71216738db.png" width="1200" /></p> 
<pre><code>from .modules.EfficientV2 import efficientvit_backbone_b0,efficientvit_backbone_b1,efficientvit_backbone_b2,efficientvit_backbone_b3</code></pre> 
<p></p> 
<hr /> 
<h3 id="%E4%BF%AE%E6%94%B9%E4%B8%89%C2%A0">修改三 </h3> 
<p><strong>添加如下两行代码&#xff01;&#xff01;&#xff01;</strong></p> 
<p class="img-center"><img alt="" height="261" src="https://img-blog.csdnimg.cn/direct/1655de23b1834dfca4f304336f0f2c19.png" width="867" /></p> 
<p></p> 
<hr /> 
<h3 id="%E4%BF%AE%E6%94%B9%E5%9B%9B">修改四</h3> 
<p>找到七百多行大概把具体看图片&#xff0c;按照图片来修改就行&#xff0c;添加红框内的部分&#xff0c;注意没有()只是函数名。</p> 
<p><img alt="" height="523" src="https://img-blog.csdnimg.cn/direct/c1dde522a44248d9bea5d7c8b311b326.png" width="1146" /></p> 
<pre><code>        elif m in {efficientvit_backbone_b0, efficientvit_backbone_b1, efficientvit_backbone_b2, efficientvit_backbone_b3}:
            m &#61; m()
            c2 &#61; m.width_list  # 返回通道列表
            backbone &#61; True</code></pre> 
<p></p> 
<hr /> 
<h3 id="%E4%BF%AE%E6%94%B9%E4%BA%94%C2%A0">修改五 </h3> 
<p>下面的两个红框内都是需要改动的。 </p> 
<p><img alt="" height="223" src="https://img-blog.csdnimg.cn/direct/6437a57f982c4388a83b7be05cf64448.png" width="968" /></p> 
<pre><code>        if isinstance(c2, list):
            m_ &#61; m
            m_.backbone &#61; True
        else:
            m_ &#61; nn.Sequential(*(m(*args) for _ in range(n))) if n &gt; 1 else m(*args)  # module
            t &#61; str(m)[8:-2].replace(&#39;__main__.&#39;, &#39;&#39;)  # module type


        m.np &#61; sum(x.numel() for x in m_.parameters())  # number params
        m_.i, m_.f, m_.type &#61; i &#43; 4 if backbone else i, f, t  # attach index, &#39;from&#39; index, type</code></pre> 
<p></p> 
<hr /> 
<h3 id="%E4%BF%AE%E6%94%B9%E5%85%AD%C2%A0">修改六 </h3> 
<p>如下的也需要修改&#xff0c;全部按照我的来。</p> 
<p><img alt="" height="248" src="https://img-blog.csdnimg.cn/direct/7b6a03061e7e4846b51bc282e88bead8.png" width="1142" /></p> 
<p>代码如下把原先的代码替换了即可。 </p> 
<pre><code>        save.extend(x % (i &#43; 4 if backbone else i) for x in ([f] if isinstance(f, int) else f) if x !&#61; -1)  # append to savelist
        layers.append(m_)
        if i &#61;&#61; 0:
            ch &#61; []
        if isinstance(c2, list):
            ch.extend(c2)
            if len(c2) !&#61; 5:
                ch.insert(0, 0)
        else:
            ch.append(c2)</code></pre> 
<p></p> 
<hr /> 
<h3 id="%E4%BF%AE%E6%94%B9%E4%B8%83">修改七</h3> 
<p>修改七和前面的都不太一样&#xff0c;需要修改前向传播中的一个部分&#xff0c; 已经离开了parse_model方法了。</p> 
<p>可以在图片中开代码行数&#xff0c;没有离开task.py文件都是同一个文件。 同时这个部分有好几个前向传播都很相似&#xff0c;大家不要看错了&#xff0c;<strong>是70多行左右的&#xff01;&#xff01;&#xff01;&#xff0c;同时我后面提供了代码&#xff0c;大家直接复制粘贴即可&#xff0c;有时间我针对这里会出一个视频。</strong></p> 
<p class="img-center"><img alt="" height="751" src="https://img-blog.csdnimg.cn/direct/c2ad3781e93f4f01ac1cfab9b90ed1bb.png" width="1200" /></p> 
<p><strong>代码如下-&gt;</strong></p> 
<pre><code>    def _predict_once(self, x, profile&#61;False, visualize&#61;False):
        &#34;&#34;&#34;
        Perform a forward pass through the network.

        Args:
            x (torch.Tensor): The input tensor to the model.
            profile (bool):  Print the computation time of each layer if True, defaults to False.
            visualize (bool): Save the feature maps of the model if True, defaults to False.

        Returns:
            (torch.Tensor): The last output of the model.
        &#34;&#34;&#34;
        y, dt &#61; [], []  # outputs
        for m in self.model:
            if m.f !&#61; -1:  # if not from previous layer
                x &#61; y[m.f] if isinstance(m.f, int) else [x if j &#61;&#61; -1 else y[j] for j in m.f]  # from earlier layers
            if profile:
                self._profile_one_layer(m, x, dt)
            if hasattr(m, &#39;backbone&#39;):
                x &#61; m(x)
                if len(x) !&#61; 5: # 0 - 5
                    x.insert(0, None)
                for index, i in enumerate(x):
                    if index in self.save:
                        y.append(i)
                    else:
                        y.append(None)
                x &#61; x[-1] # 最后一个输出传给下一层
            else:
                x &#61; m(x)  # run
                y.append(x if m.i in self.save else None)  # save output
            if visualize:
                feature_visualization(x, m.type, m.i, save_dir&#61;visualize)
        return x</code></pre> 
<p></p> 
<hr /> 
<h3 id="%E4%BF%AE%E6%94%B9%E5%85%AB">修改八</h3> 
<p>需要额外修改一处&#xff0c; 我们找到如下文件&#39;ultralytics/utils/torch_utils.py&#39;按照如下的图片进行修改。</p> 
<p class="img-center"><img alt="" height="288" src="https://img-blog.csdnimg.cn/direct/24068f6039b94ceeb91e98642c00e594.png" width="1095" /></p> 
<p>到这里就完成了修改部分&#xff0c;但是这里面细节很多&#xff0c;大家千万要注意不要替换多余的代码&#xff0c;导致报错&#xff0c;也不要拉下任何一步&#xff0c;都会导致运行失败&#xff0c;而且报错很难排查&#xff01;&#xff01;&#xff01;很难排查&#xff01;&#xff01;&#xff01; </p> 
<p></p> 
<h3 id="%E4%BA%94%E3%80%81EfficientViT2023yaml%E6%96%87%E4%BB%B6">修改九</h3> 
<p><strong>复制如下yaml文件进行运行&#xff01;&#xff01;&#xff01; </strong></p> 
<pre><code># Ultralytics YOLO &#x1f680;, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 80  # number of classes
scales: # model compound scaling constants, i.e. &#39;model&#61;yolov8n.yaml&#39; will call yolov8.yaml with scale &#39;n&#39;
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [0.33, 0.50, 1024]  # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs
  m: [0.67, 0.75, 768]   # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs
  l: [1.00, 1.00, 512]   # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  x: [1.00, 1.25, 512]   # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs

# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, efficientvit_backbone_b0, []]  # 4
  - [-1, 1, SPPF, [1024, 5]]  # 5

# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, &#39;nearest&#39;]] # 6
  - [[-1, 3], 1, Concat, [1]]  # 7 cat backbone P4
  - [-1, 3, C2f, [512]]  # 8

  - [-1, 1, nn.Upsample, [None, 2, &#39;nearest&#39;]] # 9
  - [[-1, 2], 1, Concat, [1]]  # 10 cat backbone P3
  - [-1, 3, C2f, [256]]  # 11 (P3/8-small)

  - [-1, 1, Conv, [256, 3, 2]] # 12
  - [[-1, 8], 1, Concat, [1]]  # 13 cat head P4
  - [-1, 3, C2f, [512]]  # 14 (P4/16-medium)

  - [-1, 1, Conv, [512, 3, 2]] # 15
  - [[-1, 5], 1, Concat, [1]]  # 16 cat head P5
  - [-1, 3, C2f, [1024]]  # 17 (P5/32-large)

  - [[11, 14, 17], 1, Detect, [nc]]  # Detect(P3, P4, P5)
</code></pre> 
<h2 id="%E5%85%AD%E3%80%81%E6%9C%AC%E6%96%87%E6%80%BB%E7%BB%93">十、本文总结</h2> 
<p>到此本文的正式分享内容就结束了&#xff0c;在这里给大家推荐我的YOLOv8改进有效涨点专栏&#xff0c;本专栏目前为新开的平均质量分98分&#xff0c;后期我会根据各种最新的前沿顶会进行论文复现&#xff0c;也会对一些老的改进机制进行补充&#xff0c;<span style="color:#fe2c24;"><strong>目前本专栏免费阅读(暂时&#xff0c;大家尽早关注不迷路~)</strong></span>&#xff0c;如果大家觉得本文帮助到你了&#xff0c;订阅本专栏&#xff0c;关注后续更多的更新~</p> 
<blockquote> 
 <p><strong><span style="color:#fe2c24;">专栏回顾&#xff1a;</span></strong></p> 
</blockquote>
                </div>
        </div>
        <div id="treeSkill"></div>
        <div id="blogExtensionBox" style="width:400px;margin:auto;margin-top:12px" class="blog-extension-box"></div>
    </article>
<script>
  $(function() {
    setTimeout(function () {
      var mathcodeList = document.querySelectorAll('.htmledit_views img.mathcode');
      if (mathcodeList.length > 0) {
        for (let i = 0; i < mathcodeList.length; i++) {
          if (mathcodeList[i].naturalWidth === 0 || mathcodeList[i].naturalHeight === 0) {
            var alt = mathcodeList[i].alt;
            alt = '\\(' + alt + '\\)';
            var curSpan = $('<span class="img-codecogs"></span>');
            curSpan.text(alt);
            $(mathcodeList[i]).before(curSpan);
            $(mathcodeList[i]).remove();
          }
        }
        MathJax.Hub.Queue(["Typeset",MathJax.Hub]);
      }
    }, 1000)
  });
</script>
</div>
<div class="directory-boxshadow-dialog" style="display:none;">
  <div class="directory-boxshadow-dialog-box">
  </div>
  <div class="vip-limited-time-offer-box">
    <div class="vip-limited-time-offer-content">
      <img class="limited-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/vip-limited-close.png">
      <div class="limited-box">
        <span class="limited-num"></span>
        <span class="limited-quan"> 优惠劵</span>
      </div>
      <div class="limited-time-box">
        <span class="time-hour"></span>
        <span class="time-minite"></span>
        <span class="time-second"></span>
      </div>
      <a class="limited-time-btn" href="https://mall.csdn.net/vip" data-report-click='{"spm":"1001.2101.3001.9621"}' data-report-query='spm=1001.2101.3001.9621'></a>
    </div>
  </div>
</div>    <div class="more-toolbox-new" id="toolBarBox">
      <div class="left-toolbox">
        <div class="toolbox-left">
            <div class="profile-box">
              <a class="profile-href" target="_blank" href="https://snu77.blog.csdn.net"><img class="profile-img" src="https://profile-avatar.csdnimg.cn/27160f4941a54d07b535ceabcfa4a800_java1314777.jpg!1">
                <span class="profile-name">
                  Snu77
                </span>
              </a>
            </div>
            <div class="profile-attend">
              
                <a class="tool-attend tool-bt-button tool-unbt-attend" href="javascript:;" data-report-view='{"mod":"1592215036_002","spm":"1001.2101.3001.4232","extend1":"已关注"}'>已关注</a>
              <a class="tool-item-follow active-animation" style="display:none;">关注</a>
            </div>
        </div>
        <div class="toolbox-middle">
          <ul class="toolbox-list">
            <li class="tool-item tool-item-size tool-active is-like" id="is-like">
              <a class="tool-item-href">
                <img style="display:none;" id="is-like-imgactive-animation-like" class="animation-dom active-animation" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarThumbUpactive.png" alt="">
                <img class="isactive" style="display:none" id="is-like-imgactive" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newHeart2021Active.png" alt="">
                <img class="isdefault" style="display:block" id="is-like-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newHeart2021Black.png" alt="">
                <span id="spanCount" class="count ">
                    78
                </span>
              </a>
              <div class="tool-hover-tip"><span class="text space">点赞</span></div>
            </li>
            <li class="tool-item tool-item-size tool-active is-unlike" id="is-unlike">
              <a class="tool-item-href">
                <img class="isactive" style="margin-right:0px;display:none" id="is-unlike-imgactive" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newUnHeart2021Active.png" alt="">
                <img class="isdefault" style="margin-right:0px;display:block" id="is-unlike-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newUnHeart2021Black.png" alt="">
                <span id="unlikeCount" class="count "></span>
              </a>
              <div class="tool-hover-tip"><span class="text space">踩</span></div>
            </li>
            <li class="tool-item tool-item-size tool-active is-collection ">
              <a class="tool-item-href" href="javascript:;" data-report-click='{"mod":"popu_824","spm":"1001.2101.3001.4130","ab":"new"}'>
                <img style="display:none" id="is-collection-img-collection" class="animation-dom active-animation" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarCollectionActive.png" alt="">
                <img class="isdefault" id="is-collection-img" style="display:block" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCollectBlack.png" alt="">
                <img class="isactive" id="is-collection-imgactive" style="display:none" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCollectActive.png" alt="">
                <span class="count get-collection " data-num="168" id="get-collection">
                    168
                </span>
              </a>
              <div class="tool-hover-tip collect">
                <div class="collect-operate-box">
                  <span class="collect-text" id="is-collection">
                    收藏
                  </span>
                </div>
              </div>
              <div class="tool-active-list">
                <div class="text">
                  觉得还不错?
                  <span class="collect-text" id="tool-active-list-collection">
                    一键收藏
                  </span>
                 <img id="tool-active-list-close" src="https://csdnimg.cn/release/blogv2/dist/pc/img/collectionCloseBlack.png" alt="">
                </div>
              </div>
            </li>
                <li class="tool-item tool-item-size tool-active tool-item-reward">
                  <a class="tool-item-href" href="javascript:;" data-report-click='{"mod":"popu_830","spm":"1001.2101.3001.4237","dest":"","ab":"new"}'>
                    <img class="isdefault reward-bt" id="rewardBtNew" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newRewardBlack.png" alt="打赏">
                    <span class="count"></span>
                  </a>
                  <div class="tool-hover-tip"><span class="text space">打赏</span></div>
                </li>
          <li class="tool-item tool-item-size tool-active tool-item-comment">
            <div class="guide-rr-first">
              <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/guideRedReward01.png" alt="">
              <button class="btn-guide-known">知道了</button>
            </div>
              <a class="tool-item-href go-side-comment" data-report-click='{"spm":"1001.2101.3001.7009"}'>
              <img class="isdefault" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newComment2021Black.png" alt="">
              <span class="count">
                  79
              </span>
            </a>
            <div class="tool-hover-tip"><span class="text space">评论</span></div>
          </li>
          <li class="tool-item tool-item-bar">
          </li>
          <li class="tool-item tool-item-size tool-active tool-QRcode" data-type="article" id="tool-share">
            <a class="tool-item-href" href="javascript:;" data-report-click='{"mod":"1582594662_002","spm":"1001.2101.3001.4129","ab":"new"}'>
              <img class="isdefault" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newShareBlack.png" alt="">
            </a>
              <div class="QRcode" id="tool-QRcode">
            <div class="share-bg-icon icon1" id="shareBgIcon"></div>
              <div class="share-bg-box">
                <div class="share-content">
                    <img class="share-avatar" src="https://profile-avatar.csdnimg.cn/27160f4941a54d07b535ceabcfa4a800_java1314777.jpg!1" alt="">
                  <div class="share-tit">
                    YOLOv8改进 | 如何在网络结构中添加注意力机制、C2f、卷积、Neck、检测头
                  </div>
                  <div class="share-dec">
                    本篇文章的内容是在大家得到一个改进版本的C2f一个新的注意力机制、或者一个新的卷积模块、或者是检测头的时候如何替换我们YOLOv8模型中的原有的模块，从而用你的模块去进行训练模型或者检测。因为最近开了一个专栏里面涉及到挺多改进的地方，不能每篇文章都去讲解一遍如何修改，就想着在这里单独出一期文章进行一个总结性教程大家可以从我的其它文章中拿到修改后的代码，从这篇文章学会如何去添加到你的模型结构中去。YOLOv8改进有效涨点专栏-&gt;持续复现各种最新机制本文的讲解举例都以最新的YOLOv8。
                  </div>
                  <a id="copyPosterUrl" class="url" data-report-click='{"spm":"1001.2101.3001.7493"}' data-report-view='{"spm":"1001.2101.3001.7493"}'>复制链接</a>
                </div>
                <div class="share-code">
                  <div class="share-code-box" id='shareCode'></div>
                  <div class="share-code-text">扫一扫</div>
                </div>
              </div>
                <div class="share-code-type">
                </div>
            </div>
          </li>
        </ul>
      </div>
      <div class="toolbox-right">
            <div class="tool-directory">
                <a class="bt-columnlist-show"
                  data-id="12483754"
                  data-free="false"
                  data-subscribe="true"
                  data-title="YOLOv8有效涨点专栏"
                  data-img="https://img-blog.csdnimg.cn/direct/d0d498bd4f0c4e17b48ff54e86b67668.png?x-oss-process=image/resize,m_fixed,h_224,w_224"
                  data-url="https://blog.csdn.net/java1314777/category_12483754.html"
                  data-sum="125"
                  data-people="341"
                  data-price="199.90"
                  data-hotRank="1"
                  data-status="true"
                  data-oldprice="99.00"
                  data-join="false"
                  data-studyvip="false"
                  data-studysubscribe="false"
                  data-report-view='{"spm":"1001.2101.3001.6334","extend1":"专栏目录"}'
                  data-report-click='{"spm":"1001.2101.3001.6334","extend1":"专栏目录"}'>专栏目录</a>
          </div>
                <div class="tool-column">
                    <a class="tool-bt-button tool-unbt-subscribe" href="javascript:;" data-report-view='{"mod":"1592215036_001","spm":"1001.2101.3001.4405","extend1":"已订阅"}' data-report-click='{"mod":"1592215036_001","spm":"1001.2101.3001.4405","extend1":"已订阅"}'>已订阅</a>
                </div>
</div>
</div>
</div>
<script type=text/javascript crossorigin src="https://csdnimg.cn/release/phoenix/production/qrcode-7c90a92189.min.js"></script>
<script src="//g.csdnimg.cn/??sharewx/1.2.1/sharewx.js" type="text/javascript"></script>
<script type="text/javascript" crossorigin src="https://g.csdnimg.cn/common/csdn-login-box/csdn-login-box.js"></script>
<script type="text/javascript" crossorigin src="https://g.csdnimg.cn/collection-box/2.1.2/collection-box.js"></script>                <div class="first-recommend-box recommend-box ">
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/qq_44224801/article/details/130059070"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6661.1","mod":"popu_871","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~PayColumn-1-130059070-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"1","strategy":"2~default~CTRLIST~PayColumn","dest":"https://blog.csdn.net/qq_44224801/article/details/130059070"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/qq_44224801/article/details/130059070" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6661.1","mod":"popu_871","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~PayColumn-1-130059070-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"1","strategy":"2~default~CTRLIST~PayColumn","dest":"https://blog.csdn.net/qq_44224801/article/details/130059070"}'  data-report-query='spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7EPayColumn-1-130059070-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7EPayColumn-1-130059070-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>改进</em><em>YOLO</em>系列：<em>改进</em><em>YOLO</em><em>v8</em>，教你<em>YOLO</em><em>v8</em>如何<em>添加</em>20多种<em>注意力机制</em>，并实验不同位置。</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/qq_44224801" target="_blank"><span class="blog-title">qq_44224801的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">04-10</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					3万+
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/qq_44224801/article/details/130059070" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6661.1","mod":"popu_871","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~PayColumn-1-130059070-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"1","strategy":"2~default~CTRLIST~PayColumn","dest":"https://blog.csdn.net/qq_44224801/article/details/130059070"}'  data-report-query='spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7EPayColumn-1-130059070-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7EPayColumn-1-130059070-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1"><em>注意力机制</em>（Attention Mechanism）是<em>深度学习</em><em>中</em>一种重要的技术，它可以帮助模型更好地关注输入数据<em>中</em>的关键信息，从而提高模型的性能。<em>注意力机制</em>最早在自然语言处理领域的序列到序列（seq2seq）模型<em>中</em>得到广泛应用，后来逐渐扩展到了计算机视觉、语音识别等多个领域。<em>注意力机制</em>的基本思想是为输入数据的每个部分分配一个权重，这个权重表示该部分对于当前任务的重要程度。</div>
			</a>
		</div>
	</div>
</div>
                </div>
              <script src="https://csdnimg.cn/release/blogv2/dist/components/js/pc_wap_commontools-094b8ec121.min.js" type="text/javascript" async></script>
                <div class="second-recommend-box recommend-box ">
<div class="recommend-item-box type_download clearfix" data-url="https://download.csdn.net/download/jiebing2020/24632600"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.1","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~Paid-1-24632600-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"1","strategy":"2~default~CTRLIST~Paid","dest":"https://download.csdn.net/download/jiebing2020/24632600"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://download.csdn.net/download/jiebing2020/24632600" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.1","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~Paid-1-24632600-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"1","strategy":"2~default~CTRLIST~Paid","dest":"https://download.csdn.net/download/jiebing2020/24632600"}'  data-report-query='spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7EPaid-1-24632600-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7EPaid-1-24632600-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>添加</em><em>注意力机制</em>的<em>卷积</em>神经网络在安全帽佩戴<em>检测</em>的应用.pdf</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info display-flex">
					<span class="info-block">09-25</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://download.csdn.net/download/jiebing2020/24632600" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.1","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~Paid-1-24632600-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"1","strategy":"2~default~CTRLIST~Paid","dest":"https://download.csdn.net/download/jiebing2020/24632600"}'  data-report-query='spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7EPaid-1-24632600-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7EPaid-1-24632600-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1"><em>添加</em><em>注意力机制</em>的<em>卷积</em>神经网络在安全帽佩戴<em>检测</em>的应用.pdf</div>
			</a>
		</div>
	</div>
</div>
                </div>
<a id="commentBox" name="commentBox"></a>
  <div id="pcCommentBox" class="comment-box comment-box-new2 login-comment-box-new" style="display:none">
      <div class="has-comment" style="display:block">
        <div class="one-line-box">
          <div class="has-comment-tit go-side-comment">
            <span class="count">79</span>&nbsp;条评论
          </div>
          <div class="has-comment-con comment-operate-item"></div>
          <a class="has-comment-bt-right go-side-comment focus">写评论</a>
        </div>
      </div>
  </div>
              <div class="recommend-box insert-baidu-box recommend-box-style ">
                <div class="recommend-item-box no-index" style="display:none"></div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/weixin_46106870/article/details/134768925"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.2","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-2-134768925-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"2","strategy":"2~default~CTRLIST~Rate","dest":"https://blog.csdn.net/weixin_46106870/article/details/134768925"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/weixin_46106870/article/details/134768925" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.2","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-2-134768925-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"2","strategy":"2~default~CTRLIST~Rate","dest":"https://blog.csdn.net/weixin_46106870/article/details/134768925"}'  data-report-query='spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-2-134768925-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-2-134768925-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>YOLO</em><em>v8</em>创新魔改教程（二）如何<em>添加</em><em>注意力机制</em></div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/weixin_46106870" target="_blank"><span class="blog-title">weixin_46106870的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">12-03</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					576
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/weixin_46106870/article/details/134768925" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.2","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-2-134768925-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"2","strategy":"2~default~CTRLIST~Rate","dest":"https://blog.csdn.net/weixin_46106870/article/details/134768925"}'  data-report-query='spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-2-134768925-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-2-134768925-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">本文讲述了如何<em>添加</em><em>注意力机制</em></div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://snu77.blog.csdn.net/article/details/135309007"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.3","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~YuanLiJiHua~Position-3-135309007-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"3","strategy":"2~default~YuanLiJiHua~Position","dest":"https://snu77.blog.csdn.net/article/details/135309007"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://snu77.blog.csdn.net/article/details/135309007" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.3","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~YuanLiJiHua~Position-3-135309007-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"3","strategy":"2~default~YuanLiJiHua~Position","dest":"https://snu77.blog.csdn.net/article/details/135309007"}'  data-report-query='spm=1001.2101.3001.6650.3&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EYuanLiJiHua%7EPosition-3-135309007-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EYuanLiJiHua%7EPosition-3-135309007-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>YOLO</em><em>v8</em><em>改进</em>有效系列目录 | 包含<em>卷积</em>、主干、<em>检测</em><em>头</em>、<em>注意力机制</em>、<em>Neck</em>上百种创新机制</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/java1314777" target="_blank"><span class="blog-title">Snu77的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">12-30</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					1万+
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://snu77.blog.csdn.net/article/details/135309007" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.3","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~YuanLiJiHua~Position-3-135309007-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"3","strategy":"2~default~YuanLiJiHua~Position","dest":"https://snu77.blog.csdn.net/article/details/135309007"}'  data-report-query='spm=1001.2101.3001.6650.3&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EYuanLiJiHua%7EPosition-3-135309007-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EYuanLiJiHua%7EPosition-3-135309007-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">Hello，各位读者们好，本专栏自开设两个月以来已经更新<em>改进</em>教程120+余篇其<em>中</em>包含<em>C2f</em>、主干、<em>检测</em><em>头</em>、<em>注意力机制</em>、<em>Neck</em>多种结构上创新，也有<em>损失函数</em>和一些细节点上的创新，订阅本专栏以后你不仅可以收获跟专栏的阅读权限，同时可以进Qq群，里面包含集成我所有创新的<em>YOLO</em>最新目录，和我本人录制的视频讲解教程，如果你想要在<em>YOLO</em><em>v8</em>系列收获一篇论文，我相信订阅本专栏后你一定会有所收获~<em>YOLO</em><em>v8</em><em>改进</em>有效系列目录。</div>
			</a>
		</div>
	</div>
</div>
		<dl id="recommend-item-box-tow" class="recommend-item-box type_blog clearfix">
			
		</dl>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/weixin_43722052/article/details/134116589"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.4","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-4-134116589-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"4","strategy":"2~default~CTRLIST~Rate","dest":"https://blog.csdn.net/weixin_43722052/article/details/134116589"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/weixin_43722052/article/details/134116589" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.4","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-4-134116589-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"4","strategy":"2~default~CTRLIST~Rate","dest":"https://blog.csdn.net/weixin_43722052/article/details/134116589"}'  data-report-query='spm=1001.2101.3001.6650.4&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-134116589-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-134116589-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>YOLO</em><em>v8</em><em>修改</em>一个<em>模块</em>需要<em>修改</em>哪些代码？</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/weixin_43722052" target="_blank"><span class="blog-title">毕竟是Shy哥</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">10-30</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					192
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/weixin_43722052/article/details/134116589" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.4","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-4-134116589-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"4","strategy":"2~default~CTRLIST~Rate","dest":"https://blog.csdn.net/weixin_43722052/article/details/134116589"}'  data-report-query='spm=1001.2101.3001.6650.4&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-134116589-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-134116589-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">5、找到解析<em>模块</em>，如果<em>模块</em>需要重复，放在第一个if里面。3、在同级的init.py<em>添加</em><em>模块</em>名字，两个地方。2、把你类的名字<em>添加</em>到block.py上面。4、在tasks.py文件<em>添加</em><em>模块</em>名。1、建议<em>添加</em>到block.py里。6、注意对应通道数啥的，然后<em>添加</em>。</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://snu77.blog.csdn.net/article/details/134432299"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.5","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-5-134432299-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"5","strategy":"2~default~CTRLIST~Rate","dest":"https://snu77.blog.csdn.net/article/details/134432299"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://snu77.blog.csdn.net/article/details/134432299" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.5","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-5-134432299-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"5","strategy":"2~default~CTRLIST~Rate","dest":"https://snu77.blog.csdn.net/article/details/134432299"}'  data-report-query='spm=1001.2101.3001.6650.5&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-5-134432299-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-5-134432299-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>YOLO</em><em>v8</em><em>改进</em> | ODConv<em>卷积</em>助力极限涨点（附<em>修改</em>后的<em>C2f</em>、Bottle<em>neck</em><em>模块</em>代码）</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/java1314777" target="_blank"><span class="blog-title">Snu77的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">11-16</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					2789
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://snu77.blog.csdn.net/article/details/134432299" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.5","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-5-134432299-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"5","strategy":"2~default~CTRLIST~Rate","dest":"https://snu77.blog.csdn.net/article/details/134432299"}'  data-report-query='spm=1001.2101.3001.6650.5&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-5-134432299-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-5-134432299-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">这篇文章给大家带来的是发表于2022年ICLR的ODConv<em>中</em>文名字全维度动态<em>卷积</em>，该<em>卷积</em>可以即插即用，可以直接替换<em>网络结构</em><em>中</em>的任何一个<em>卷积</em><em>模块</em>，在本文的末尾提供可以直接替换<em>卷积</em><em>模块</em>的ODConv，<em>添加</em>ODConv<em>模块</em>的<em>C2f</em>和Bottle<em>neck</em>(配合教程将代码复制粘贴到你自己的代码<em>中</em>即可运行)给大家该<em>卷积</em><em>模块</em>主要具有更小的计算量和更高的精度，其<em>中</em><em>添加</em>ODConv<em>模块</em>的网络(只替换了一处<em>C2f</em><em>中</em>的<em>卷积</em>)参数量由8.9GFLOPS减小到8.8GFLOPS，精度也有提高-&gt;</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://cv2023.blog.csdn.net/article/details/133563710"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.6","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-6-133563710-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"6","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://cv2023.blog.csdn.net/article/details/133563710"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://cv2023.blog.csdn.net/article/details/133563710" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.6","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-6-133563710-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"6","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://cv2023.blog.csdn.net/article/details/133563710"}'  data-report-query='spm=1001.2101.3001.6650.6&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-6-133563710-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-6-133563710-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>YOLO</em><em>v8</em>轻量化模型：PConv结合<em>C2f</em> | CVPR2023</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/m0_63774211" target="_blank"><span class="blog-title">各专栏持续更新中，改进创新YOLO，适用v5、v7、v8，所有博客均是原创博客，所有文章禁止转载，违者必究。 By AI小怪兽 AI&amp;CV</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">10-04</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					957
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://cv2023.blog.csdn.net/article/details/133563710" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.6","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-6-133563710-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"6","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://cv2023.blog.csdn.net/article/details/133563710"}'  data-report-query='spm=1001.2101.3001.6650.6&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-6-133563710-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-6-133563710-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">PConv和<em>C2f</em>结合 | 轻量化的同时在数据集并有小幅涨点；</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/qq_37706472/article/details/129352058"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.7","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-7-129352058-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"7","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/qq_37706472/article/details/129352058"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/qq_37706472/article/details/129352058" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.7","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-7-129352058-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"7","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/qq_37706472/article/details/129352058"}'  data-report-query='spm=1001.2101.3001.6650.7&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-7-129352058-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-7-129352058-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>YOLO</em>系列模型<em>改进</em>指南</div>
					<div class="tag">热门推荐</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/qq_37706472" target="_blank"><span class="blog-title">qq_37706472的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">03-05</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					4万+
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/qq_37706472/article/details/129352058" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.7","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-7-129352058-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"7","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/qq_37706472/article/details/129352058"}'  data-report-query='spm=1001.2101.3001.6650.7&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-7-129352058-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-7-129352058-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1"><em>YOLO</em>主流模型<em>改进</em>大杂烩！！！
目前包含<em>yolo</em>v5，<em>yolo</em>v7，<em>yolo</em><em>v8</em>模型的众多<em>改进</em>方案，效果因数据集和参数而定，仅供参考。</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/qq_42722197/article/details/128991193"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.8","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-8-128991193-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"8","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/qq_42722197/article/details/128991193"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/qq_42722197/article/details/128991193" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.8","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-8-128991193-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"8","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/qq_42722197/article/details/128991193"}'  data-report-query='spm=1001.2101.3001.6650.8&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-8-128991193-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-8-128991193-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1">Ultralytics官宣！ <em>YOLO</em><em>v8</em> 来了</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/qq_42722197" target="_blank"><span class="blog-title">小白学视觉</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">02-11</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					1311
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/qq_42722197/article/details/128991193" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.8","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-8-128991193-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"8","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/qq_42722197/article/details/128991193"}'  data-report-query='spm=1001.2101.3001.6650.8&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-8-128991193-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-8-128991193-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">点击上方&ldquo;小白学视觉&rdquo;，选择加&quot;星标&quot;或&ldquo;置顶&rdquo;重磅干货，第一时间送达大家好昨天Ultralytics 官方账号宣布，<em>YOLO</em><em>v8</em>来了简单总结如下：更简单更准确更快更小，部署更方便回顾一下<em>YOLO</em>v5这里粗略回顾一下，这里直接提供<em>YOLO</em>v5的整理的结构图吧：Backbone：CSPDarkNet结构，主要结构思想的体现在C3<em>模块</em>，这里也是梯度分流的主要思想所在的地方；PAN-FPN：双流的FP...</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/pope888/article/details/135538264"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.9","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-9-135538264-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"9","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/pope888/article/details/135538264"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/pope888/article/details/135538264" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.9","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-9-135538264-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"9","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/pope888/article/details/135538264"}'  data-report-query='spm=1001.2101.3001.6650.9&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-9-135538264-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-9-135538264-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>YOLO</em><em>v8</em><em>改进</em>&mdash;&mdash;使用<em>C2f</em>-Faster替换<em>C2f</em></div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/pope888" target="_blank"><span class="blog-title">pope888的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">01-11</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					735
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/pope888/article/details/135538264" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.9","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-9-135538264-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"9","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/pope888/article/details/135538264"}'  data-report-query='spm=1001.2101.3001.6650.9&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-9-135538264-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-9-135538264-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">【代码】<em>YOLO</em><em>v8</em><em>改进</em>&mdash;&mdash;使用<em>C2f</em>-Faster替换<em>C2f</em>.(使用FasterNet<em>中</em>的FasterBlock替换<em>C2f</em><em>中</em>的Bottle<em>neck</em>)</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/jam12315/article/details/130505406"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.10","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-10-130505406-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"10","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/jam12315/article/details/130505406"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/jam12315/article/details/130505406" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.10","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-10-130505406-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"10","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/jam12315/article/details/130505406"}'  data-report-query='spm=1001.2101.3001.6650.10&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-10-130505406-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-10-130505406-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1">【<em>Yolo</em>】<em>Yolo</em>V5训练自定义模型</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/jam12315" target="_blank"><span class="blog-title">jam12315的专栏</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">05-05</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					1682
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/jam12315/article/details/130505406" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.10","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-10-130505406-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"10","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/jam12315/article/details/130505406"}'  data-report-query='spm=1001.2101.3001.6650.10&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-10-130505406-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-10-130505406-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">上一篇博文主要记录了在Jetson Orin Nano下部署<em>Yolo</em>V5环境，并运行了<em>yolo</em>V5n.pt模型，本篇在上一篇的基础上，进一步记录如何训练自己的目标模型，我们以一根为训练对象进行说明。</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_download clearfix" data-url="https://download.csdn.net/download/admin_maxin/88813918"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.11","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~default-11-88813918-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"11","strategy":"2~default~CTRLIST~default","dest":"https://download.csdn.net/download/admin_maxin/88813918"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://download.csdn.net/download/admin_maxin/88813918" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.11","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~default-11-88813918-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"11","strategy":"2~default~CTRLIST~default","dest":"https://download.csdn.net/download/admin_maxin/88813918"}'  data-report-query='spm=1001.2101.3001.6650.11&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7Edefault-11-88813918-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7Edefault-11-88813918-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1">主要包含了LSTM、<em>卷积</em>神经网络<em>中</em>，<em>注意力机制</em>的实现</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info display-flex">
					<span class="info-block">02-06</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://download.csdn.net/download/admin_maxin/88813918" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.11","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~default-11-88813918-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"11","strategy":"2~default~CTRLIST~default","dest":"https://download.csdn.net/download/admin_maxin/88813918"}'  data-report-query='spm=1001.2101.3001.6650.11&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7Edefault-11-88813918-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7Edefault-11-88813918-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">主要包含了LSTM、<em>卷积</em>神经网络<em>中</em>，<em>注意力机制</em>的实现

目录
所需环境 Environ<em>ment</em>
LSTM<em>中</em>的<em>注意力机制</em>
Conv<em>中</em>的<em>注意力机制</em>
所需环境
tensorflow-gpu==1.13.1
keras==2.1.5

LSTM<em>中</em>的<em>注意力机制</em>
在本库<em>中</em>，我将<em>注意力机制</em>施加在LSTM的Step上，目的是注意输入进来的样本，每一个Step的重要程度。我们使用的样本数据如下：</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_download clearfix" data-url="https://download.csdn.net/download/Runnymmede/88646299"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.12","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~default-12-88646299-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"12","strategy":"2~default~CTRLIST~default","dest":"https://download.csdn.net/download/Runnymmede/88646299"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://download.csdn.net/download/Runnymmede/88646299" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.12","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~default-12-88646299-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"12","strategy":"2~default~CTRLIST~default","dest":"https://download.csdn.net/download/Runnymmede/88646299"}'  data-report-query='spm=1001.2101.3001.6650.12&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7Edefault-12-88646299-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7Edefault-12-88646299-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1">本科毕设-基于<em>注意力机制</em>和图<em>卷积</em>神经网络的多任务谣言<em>检测</em><em>python</em>源码+数据集.zip</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info display-flex">
					<span class="info-block">12-20</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://download.csdn.net/download/Runnymmede/88646299" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.12","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~default-12-88646299-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"12","strategy":"2~default~CTRLIST~default","dest":"https://download.csdn.net/download/Runnymmede/88646299"}'  data-report-query='spm=1001.2101.3001.6650.12&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7Edefault-12-88646299-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7Edefault-12-88646299-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">【资源说明】
1.项目代码均经过功能验证ok，确保稳定可靠运行。欢迎下载食用体验！
2.主要针对各个计算机相关专业，包括计算机科学、信息安全、数据科学与大数据技术、<em>人工智能</em>、通信、物联网等领域的在校学生、专业教师、企业员工。
3.项目具有丰富的拓展空间，不仅可作为入门进阶，也可直接作为毕设、课程设计、大作业、初期项目立项演示等用途。
4.当然也鼓励大家基于此进行二次开发。在使用过程<em>中</em>，如有问题或建议，请及时沟通。
5.期待你能在项目<em>中</em>找到乐趣和灵感，也欢迎你的分享和反馈！
【项目介绍】
本科毕设-基于<em>注意力机制</em>和图<em>卷积</em>神经网络的多任务谣言<em>检测</em><em>python</em>源码+数据集.zip本科毕设-基于<em>注意力机制</em>和图<em>卷积</em>神经网络的多任务谣言<em>检测</em><em>python</em>源码+数据集.zip本科毕设-基于<em>注意力机制</em>和图<em>卷积</em>神经网络的多任务谣言<em>检测</em><em>python</em>源码+数据集.zip本科毕设-基于<em>注意力机制</em>和图<em>卷积</em>神经网络的多任务谣言<em>检测</em><em>python</em>源码+数据集.zip本科毕设-基于<em>注意力机制</em>和图<em>卷积</em>神经网络的多任务谣言<em>检测</em><em>python</em>源码+数据集.zip本科毕设-基于<em>注意力机制</em>和图<em>卷积</em>神经网络的多任务谣言<em>检测</em><em>python</em>源码+数据集.zip本科毕设-基于<em>注意力机制</em>和图<em>卷积</em>神经网络的多任务谣言<em>检测</em><em>python</em>源码+数据集.zip
本科毕设-基于<em>注意力机制</em>和图<em>卷积</em>神经网络的多任务谣言<em>检测</em><em>python</em>源码+数据集.zip</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_download clearfix" data-url="https://download.csdn.net/download/DeepLearning_/88475246"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.13","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~OPENSEARCH~Rate-13-88475246-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"13","strategy":"2~default~OPENSEARCH~Rate","dest":"https://download.csdn.net/download/DeepLearning_/88475246"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://download.csdn.net/download/DeepLearning_/88475246" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.13","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~OPENSEARCH~Rate-13-88475246-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"13","strategy":"2~default~OPENSEARCH~Rate","dest":"https://download.csdn.net/download/DeepLearning_/88475246"}'  data-report-query='spm=1001.2101.3001.6650.13&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7EOPENSEARCH%7ERate-13-88475246-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7EOPENSEARCH%7ERate-13-88475246-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1">基于结合<em>注意力机制</em>和膨胀<em>卷积</em>的HRNet遥感图像语义分割<em>python</em>源码.zip</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info display-flex">
					<span class="info-block">10-26</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://download.csdn.net/download/DeepLearning_/88475246" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.13","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~OPENSEARCH~Rate-13-88475246-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"13","strategy":"2~default~OPENSEARCH~Rate","dest":"https://download.csdn.net/download/DeepLearning_/88475246"}'  data-report-query='spm=1001.2101.3001.6650.13&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7EOPENSEARCH%7ERate-13-88475246-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7EOPENSEARCH%7ERate-13-88475246-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">基于结合<em>注意力机制</em>和膨胀<em>卷积</em>的HRNet遥感图像语义分割<em>python</em>源码.zip基于结合<em>注意力机制</em>和膨胀<em>卷积</em>的HRNet遥感图像语义分割<em>python</em>源码.zip基于结合<em>注意力机制</em>和膨胀<em>卷积</em>的HRNet遥感图像语义分割<em>python</em>源码.zip基于...</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_download clearfix" data-url="https://download.csdn.net/download/admin_maxin/88814033"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.14","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~OPENSEARCH~Rate-14-88814033-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"14","strategy":"2~default~OPENSEARCH~Rate","dest":"https://download.csdn.net/download/admin_maxin/88814033"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://download.csdn.net/download/admin_maxin/88814033" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.14","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~OPENSEARCH~Rate-14-88814033-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"14","strategy":"2~default~OPENSEARCH~Rate","dest":"https://download.csdn.net/download/admin_maxin/88814033"}'  data-report-query='spm=1001.2101.3001.6650.14&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7EOPENSEARCH%7ERate-14-88814033-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7EOPENSEARCH%7ERate-14-88814033-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1">基于可变形<em>卷积</em>和<em>注意力机制</em>的滚动轴承故障诊断</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info display-flex">
					<span class="info-block">02-06</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://download.csdn.net/download/admin_maxin/88814033" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.14","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~OPENSEARCH~Rate-14-88814033-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"14","strategy":"2~default~OPENSEARCH~Rate","dest":"https://download.csdn.net/download/admin_maxin/88814033"}'  data-report-query='spm=1001.2101.3001.6650.14&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7EOPENSEARCH%7ERate-14-88814033-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7EOPENSEARCH%7ERate-14-88814033-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">本文利用可变形<em>卷积</em>神经网络提高使用固定几何结构进行局部特征提取的能力，并引入<em>注意力机制</em>，充分考虑滚动轴承故障的特征来设计注意<em>模块</em>，以增强故障相关特征，忽略一些无关特征，提出了一种可变形多<em>注意力</em><em>卷积</em>神经...</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/mddCSDN/article/details/136225541"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.15","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-15-136225541-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"15","strategy":"2~default~BLOGTAG~default","dest":"https://blog.csdn.net/mddCSDN/article/details/136225541"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/mddCSDN/article/details/136225541" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.15","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-15-136225541-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"15","strategy":"2~default~BLOGTAG~default","dest":"https://blog.csdn.net/mddCSDN/article/details/136225541"}'  data-report-query='spm=1001.2101.3001.6650.15&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-15-136225541-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-15-136225541-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>yolo</em>v5导出onnx转engine推理</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/mddCSDN" target="_blank"><span class="blog-title">mddCSDN的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">02-22</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					890
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/mddCSDN/article/details/136225541" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.15","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-15-136225541-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"15","strategy":"2~default~BLOGTAG~default","dest":"https://blog.csdn.net/mddCSDN/article/details/136225541"}'  data-report-query='spm=1001.2101.3001.6650.15&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-15-136225541-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-15-136225541-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">使用上述文章<em>中</em>的代码ONNX转engine速度较慢， engine_file_path需要给出具体名称，如：<em>yolo</em>v5_my.engine。pt转engine是先转ONNX，然后再到engine。将TensorRT的的lib加入环境变量<em>中</em>。需要提供配置文件和权重文件，不然导出模型不能正常推理。在win11系统环境path<em>添加</em>。</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://snu77.blog.csdn.net/article/details/136278117"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.16","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-16-136278117-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"16","strategy":"2~default~BLOGTAG~default","dest":"https://snu77.blog.csdn.net/article/details/136278117"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://snu77.blog.csdn.net/article/details/136278117" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.16","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-16-136278117-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"16","strategy":"2~default~BLOGTAG~default","dest":"https://snu77.blog.csdn.net/article/details/136278117"}'  data-report-query='spm=1001.2101.3001.6650.16&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-16-136278117-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-16-136278117-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>YOLO</em>v5<em>改进</em> | SPPF篇 | 利用<em>YOLO</em>v9最新的SPPELAN<em>模块</em><em>改进</em>SPPF（全网独家创新，附手撕结构图）</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/java1314777" target="_blank"><span class="blog-title">Snu77的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">02-25</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					730
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://snu77.blog.csdn.net/article/details/136278117" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.16","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-16-136278117-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"16","strategy":"2~default~BLOGTAG~default","dest":"https://snu77.blog.csdn.net/article/details/136278117"}'  data-report-query='spm=1001.2101.3001.6650.16&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-16-136278117-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-16-136278117-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">本文给大家带来的<em>改进</em>机制是利用2024/02/21号最新发布的<em>YOLO</em>v9其<em>中</em>提出的SPPELAN<em>模块</em>来<em>改进</em>SPPF，其<em>中</em><em>YOLO</em>v9针对于这个<em>模块</em>并没有介绍，只是在其项目文件<em>中</em>用到了，我将其整理出来用于我们的<em>YOLO</em>v5的项目，同时空间金字塔池化作为我们<em>YOLO</em>v5<em>中</em>的一个比较独特的存在其的改变并不会影响我们的模型其它的<em>改进</em>太多，所以如果你融合方面比较困难，可以尝试替换一下SPPF来改变模型的结构从而达到一个创新的目的，同时本文的内容目前网络上并无其它人总结大家可以尝试以下在自己数据集上的效果。</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/huohu728/article/details/136279327"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.17","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-17-136279327-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"17","strategy":"2~default~BLOGTAG~default","dest":"https://blog.csdn.net/huohu728/article/details/136279327"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/huohu728/article/details/136279327" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.17","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-17-136279327-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"17","strategy":"2~default~BLOGTAG~default","dest":"https://blog.csdn.net/huohu728/article/details/136279327"}'  data-report-query='spm=1001.2101.3001.6650.17&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-17-136279327-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-17-136279327-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>YOLO</em>v9来了，可编程梯度信息与广义高效层聚合网络 助力全新<em>检测</em>SOTA前沿</div>
					<div class="tag">最新发布</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/huohu728" target="_blank"><span class="blog-title">聚焦底层视觉处理，对相关基础AI技术持续学习</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">02-25</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					1275
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/huohu728/article/details/136279327" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.17","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-17-136279327-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"17","strategy":"2~default~BLOGTAG~default","dest":"https://blog.csdn.net/huohu728/article/details/136279327"}'  data-report-query='spm=1001.2101.3001.6650.17&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-17-136279327-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-17-136279327-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1"><em>YOLO</em>v9来了</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_chatgpt clearfix" data-url="https://wenku.csdn.net/answer/6rbxu7fzdh"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.18","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-chatgpt-2~default~CTRLIST~Position-18-6rbxu7fzdh-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"18","strategy":"2~default~CTRLIST~Position","dest":"https://wenku.csdn.net/answer/6rbxu7fzdh"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://wenku.csdn.net/answer/6rbxu7fzdh" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.18","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-chatgpt-2~default~CTRLIST~Position-18-6rbxu7fzdh-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"18","strategy":"2~default~CTRLIST~Position","dest":"https://wenku.csdn.net/answer/6rbxu7fzdh"}'  data-report-query='spm=1001.2101.3001.6650.18&utm_medium=distribute.pc_relevant.none-task-chatgpt-2%7Edefault%7ECTRLIST%7EPosition-18-6rbxu7fzdh-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-chatgpt-2%7Edefault%7ECTRLIST%7EPosition-18-6rbxu7fzdh-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>YOLO</em>V5<em>改进</em>-<em>添加</em><em>注意力机制</em>senet</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info display-flex">
					<span class="info-block">09-13</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://wenku.csdn.net/answer/6rbxu7fzdh" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.18","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-chatgpt-2~default~CTRLIST~Position-18-6rbxu7fzdh-blog-134432710.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709121948981_66381\"}","dist_request_id":"1709121948981_66381","ab_strategy":"increase_t0_anti_vip","index":"18","strategy":"2~default~CTRLIST~Position","dest":"https://wenku.csdn.net/answer/6rbxu7fzdh"}'  data-report-query='spm=1001.2101.3001.6650.18&utm_medium=distribute.pc_relevant.none-task-chatgpt-2%7Edefault%7ECTRLIST%7EPosition-18-6rbxu7fzdh-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-chatgpt-2%7Edefault%7ECTRLIST%7EPosition-18-6rbxu7fzdh-blog-134432710.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">你好！关于<em>YOLO</em>v5的<em>改进</em>，你提到了<em>添加</em><em>注意力机制</em>SENet。SENet（Squeeze-and-Excitation Network）是一种用于增强<em>卷积</em>神经网络性能的<em>注意力机制</em>。它通过学习通道间的依赖关系，来自适应地调整不同通道的特征响应。

在<em>YOLO</em>v5<em>中</em>，可以通过将SENet<em>模块</em>嵌入到主干特征提取网络<em>中</em>来实现<em>注意力机制</em>的<em>添加</em>。具体而言，可以在主干网络的某些<em>卷积</em>层之后<em>添加</em>SENet<em>模块</em>，以学习通道间的权重。这样做可以帮助网络更好地关注对<em>目标检测</em>任务更有用的特征，从而提高<em>检测</em>性能。

<em>添加</em>SENet的步骤如下：
1. 在主干网络的某些<em>卷积</em>层之后插入SENet<em>模块</em>。
2. SE<em>模块</em>由两个阶段组成：Squeeze阶段和Excitation阶段。
   - Squeeze阶段：通过全局平均池化操作将每个通道的特征图压缩为一个标量。
   - Excitation阶段：使用全连接层将压缩后的特征进行激活处理，并生成一个通道<em>注意力</em>向量。
3. 将通道<em>注意力</em>向量与原始特征相乘，以增强重要特征的表示能力。

通过引入SENet的<em>注意力机制</em>，<em>YOLO</em>v5可以更好地选择和强调对<em>目标检测</em>任务最为关键的特征，从而提升<em>检测</em>性能。这是一种常见的<em>改进</em>方法，已被广泛应用于不同的视觉任务<em>中</em>。希望这些信息对你有所帮助！如果你还有其他问题，可以继续提问。</div>
			</a>
		</div>
	</div>
</div>
              </div>
<div id="recommendNps" class="recommend-nps-box common-nps-box">
  <h3 class="aside-title">“相关推荐”对你有帮助么？</h3>
  <div class="aside-content">
      <ul class="newnps-list">
          <li class="newnps-item" data-type="非常没帮助">
              <div class="newnps-img-box">
                  <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel1.png" alt="">
                  <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey1.png" alt="">
              </div>
              <div class="newnps-text">非常没帮助</div>
          </li>
          <li class="newnps-item" data-type="没帮助">
              <div class="newnps-img-box">
                  <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel2.png" alt="">
                  <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey2.png" alt="">
              </div>
              <div class="newnps-text">没帮助</div>
          </li>
          <li class="newnps-item" data-type="一般">
              <div class="newnps-img-box">
                  <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel3.png" alt="">
                  <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey3.png" alt="">
              </div>
              <div class="newnps-text">一般</div>
          </li>
          <li class="newnps-item" data-type="有帮助">
              <div class="newnps-img-box">
                  <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel4.png" alt="">
                  <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey4.png" alt="">
              </div>
              <div class="newnps-text">有帮助</div>
          </li>
          <li class="newnps-item" data-type="非常有帮助">
              <div class="newnps-img-box">
                  <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel5.png" alt="">
                  <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey5.png" alt="">
              </div>
              <div class="newnps-text">非常有帮助</div>
          </li>
      </ul>
      <div class="newnps-form-box">
      <div class="newnps-form">
          <input type="text" placeholder="请输入建议或反馈后点击提交" class="newnps-input">
          <span class="newnps-btn">提交</span>
      </div>
      </div>
  </div>
</div><div class="blog-footer-bottom" style="margin-top:10px;"></div>
<script src="https://g.csdnimg.cn/common/csdn-footer/csdn-footer.js" data-isfootertrack="false" type="text/javascript"></script>
<script type="text/javascript">
    window.csdn.csdnFooter.options = {
        el: '.blog-footer-bottom',
        type: 2
    }
</script>          </main>
<aside class="blog_container_aside">
<div id="asideProfile" class="aside-box">
    <div class="profile-intro d-flex">
        <div class="avatar-box d-flex justify-content-center flex-column">
            <a href="https://snu77.blog.csdn.net" target="_blank" data-report-click='{"mod":"popu_379","spm":"1001.2101.3001.4121","dest":"https://snu77.blog.csdn.net","ab":"new"}'>
                <img src="https://profile-avatar.csdnimg.cn/27160f4941a54d07b535ceabcfa4a800_java1314777.jpg!1" class="avatar_pic">
            </a>
        </div>
        <div class="user-info d-flex flex-column profile-intro-name-box">
            <div class="profile-intro-name-boxTop">
                <a href="https://snu77.blog.csdn.net" target="_blank" class="" id="uid" title="Snu77" data-report-click='{"mod":"popu_379","spm":"1001.2101.3001.4122","dest":"https://snu77.blog.csdn.net","ab":"new"}'>
                    <span class="name vip-name" username="java1314777">Snu77</span>
                </a>
                <span>
                <a href="https://snu77.blog.csdn.net"  data-report-click='{"spm":"1001.2101.3001.9180"}' target="_blank"><img class="identity" src="https://csdnimg.cn/release/blogv2/dist/mobile/img/vipNew.png" alt=""></a>
                </span>
                <span class="flag expert-blog">
                <span class="bubble">CSDN认证博客专家</span>
                </span>
                <span class="flag company-blog">
                <span class="bubble">CSDN认证企业博客</span>
                </span>
            </div>
            <div class="profile-intro-name-boxFooter">
                <span class="personal-home-page personal-home-years" title="已加入 CSDN 2年">码龄2年</span>
                    <span class="personal-home-page">
                    <a class="personal-home-certification" href="https://i.csdn.net/#/uc/profile?utm_source=14998968" target="_blank" title="人工智能领域优质创作者">
                    <img src="https://img-home.csdnimg.cn/images/20210412060958.png" alt="">
                    人工智能领域优质创作者
                    </a>
                    </span>
            </div>
        </div>
    </div>
    <div class="data-info d-flex item-tiling">
        <dl class="text-center" title="337">
            <a href="https://snu77.blog.csdn.net" data-report-click='{"mod":"1598321000_001","spm":"1001.2101.3001.4310"}' data-report-query="t=1">  
                <dt><span class="count">337</span></dt>
                <dd class="font">原创</dd>
            </a>
        </dl>
        <dl class="text-center" data-report-click='{"mod":"1598321000_002","spm":"1001.2101.3001.4311"}' title="7">
            <a href="https://blog.csdn.net/rank/list/weekly" target="_blank">
                <dt><span class="count">7</span></dt>
                <dd class="font">周排名</dd>
            </a>
        </dl>
        <dl class="text-center" title="1140">
            <a href="https://blog.csdn.net/rank/list/total" data-report-click='{"mod":"1598321000_003","spm":"1001.2101.3001.4312"}' target="_blank">
                <dt><span class="count">1140</span></dt>
                <dd class="font">总排名</dd>
            </a>
        </dl>
        <dl class="text-center" style="min-width:58px" title="592968">  
            <dt><span class="count">59万+</span></dt>
            <dd>访问</dd>
        </dl>
        <dl class="text-center" title="7级,点击查看等级说明">
            <dt><a href="https://blog.csdn.net/blogdevteam/article/details/103478461" target="_blank">
                <img class="level" src="https://csdnimg.cn/identity/blog7.png">
            </a>
            </dt>
            <dd>等级</dd>
        </dl>
    </div>
    <div class="item-rank"></div>
    <div class="data-info d-flex item-tiling">
        <dl class="text-center" title="13270">
            <dt><span class="count">1万+</span></dt>
            <dd>积分</dd>
        </dl>
         <dl class="text-center" id="fanBox" title="25757">
            <dt><span class="count" id="fan">2万+</span></dt>
            <dd>粉丝</dd>
        </dl>
        <dl class="text-center" title="7609">
            <dt><span class="count">7609</span></dt>
            <dd>获赞</dd>
        </dl>
        <dl class="text-center" title="3467">
            <dt><span class="count">3467</span></dt>
            <dd>评论</dd>
        </dl>
        <dl class="text-center" title="9402">
            <dt><span class="count">9402</span></dt>
            <dd>收藏</dd>
        </dl>
    </div>
    <div class="aside-box-footer" data-report-view='{"spm":"3001.4296"}'>
        <div class="badge-box d-flex">
            <div class="badge d-flex">
                <div class="icon-badge" title="MarkDown">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/11887cd76794439ba69942cd77e81457.png" alt="MarkDown">
                    </div>
                </div>
                <div class="icon-badge" title="CUDA入门">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/cd999bc9a00b4283abaff17a468ff189.png" alt="CUDA入门">
                    </div>
                </div>
                <div class="icon-badge" title="云原生入门">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/3d0f343b511d482892084e4bec9ef37b.png" alt="云原生入门">
                    </div>
                </div>
                <div class="icon-badge" title="学无止境">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/0af32a292d094a4cbfd0feff60f3590d.png" alt="学无止境">
                    </div>
                </div>
                <div class="icon-badge" title="习惯养成">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/xiguanyangchengLv1.png" alt="习惯养成">
                    </div>
                </div>
                <div class="icon-badge" title="笔记达人">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/bijidarenLv1.png" alt="笔记达人">
                    </div>
                </div>
                <div class="icon-badge" title="Java工程师·初级">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/s_java_b_lv1@240.png" alt="Java工程师·初级">
                    </div>
                </div>
                <div class="icon-badge" title="Java工程师·高级">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/s_java_a_lv1@240.png" alt="Java工程师·高级">
                    </div>
                </div>
                <div class="icon-badge" title="博客之星–参与">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/76b1d0d897bc4bdabc11a5d89fe552d3.png" alt="博客之星–参与">
                    </div>
                </div>
                <div class="icon-badge" title="Python工程师·初级">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/s_python_b_lv1@240.png" alt="Python工程师·初级">
                    </div>
                </div>
                <div class="icon-badge" title="Vue进阶">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/c1369b46fc9140c3808c8189382cf046.png" alt="Vue进阶">
                    </div>
                </div>
                <div class="icon-badge" title="Python工程师·高级">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/s_python_a_lv1@240.png" alt="Python工程师·高级">
                    </div>
                </div>
                <div class="icon-badge" title="勤写标兵">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/eabb492c5e3343738376cdb052649492.png" alt="勤写标兵">
                    </div>
                </div>
                <div class="icon-badge" title="创作能手">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/qixiebiaobing4@240.png" alt="创作能手">
                    </div>
                </div>
                <div class="icon-badge" title="新秀勋章">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/xinxiu@240.png" alt="新秀勋章">
                    </div>
                </div>
                <div class="icon-badge" title="持之以恒">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/a73a5facfe464b5a9e2b0393b1189042.png" alt="持之以恒">
                    </div>
                </div>
                <div class="icon-badge" title="创作纪念日">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/cz1th.png" alt="创作纪念日">
                    </div>
                </div>
                <div class="icon-badge" title="GitHub">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/github@240.png" alt="GitHub">
                    </div>
                </div>
                <div class="icon-badge" title="笔耕不辍">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/02d34b42a3ee476fb50850304ab67017.png" alt="笔耕不辍">
                    </div>
                </div>
                <div class="icon-badge" title="话题达人">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/dff63da017d0435d83f26031510a70f0.png" alt="话题达人">
                    </div>
                </div>
                <div class="icon-badge" title="知无不言">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/f19b84c244aa4e6d8bf469b4aff1f98c.png" alt="知无不言">
                    </div>
                </div>
                <div class="icon-badge" title="授人以渔">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/53a3e1cbc8b643cd88e0be2ea68200f7.png" alt="授人以渔">
                    </div>
                </div>
                <div class="icon-badge" title="求知">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/c0535f9cefbd4cc0a4878be28bfc4590.png" alt="求知">
                    </div>
                </div>
                <div class="icon-badge" title="受益良多">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/f36bcf8b59434f7e8e4fe5cab12ed731.png" alt="受益良多">
                    </div>
                </div>
                <div class="icon-badge" title="MySQL进阶">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/2b34833c180244d581b07e8aaa9ae3d9.png" alt="MySQL进阶">
                    </div>
                </div>
                <div class="icon-badge" title="Go">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/23159beb43324e31b1a0ffa3bd651a22.png" alt="Go">
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="profile-intro-name-boxOpration">
        <div class="opt-letter-watch-box">
        <a rel="nofollow" class="bt-button personal-letter" href="https://im.csdn.net/chat/java1314777" target="_blank" rel="noopener">私信</a>
        </div>
        <div class="opt-letter-watch-box"> 
            <a class="attented personal-watch bt-button" id="btnAttent">已关注</a>
        </div>
    </div>
</div>
<a id="remuneration" data-report-click='{"spm":"1001.2101.3001.9809"}' rel="nofollow" href="" class="remuneration-box">
  <img src="" alt="">
</a>
  <div id="asideWriteGuide" class="aside-box side-write-guide-box type-1" data-report-view='{"spm":"3001.9727"}'>
    <div class="content-box">
      <a rel="nofollow" href="https://mp.csdn.net" target="_blank" class="btn-go-write" data-report-query="spm=3001.9727" data-report-click='{"spm":"3001.9727"}'>
        <img src="https://img-home.csdnimg.cn/images/20240218021837.png" alt="写文章">
      </a>
    </div>
  </div>
<div id="asideSearchArticle" class="aside-box">
	<div class="aside-content search-comter">
    <div class="aside-search aside-search-blog">         
        <input type="text" class="input-serch-blog" name="" autocomplete="off" value="" id="search-blog-words" placeholder="搜博主文章">
        <a class="btn-search-blog" data-report-click='{"spm":"1001.2101.3001.9182"}'>
            <img src="//csdnimg.cn/cdn/content-toolbar/csdn-white-search.png?v=1587006908">
        </a>
    </div>
    </div>
</div>



<div id="asideHotArticle" class="aside-box">
	<h3 class="aside-title">热门文章</h3>
	<div class="aside-content">
		<ul class="hotArticle-list">
			<li>
				<a href="https://snu77.blog.csdn.net/article/details/132974960" target="_blank"  data-report-click='{"mod":"popu_541","spm":"1001.2101.3001.4139","dest":"https://snu77.blog.csdn.net/article/details/132974960","ab":"new"}'>
				时间序列预测模型实战案例(三)(LSTM)(Python)(深度学习)时间序列预测(包括运行代码以及代码讲解)
					<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					<span class="read">19092</span>
                </a>
			</li>
			<li>
				<a href="https://snu77.blog.csdn.net/article/details/135309007" target="_blank"  data-report-click='{"mod":"popu_541","spm":"1001.2101.3001.4139","dest":"https://snu77.blog.csdn.net/article/details/135309007","ab":"new"}'>
				YOLOv8改进有效系列目录 | 包含卷积、主干、检测头、注意力机制、Neck上百种创新机制
					<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					<span class="read">17067</span>
                </a>
			</li>
			<li>
				<a href="https://snu77.blog.csdn.net/article/details/134154676" target="_blank"  data-report-click='{"mod":"popu_541","spm":"1001.2101.3001.4139","dest":"https://snu77.blog.csdn.net/article/details/134154676","ab":"new"}'>
				YOLOv8性能评估指标-＞mAP、Precision、Recall、FPS、IoU
					<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					<span class="read">16119</span>
                </a>
			</li>
			<li>
				<a href="https://snu77.blog.csdn.net/article/details/134097996" target="_blank"  data-report-click='{"mod":"popu_541","spm":"1001.2101.3001.4139","dest":"https://snu77.blog.csdn.net/article/details/134097996","ab":"new"}'>
				详解YOLOv8网络结构/环境搭建/数据集获取/训练/推理/验证/导出/部署
					<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					<span class="read">12428</span>
                </a>
			</li>
			<li>
				<a href="https://snu77.blog.csdn.net/article/details/128027977" target="_blank"  data-report-click='{"mod":"popu_541","spm":"1001.2101.3001.4139","dest":"https://snu77.blog.csdn.net/article/details/128027977","ab":"new"}'>
				Win11上Pytorch的安装并在Pycharm上调用PyTorch最新超详细过程并附详细的系统变量添加过程,可解决pycharm中pip不好使的问题
					<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					<span class="read">9005</span>
                </a>
			</li>
		</ul>
	</div>
</div>
<div id="asideCategory" class="aside-box flexible-box">
    <h3 class="aside-title">分类专栏</h3>
    <div class="aside-content">
        <ul>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12483754.html" data-report-click='{"mod":"popu_826","spm":"1001.2101.3001.4230","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12483754.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/direct/d0d498bd4f0c4e17b48ff54e86b67668.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        YOLOv8有效涨点专栏
                    </span>
                        <span class="pay-tag">付费</span>
                </a>
                <span class="special-column-num">125篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12500428.html" data-report-click='{"mod":"popu_826","spm":"1001.2101.3001.4230","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12500428.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/direct/bce35723af3f466e97009ebf18e827aa.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        RT-DETR有效改进专栏
                    </span>
                        <span class="pay-tag">付费</span>
                </a>
                <span class="special-column-num">61篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12500426.html" data-report-click='{"mod":"popu_826","spm":"1001.2101.3001.4230","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12500426.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/direct/6029d5920130491c8f52a4b3005e5f84.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        YOLOv5改进有效专栏
                    </span>
                        <span class="pay-tag">付费</span>
                </a>
                <span class="special-column-num">106篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12583198.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12583198.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/direct/ba2519e7272a4267a3ded30aaa79eb09.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        YOLOv9有效涨点专栏
                    </span>
                </a>
                <span class="special-column-num">2篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12464694.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12464694.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/20201014180756913.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        数据集专栏
                    </span>
                </a>
                <span class="special-column-num">3篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12551123.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12551123.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/direct/85c6dd75fec842e7a1a36ea95aa69562.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        YOLOv5/v7有效涨点
                    </span>
                </a>
                <span class="special-column-num">1篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12510496.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12510496.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/direct/e44ee41c806043f0a3245f74fd5de1db.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        深度学习100题大战
                    </span>
                </a>
                <span class="special-column-num">1篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12486438.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12486438.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/20201014180756738.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        活动专栏
                    </span>
                </a>
                <span class="special-column-num">2篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12285732.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12285732.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/20201014180756919.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        目标检测专栏
                    </span>
                </a>
                <span class="special-column-num">3篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12441087.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12441087.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/direct/5ae08a29357d42a9b849b054be235894.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        时间序列预测专栏
                    </span>
                </a>
                <span class="special-column-num">35篇</span>
            </li>
        </ul>
    </div>
    <p class="text-center">
        <a class="flexible-btn" data-fbox="aside-archive"><img class="look-more" src="https://csdnimg.cn/release/blogv2/dist/pc/img/arrowDownBlack.png" alt=""></a>
    </p>
</div>
<div id="asideNewComments" class="aside-box">
    <h3 class="aside-title">最新评论</h3>
    <div class="aside-content">
        <ul class="newcomment-list">
            <li>
                <a class="title text-truncate" target="_blank" href="https://snu77.blog.csdn.net/article/details/136282783#comments_31436253" data-report-click='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/136282783#comments_31436253","ab":"new"}' data-report-view='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/136282783#comments_31436253","ab":"new"}'>YOLOv5改进 | Conv篇 | 全新的SOATA轻量化下采样操作ADown（轻量又涨点，附手撕结构图）</a>
                <p class="comment ellipsis">
                    <a href="https://xiaoming.blog.csdn.net" class="user-name" target="_blank">小   明: </a>
                    <span class="code-comments">您的深度理解和清晰的表达方式使复杂的技术概念变得容易理解。感谢您的无私分享，这对于像我这样的技术爱好者来说是一份宝贵的资源。期待更多精彩的内容！</span>
                </p>
            </li>
            <li>
                <a class="title text-truncate" target="_blank" href="https://snu77.blog.csdn.net/article/details/136346900#comments_31436249" data-report-click='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/136346900#comments_31436249","ab":"new"}' data-report-view='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/136346900#comments_31436249","ab":"new"}'>YOLOv8改进 | 独家创新篇 | 结合SOTA思想利用双主干网络改进YOLOv8（全网独家创新，最重磅的更新）</a>
                <p class="comment ellipsis">
                    <a href="https://xiaoming.blog.csdn.net" class="user-name" target="_blank">小   明: </a>
                    <span class="code-comments">总结的很详细，文章有深度，内容丰富，干货满满，期待博主持续更新，三连支持！！</span>
                </p>
            </li>
            <li>
                <a class="title text-truncate" target="_blank" href="https://snu77.blog.csdn.net/article/details/135305515#comments_31435440" data-report-click='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/135305515#comments_31435440","ab":"new"}' data-report-view='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/135305515#comments_31435440","ab":"new"}'>YOLOv8改进 | 检测头篇 | DynamicHead原论文一比一复现 （不同于网上版本，全网首发）</a>
                <p class="comment ellipsis">
                    <a href="https://snu77.blog.csdn.net" class="user-name" target="_blank">Snu77: </a>
                    <span class="code-comments">安装一下就行，mmcv这是个第三方库。</span>
                </p>
            </li>
            <li>
                <a class="title text-truncate" target="_blank" href="https://snu77.blog.csdn.net/article/details/135305515#comments_31435053" data-report-click='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/135305515#comments_31435053","ab":"new"}' data-report-view='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/135305515#comments_31435053","ab":"new"}'>YOLOv8改进 | 检测头篇 | DynamicHead原论文一比一复现 （不同于网上版本，全网首发）</a>
                <p class="comment ellipsis">
                    <a href="https://blog.csdn.net/m0_59403586" class="user-name" target="_blank">m0_59403586: </a>
                    <span class="code-comments">博主你好，   from mmcv.ops import ModulatedDeformConv2d
ModuleNotFoundError: No module named &#39;mmcv&#39; 这个问题怎么解决</span>
                </p>
            </li>
            <li>
                <a class="title text-truncate" target="_blank" href="https://snu77.blog.csdn.net/article/details/136346900#comments_31434710" data-report-click='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/136346900#comments_31434710","ab":"new"}' data-report-view='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/136346900#comments_31434710","ab":"new"}'>YOLOv8改进 | 独家创新篇 | 结合SOTA思想利用双主干网络改进YOLOv8（全网独家创新，最重磅的更新）</a>
                <p class="comment ellipsis">
                    <a href="https://blog.csdn.net/WTYuong" class="user-name" target="_blank">是Yu欸: </a>
                    <span class="code-comments">这是一篇高质量的好文，深度理解和清晰的表达方式使复杂的技术概念变得容易理解，值得收藏点赞。博主用心很有耐心，更有对知识的热忱和热爱，写了这么实用有效的分享，期盼博主能够光顾我的博客，给予宝贵的指导！</span>
                </p>
            </li>
        </ul>
    </div>
</div>
<div id="asideNewNps" class="aside-box common-nps-box">
    <h3 class="aside-title">您愿意向朋友推荐“博客详情页”吗？</h3>
    <div class="aside-content">
        <ul class="newnps-list">
            <li class="newnps-item" data-type="强烈不推荐">
                <div class="newnps-img-box">
                    <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel1.png" alt="">
                    <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey1.png" alt="">
                </div>
                <div class="newnps-text">强烈不推荐</div>
            </li>
            <li class="newnps-item" data-type="不推荐">
                <div class="newnps-img-box">
                    <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel2.png" alt="">
                    <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey2.png" alt="">
                </div>
                <div class="newnps-text">不推荐</div>
            </li>
            <li class="newnps-item" data-type="一般般">
                <div class="newnps-img-box">
                    <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel3.png" alt="">
                    <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey3.png" alt="">
                </div>
                <div class="newnps-text">一般般</div>
            </li>
            <li class="newnps-item" data-type="推荐">
                <div class="newnps-img-box">
                    <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel4.png" alt="">
                    <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey4.png" alt="">
                </div>
                <div class="newnps-text">推荐</div>
            </li>
            <li class="newnps-item" data-type="强烈推荐">
                <div class="newnps-img-box">
                    <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel5.png" alt="">
                    <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey5.png" alt="">
                </div>
                <div class="newnps-text">强烈推荐</div>
            </li>
        </ul>
        <div class="newnps-form-box">
        <div class="newnps-form">
            <input type="text" placeholder="请输入建议或反馈后点击提交" class="newnps-input">
            <span class="newnps-btn">提交</span>
        </div>
        </div>
    </div>
</div>
<div id="asideArchive" class="aside-box" style="display:block!important; width:300px;">
    <h3 class="aside-title">最新文章</h3>
    <div class="aside-content">
        <ul class="inf_list clearfix">
            <li class="clearfix">
            <a href="https://snu77.blog.csdn.net/article/details/136346900" target="_blank" data-report-click='{"mod":"popu_382","spm":"1001.2101.3001.4136","dest":"https://snu77.blog.csdn.net/article/details/136346900","ab":"new"}' data-report-view='{"mod":"popu_382","dest":"https://snu77.blog.csdn.net/article/details/136346900","ab":"new"}'>YOLOv8改进 | 独家创新篇 | 结合SOTA思想利用双主干网络改进YOLOv8（全网独家创新，最重磅的更新）</a>
            </li>
            <li class="clearfix">
            <a href="https://snu77.blog.csdn.net/article/details/136282783" target="_blank" data-report-click='{"mod":"popu_382","spm":"1001.2101.3001.4136","dest":"https://snu77.blog.csdn.net/article/details/136282783","ab":"new"}' data-report-view='{"mod":"popu_382","dest":"https://snu77.blog.csdn.net/article/details/136282783","ab":"new"}'>YOLOv5改进 | Conv篇 | 全新的SOATA轻量化下采样操作ADown（轻量又涨点，附手撕结构图）</a>
            </li>
            <li class="clearfix">
            <a href="https://snu77.blog.csdn.net/article/details/136278264" target="_blank" data-report-click='{"mod":"popu_382","spm":"1001.2101.3001.4136","dest":"https://snu77.blog.csdn.net/article/details/136278264","ab":"new"}' data-report-view='{"mod":"popu_382","dest":"https://snu77.blog.csdn.net/article/details/136278264","ab":"new"}'>YOLOv8改进 | Conv篇 | 全新的SOATA轻量化下采样操作ADown（参数量下降百分之二十，附手撕结构图）</a>
            </li>
        </ul>
        <div class="archive-bar"></div>
        <div class="archive-box">
                <div class="archive-title">2024</div> 
                <div class="archive-content">
                    <div class="archive-item">
                        <a href="https://snu77.blog.csdn.net?type=blog&amp;year=2024&amp;month=02" target="_blank" data-report-click='{"mod":"popu_538","spm":"1001.2101.3001.4138","ab":"new","dest":"https://snu77.blog.csdn.net?type=blog&amp;year=2024&amp;month=02"}'>
                        <span class="time">02月</span>
                        <span class="count">55篇</span>
                        </a>
                    </div>
                    <div class="archive-item">
                        <a href="https://snu77.blog.csdn.net?type=blog&amp;year=2024&amp;month=01" target="_blank" data-report-click='{"mod":"popu_538","spm":"1001.2101.3001.4138","ab":"new","dest":"https://snu77.blog.csdn.net?type=blog&amp;year=2024&amp;month=01"}'>
                        <span class="time">01月</span>
                        <span class="count">143篇</span>
                        </a>
                    </div>
                </div>
                <div class="archive-list-item"><a href="https://snu77.blog.csdn.net?type=blog&amp;year=2023&amp;month=12" target="_blank" data-report-click='{"mod":"popu_538","spm":"1001.2101.3001.4138","ab":"new","dest":"https://snu77.blog.csdn.net?type=blog&amp;year=2023&amp;month=12"}'><span class="year">2023年</span><span class="num">138篇</span></a></div>
                <div class="archive-list-item"><a href="https://snu77.blog.csdn.net?type=blog&amp;year=2022&amp;month=11" target="_blank" data-report-click='{"mod":"popu_538","spm":"1001.2101.3001.4138","ab":"new","dest":"https://snu77.blog.csdn.net?type=blog&amp;year=2022&amp;month=11"}'><span class="year">2022年</span><span class="num">1篇</span></a></div>
        </div>
    </div>
</div>
    <!-- 详情页显示目录 -->
<!--文章目录-->
<div id="asidedirectory" class="aside-box">
    <div class='groupfile' id="directory">
        <h3 class="aside-title">目录</h3>
        <div class="align-items-stretch group_item">
            <div class="pos-box">
            <div class="scroll-box">
                <div class="toc-box"></div>
            </div>
            </div>
        </div>
    </div>
</div>
</aside>
<script>
	$("a.flexible-btn").click(function(){
		$(this).parents('div.aside-box').removeClass('flexible-box');
		$(this).parents("p.text-center").remove();
	})
</script>
<script type="text/javascript"  src="https://g.csdnimg.cn/user-tooltip/2.7/user-tooltip.js"></script>
<script type="text/javascript"  src="https://g.csdnimg.cn/user-medal/2.0.0/user-medal.js"></script>        </div>
<div class="recommend-right align-items-stretch clearfix" id="rightAside" data-type="recommend">
    <aside class="recommend-right_aside">
        <div id="recommend-right" >
                        <div class='flex-column aside-box groupfile' id="groupfile">
                <div class="groupfile-div">
                <h3 class="aside-title">目录</h3>
                <div class="align-items-stretch group_item">
                    <div class="pos-box">
                        <div class="scroll-box">
                            <div class="toc-box"></div>
                        </div>
                    </div>
                </div>
                </div>
            </div>
            <div class='aside-box kind_person d-flex flex-column'>
                    <h3 class="aside-title">分类专栏</h3>
                    <div class="align-items-stretch kindof_item" id="kind_person_column">
                        <div class="aside-content">
                            <ul>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12483754.html" data-report-click='{"mod":"popu_826","spm":"1001.2101.3001.4230","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12483754.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/direct/d0d498bd4f0c4e17b48ff54e86b67668.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            YOLOv8有效涨点专栏
                                        </span>
                                            <span class="pay-tag">付费</span>
                                    </a>
                                    <span class="special-column-num">125篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12500428.html" data-report-click='{"mod":"popu_826","spm":"1001.2101.3001.4230","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12500428.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/direct/bce35723af3f466e97009ebf18e827aa.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            RT-DETR有效改进专栏
                                        </span>
                                            <span class="pay-tag">付费</span>
                                    </a>
                                    <span class="special-column-num">61篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12500426.html" data-report-click='{"mod":"popu_826","spm":"1001.2101.3001.4230","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12500426.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/direct/6029d5920130491c8f52a4b3005e5f84.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            YOLOv5改进有效专栏
                                        </span>
                                            <span class="pay-tag">付费</span>
                                    </a>
                                    <span class="special-column-num">106篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12583198.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12583198.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/direct/ba2519e7272a4267a3ded30aaa79eb09.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            YOLOv9有效涨点专栏
                                        </span>
                                    </a>
                                    <span class="special-column-num">2篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12464694.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12464694.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/20201014180756913.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            数据集专栏
                                        </span>
                                    </a>
                                    <span class="special-column-num">3篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12551123.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12551123.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/direct/85c6dd75fec842e7a1a36ea95aa69562.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            YOLOv5/v7有效涨点
                                        </span>
                                    </a>
                                    <span class="special-column-num">1篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12510496.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12510496.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/direct/e44ee41c806043f0a3245f74fd5de1db.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            深度学习100题大战
                                        </span>
                                    </a>
                                    <span class="special-column-num">1篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12486438.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12486438.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/20201014180756738.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            活动专栏
                                        </span>
                                    </a>
                                    <span class="special-column-num">2篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12285732.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12285732.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/20201014180756919.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            目标检测专栏
                                        </span>
                                    </a>
                                    <span class="special-column-num">3篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12441087.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12441087.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/direct/5ae08a29357d42a9b849b054be235894.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            时间序列预测专栏
                                        </span>
                                    </a>
                                    <span class="special-column-num">35篇</span>
                                </li>
                            </ul>
                        </div>
                    </div>
            </div>
        </div>
    </aside>
</div>

<div class="recommend-right1  align-items-stretch clearfix" id="rightAsideConcision" data-type="recommend">
    <aside class="recommend-right_aside">
        <div id="recommend-right-concision" >
            <div class='flex-column aside-box groupfile' id="groupfileConcision">
                <div class="groupfile-div1">
                <h3 class="aside-title">目录</h3>
                <div class="align-items-stretch group_item">
                    <div class="pos-box">
                        <div class="scroll-box">
                            <div class="toc-box"></div>
                        </div>
                    </div>
                </div>
                </div>
            </div>
        </div>
    </aside>
</div>

      </div>
      <div class="mask-dark"></div>
      <div class="skin-boxshadow"></div>
      <div class="directory-boxshadow"></div>
<div class="comment-side-box-shadow comment-side-tit-close" id="commentSideBoxshadow">
<div class="comment-side-content">
	<div class="comment-side-tit">
		<div class="comment-side-tit-count">评论&nbsp;<span class="count">79</span></div>
	<img class="comment-side-tit-close" src="https://csdnimg.cn/release/blogv2/dist/pc/img/closeBt.png"></div>
	<div id="pcCommentSideBox" class="comment-box comment-box-new2 " style="display:block">
    <div class="comment-edit-box d-flex">
      <div class="user-img">
        <a href="https://blog.csdn.net/DreamSun527" target="_blank">
          <img src="https://profile-avatar.csdnimg.cn/default.jpg!1">
        </a>
      </div>
      <form id="commentform">
        <textarea class="comment-content" name="comment_content" id="comment_content" placeholder="欢迎高质量的评论，低质的评论会被折叠" maxlength="1000"></textarea>
        <div class="comment-reward-box" style="background-image: url('https://img-home.csdnimg.cn/images/20230131025301.png');">
          <a class="btn-remove-reward"></a>
          <div class="form-reward-box">
            <div class="info">
              成就一亿技术人!
            </div>
            <div class="price-info">
              拼手气红包<span class="price">6.0元</span>
            </div>
          </div>
        </div>
        <div class="comment-operate-box">
          <div class="comment-operate-l">
            <span id="tip_comment" class="tip">还能输入<em>1000</em>个字符</span>
          </div>
          <div class="comment-operate-c">
            &nbsp;
          </div>
          <div class="comment-operate-r">
            <div class="comment-operate-item comment-reward">
              <img class="comment-operate-img" data-url="https://csdnimg.cn/release/blogv2/dist/pc/img/" src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentReward.png" alt="红包">
              <span class="comment-operate-tip">添加红包</span>
            </div>
            <div class="comment-operate-item comment-emoticon">
              <img class="comment-operate-img" data-url="https://csdnimg.cn/release/blogv2/dist/pc/img/" src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentEmotionIcon.png" alt="表情包">
              <span class="comment-operate-tip">插入表情</span>
              <div class="comment-emoticon-box comment-operate-isshow">
                <div class="comment-emoticon-img-box"></div>
              </div>
            </div>
            <div class="comment-operate-item comment-code">
              <img class="comment-operate-img" data-url="https://csdnimg.cn/release/blogv2/dist/pc/img/" src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentCodeIcon.png" alt="表情包">
              <span class="comment-operate-tip">代码片</span>
              <div class="comment-code-box comment-operate-isshow">
                <ul id="commentCode">
                  <li><a data-code="html">HTML/XML</a></li>
                  <li><a data-code="objc">objective-c</a></li>
                  <li><a data-code="ruby">Ruby</a></li>
                  <li><a data-code="php">PHP</a></li>
                  <li><a data-code="csharp">C</a></li>
                  <li><a data-code="cpp">C++</a></li>
                  <li><a data-code="javascript">JavaScript</a></li>
                  <li><a data-code="python">Python</a></li>
                  <li><a data-code="java">Java</a></li>
                  <li><a data-code="css">CSS</a></li>
                  <li><a data-code="sql">SQL</a></li>
                  <li><a data-code="plain">其它</a></li>
                </ul>
              </div>
            </div>
            <div class="comment-operate-item">
              <input type="hidden" id="comment_replyId" name="comment_replyId">
              <input type="hidden" id="article_id" name="article_id" value="134432710">
              <input type="hidden" id="comment_userId" name="comment_userId" value="">
              <input type="hidden" id="commentId" name="commentId" value="">
              <a data-report-click='{"mod":"1582594662_003","spm":"1001.2101.3001.4227","ab":"new"}'>
              <input type="submit" class="btn-comment btn-comment-input" value="评论">
              </a>
            </div>
          </div>
        </div>
      </form>
    </div>
		<div class="comment-list-container">
			<div class="comment-list-box comment-operate-item">
			</div>
			<div id="lookGoodComment" class="look-good-comment side-look-comment">
				<a class="look-more-comment">查看更多评论<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentArrowDownBlack.png" alt=""></a>
			</div>
			<div id="lookFlodComment" class="look-flod-comment">
					<span class="count"></span>&nbsp;条评论被折叠&nbsp;<a class="look-more-flodcomment">查看</a>
			</div>
			<div class="opt-box text-center">
				<div class="btn btn-sm btn-link-blue" id="btnMoreComment"></div>
			</div>
		</div>
	</div>
	<div id="pcFlodCommentSideBox" class="pc-flodcomment-sidebox">
		<div class="comment-fold-tit"><span id="lookUnFlodComment" class="back"><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentArrowLeftBlack.png" alt=""></span>被折叠的&nbsp;<span class="count"></span>&nbsp;条评论
		 <a href="https://blogdev.blog.csdn.net/article/details/122245662" class="tip" target="_blank">为什么被折叠?</a>
		 <a href="https://bbs.csdn.net/forums/FreeZone" class="park" target="_blank">
		 <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/iconPark.png">到【灌水乐园】发言</a>                                
		</div>
		<div class="comment-fold-content"></div>
		<div id="lookBadComment" class="look-bad-comment side-look-comment">
			<a class="look-more-comment">查看更多评论<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentArrowDownBlack.png" alt=""></a>
		</div>
	</div>
</div>
<div class="comment-rewarddialog-box">
  <div class="form-box">
    <div class="title-box">
      添加红包
      <a class="btn-form-close"></a>
    </div>
    <form id="commentRewardForm">
      <div class="ipt-box">
        <label for="txtName">祝福语</label>
        <div class="ipt-btn-box">
          <input type="text" name="name" id="txtName" autocomplete="off" maxlength="50">
          <a class="btn-ipt btn-random"></a>
        </div>
        <p class="notice">请填写红包祝福语或标题</p>
      </div>
      <div class="ipt-box">
        <label for="txtSendAmount">红包数量</label>
        <div class="ipt-txt-box">
          <input type="text" name="sendAmount" maxlength="4" id="txtSendAmount" placeholder="请填写红包数量(最小10个)" autocomplete="off">
          <span class="after-txt">个</span>
        </div>
        <p class="notice">红包个数最小为10个</p>
      </div>
      <div class="ipt-box">
        <label for="txtMoney">红包总金额</label>
        <div class="ipt-txt-box error">
          <input type="text" name="money" maxlength="5" id="txtMoney" placeholder="请填写总金额(最低5元)" autocomplete="off">
          <span class="after-txt">元</span>
        </div>
        <p class="notice">红包金额最低5元</p>
      </div>
      <div class="balance-info-box">
        <label>余额支付</label>
        <div class="balance-info">
          当前余额<span class="balance">3.43</span>元
          <a href="https://i.csdn.net/#/wallet/balance/recharge" class="link-charge" target="_blank">前往充值 ></a>
        </div>
      </div>
      <div class="opt-box">
        <div class="pay-info">
          需支付：<span class="price">10.00</span>元
        </div>
        <button type="button" class="ml-auto btn-cancel">取消</button>
        <button type="button" class="ml8 btn-submit" disabled="true">确定</button>
      </div>
    </form>
  </div>
</div>
<div class="rr-guide-box">
  <div class="rr-first-box">
    <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/guideRedReward02.png" alt="">
    <button class="btn-guide-known next">下一步</button>
  </div>
  <div class="rr-second-box">
    <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/guideRedReward03.png" alt="">
    <button class="btn-guide-known known">知道了</button>
  </div>
</div>
</div>

<div class="redEnvolope" id="redEnvolope">
  <div class="env-box">
    <div class="env-container">
      <div class="pre-open" id="preOpen">
        <div class="top">
          <header>
            <img class="clearTpaErr" :src="redpacketAuthor.avatar" alt="" />
            <div class="author">成就一亿技术人!</div>
          </header>
          <div class="bot-icon"></div>
        </div>
        <footer>
          <div class="red-openbtn open-start"></div>
          <div class="tip">
            领取后你会自动成为博主和红包主的粉丝
            <a class="rule" target="_blank">规则</a>
          </div>
        </footer>
      </div>
      <div class="opened" id="opened">
        <div class="bot-icon">
          <header>
            <a class="creatorUrl" href="" target="_blank">
              <img class="clearTpaErr" src="https://profile-avatar.csdnimg.cn/default.jpg!2" alt="" />
            </a>
            <div class="author">
              <div class="tt">hope_wisdom</div> 发出的红包
            </div>
          </header>
        </div>
        <div class="receive-box">
          <header></header>
          <div class="receive-list">
          </div>
        </div>
      </div>
    </div>
    <div class="close-btn"></div>
  </div>
</div>
<div id="rewardNew" class="reward-popupbox-new">
	<p class="rewad-title">打赏作者<span class="reward-close"><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/closeBt.png"></span></p>
	<dl class="profile-box">
		<dd>
		<a href="https://snu77.blog.csdn.net" data-report-click='{"mod":"popu_379","dest":"https://snu77.blog.csdn.net","ab":"new"}'>
			<img src="https://profile-avatar.csdnimg.cn/27160f4941a54d07b535ceabcfa4a800_java1314777.jpg!1" class="avatar_pic">
		</a>
		</dd>
		<dt>
			<p class="blog-name">Snu77</p>
			<p class="blog-discript">你的鼓励将是我创作的最大动力</p>
		</dt>
	</dl>
	<div class="reward-box-new">
			<div class="reward-content"><div class="reward-right"></div></div>
	</div>
	<div class="money-box">
    <span class="choose-money choosed" data-id="1">¥1</span>
    <span class="choose-money " data-id="2">¥2</span>
    <span class="choose-money " data-id="4">¥4</span>
    <span class="choose-money " data-id="6">¥6</span>
    <span class="choose-money " data-id="10">¥10</span>
    <span class="choose-money " data-id="20">¥20</span>
	</div>
	<div class="sure-box">
		<div class="sure-box-money">
			<div class="code-box">
				<div class="code-num-box">
					<span class="code-name">扫码支付：</span><span class="code-num">¥1</span>
				</div>
				<div class="code-img-box">
					<div class="renovate">
					<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/pay-time-out.png">
					<span>获取中</span>
					</div>
				</div>
				<div class="code-pay-box">
					<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newWeiXin.png" alt="">
					<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newZhiFuBao.png" alt="">
					<span>扫码支付</span>
				</div>
			</div>
		</div>
		<div class="sure-box-blance">
			<p class="tip">您的余额不足，请更换扫码支付或<a target="_blank" data-report-click='{"mod":"1597646289_003","spm":"1001.2101.3001.4302"}' href="https://i.csdn.net/#/wallet/balance/recharge?utm_source=RewardVip" class="go-invest">充值</a></p>
			<p class="is-have-money"><a class="reward-sure">打赏作者</a></p>
		</div>
	</div>
</div>
      
      <div class="pay-code">
      <div class="pay-money">实付<span class="pay-money-span" data-nowprice='' data-oldprice=''>元</span></div>
      <div class="content-blance"><a class="blance-bt" href="javascript:;">使用余额支付</a></div>
      <div class="content-code">
        <div id="payCode" data-id="">
          <div class="renovate">
            <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/pay-time-out.png">
            <span>点击重新获取</span>
          </div>
        </div>
        <div class="pay-style"><span><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/weixin.png"></span><span><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/zhifubao.png"></span><span><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/jingdong.png"></span><span class="text">扫码支付</span></div>
      </div>
      <div class="bt-close">
        <svg t="1567152543821" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="10924" xmlns:xlink="http://www.w3.org/1999/xlink" width="12" height="12">
          <defs>
            <style type="text/css"></style>
          </defs>
          <path d="M512 438.378667L806.506667 143.893333a52.032 52.032 0 1 1 73.6 73.621334L585.621333 512l294.485334 294.485333a52.074667 52.074667 0 0 1-73.6 73.642667L512 585.621333 217.514667 880.128a52.053333 52.053333 0 1 1-73.621334-73.642667L438.378667 512 143.893333 217.514667a52.053333 52.053333 0 1 1 73.621334-73.621334L512 438.378667z" fill="" p-id="10925"></path>
        </svg>
      </div>
      <div class="pay-balance">
        <input type="radio" class="pay-code-radio" data-type="details">
        <span class="span">钱包余额</span>
          <span class="balance" style="color:#FC5531;font-size:14px;">0</span>
          <div class="pay-code-tile">
            <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/pay-help.png" alt="">
            <div class="pay-code-content">
              <div class="span">
                <p class="title">抵扣说明：</p>
                <p> 1.余额是钱包充值的虚拟货币，按照1:1的比例进行支付金额的抵扣。<br> 2.余额无法直接购买下载，可以购买VIP、付费专栏及课程。</p>
              </div>
            </div>
          </div>
      </div>
      <a class="pay-balance-con" href="https://i.csdn.net/#/wallet/balance/recharge" target="_blank"><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/recharge.png" alt=""><span>余额充值</span></a>
    </div>
    <div style="display:none;">
      <img src="" onerror='setTimeout(function(){if(!/(csdn.net|iteye.com|baiducontent.com|googleusercontent.com|360webcache.com|sogoucdn.com|bingj.com|baidu.com)$/.test(window.location.hostname)){window.location.href="\x68\x74\x74\x70\x73\x3a\x2f\x2f\x77\x77\x77\x2e\x63\x73\x64\x6e\x2e\x6e\x65\x74"}},3000);'>
    </div>
    <div class="keyword-dec-box" id="keywordDecBox"></div>
  </body>
    <!-- 富文本柱状图  -->
    <link rel="stylesheet" href="https://csdnimg.cn/release/blog_editor_html/release1.6.12/ckeditor/plugins/chart/chart.css" />
    <script type="text/javascript" src="https://csdnimg.cn/release/blog_editor_html/release1.6.12/ckeditor/plugins/chart/lib/chart.min.js"></script>
    <script type="text/javascript" src="https://csdnimg.cn/release/blog_editor_html/release1.6.12/ckeditor/plugins/chart/widget2chart.js"></script>
  <script src="https://csdnimg.cn/release/blogv2/dist/components/js/axios-83fa28cedf.min.js" type="text/javascript"></script>
  <script src="https://csdnimg.cn/release/blogv2/dist/components/js/pc_wap_highlight-8defd55d6e.min.js" type="text/javascript"></script>
  <script src="https://csdnimg.cn/release/blogv2/dist/components/js/pc_wap_common-be82269d23.min.js" type="text/javascript"></script>
  <script src="https://csdnimg.cn/release/blogv2/dist/components/js/edit_copy_code-27143fd02b.min.js" type="text/javascript"></script>
  <link rel="stylesheet" href="https://csdnimg.cn/release/blog_editor_html/release1.6.12/ckeditor/plugins/codesnippet/lib/highlight/styles/tomorrow-night.css">
  <script src="https://g.csdnimg.cn/user-accusation/1.0.6/user-accusation.js" type="text/javascript"></script>
  <script>
    // 全局声明
    if (window.csdn === undefined) {
      window.csdn = {};
    }
    window.csdn.sideToolbar = {
      options: {
        report: {
          isShow: true,
        },
        qr: {
          isShow: false,
        },
        guide: {
          isShow: true
        }
      }
    }
    $(function() {
      $(document).on('click', "a.option-box[data-type='report']", function() {
        window.csdn.loginBox.key({
          biz: 'blog',
          subBiz: 'other_service',
          cb: function() {
            window.csdn.feedback({
              "type": 'blog',
              "rtype": 'article',
              "rid": articleId,
              "reportedName": username,
              "submitOptions": {
                "title": articleTitle,
                "contentUrl": articleDetailUrl
              },
              "callback": function() {
                showToast({
                  text: "感谢您的举报，我们会尽快审核！",
                  bottom: '10%',
                  zindex: 9000,
                  speed: 500,
                  time: 1500
                })
              }
            })
          }
        })
      });
    })
  </script>
    <script src="https://g.csdnimg.cn/baidu-search/1.0.12/baidu-search.js" type="text/javascript"></script>
  <script src="https://csdnimg.cn/release/download/old_static/js/qrcode.js"></script>
  <script src="https://g.csdnimg.cn/lib/qrcode/1.0.0/qrcode.min.js"></script>
  <script src="https://g.csdnimg.cn/user-ordercart/3.0.1/user-ordercart.js" type="text/javascript"></script>
  <script src="https://g.csdnimg.cn/user-ordertip/5.0.3/user-ordertip.js" type="text/javascript"></script>
  <script src="https://g.csdnimg.cn/order-payment/4.0.5/order-payment.js" type="text/javascript"></script>
  <script src="https://csdnimg.cn/release/blogv2/dist/pc/js/common-a425354f6a.min.js" type="text/javascript"></script>
  <script src="https://csdnimg.cn/release/blogv2/dist/pc/js/detail-0655e5d8db.min.js" type="text/javascript"></script>
  <script src="https://csdnimg.cn/release/blogv2/dist/pc/js/column-35b87614d0.min.js" type="text/javascript"></script>
  <script src="https://g.csdnimg.cn/side-toolbar/3.4/side-toolbar.js" type="text/javascript"></script>
    <script>
    window.csdn.extensionBox = window.csdn.extensionBox ? window.csdn.extensionBox : {};
    window.csdn.extensionBox.extensionBoxParams = {
      inited: function() {
        var extensionBox = document.getElementById('blogExtensionBox'); // 位置dom元素
        window.csdn.extensionBox.show({
          isdark: true, // 是否黑皮肤
          voteusername: "java1314777",
          posDom: extensionBox, // 插入位置 selectorString || 位置dom元素
          codyFn: () => {
            //复制成功回调函数
            showToast({
              text: '复制成功（作者已获得对应原力分）!',
              bottom: '10%', //toast距离页面底部的距离
              zindex: 9000, //为了防止被其他控件遮盖，z-index默认为2
              speed: 500, //toast的显示速度
              time: 1500 //toast显示多久以后消失
            });
          }
        });
      }
    }
    </script>
    <script src="https://g.csdnimg.cn/extension-box/1.1.7/extension-box.js" type="text/javascript"></script>
  <script src="https://g.csdnimg.cn/copyright/1.0.4/copyright.js" type="text/javascript"></script>
  <script>
    $(".MathJax").remove();
    if ($('div.markdown_views pre.prettyprint code.hljs').length > 0) {
      $('div.markdown_views')[0].className = 'markdown_views';
    }
  </script>
  <script type="text/javascript" src="https://csdnimg.cn/release/blog_mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      "HTML-CSS": {
        linebreaks: { automatic: true, width: "94%container" },
        imageFont: null
      },
      tex2jax: {
      preview: "none",
      ignoreClass:"title-article"
      },
      mml2jax: {
      preview: 'none'
      }
    });
  </script>
<script type="text/javascript" crossorigin src="https://g.csdnimg.cn/common/csdn-login-box/csdn-login-box.js"></script></html>