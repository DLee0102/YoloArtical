    <!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <link rel="canonical" href="https://blog.csdn.net/java1314777/article/details/135024120"/>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="renderer" content="webkit"/>
    <meta name="force-rendering" content="webkit"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="report" content='{"pid": "blog", "spm":"1001.2101"}'>
    <meta name="referrer" content="always">
    <meta http-equiv="Cache-Control" content="no-siteapp" /><link rel="alternate" media="handheld" href="#" />
    <meta name="shenma-site-verification" content="5a59773ab8077d4a62bf469ab966a63b_1497598848">
    <meta name="applicable-device" content="pc">
    <link  href="https://g.csdnimg.cn/static/logo/favicon32.ico"  rel="shortcut icon" type="image/x-icon" />
    <title>YOLOv8改进 | 2023Neck篇 | 利用Gold-YOLO改进YOLOv8对小目标检测-CSDN博客</title>
    <script>
      (function(){ 
        var el = document.createElement("script"); 
        el.src = "https://s3a.pstatp.com/toutiao/push.js?1abfa13dfe74d72d41d83c86d240de427e7cac50c51ead53b2e79d40c7952a23ed7716d05b4a0f683a653eab3e214672511de2457e74e99286eb2c33f4428830"; 
        el.id = "ttzz"; 
        var s = document.getElementsByTagName("script")[0]; 
        s.parentNode.insertBefore(el, s);
      })(window)
    </script>
        <meta name="keywords" content="gold-yolo">
        <meta name="csdn-baidu-search"  content='{"autorun":true,"install":true,"keyword":"gold-yolo"}'>
    <meta name="description" content="文章浏览阅读2.1k次，点赞31次，收藏27次。本文给大家带来的改进机制是Gold-YOLO利用其Neck改进v8的Neck，GoLd-YOLO引入了一种新的机制——信息聚集-分发（Gather-and-Distribute, GD）。这个机制通过全局融合不同层次的特征并将融合后的全局信息注入到各个层级中，从而实现更高效的信息交互和融合。这种方法增强了模型的颈部（neck）信息融合能力(有点类似于长颈鹿的脖子该Neck部分很长)，同时也没有显著增加延迟，提高了模型在检测不同大小物体时的性能，同时欢迎大家订阅本专栏，本专栏每周更新3-5篇最新机制，更有包含_gold-yolo">
        <link rel="stylesheet" type="text/css" href="https://csdnimg.cn/release/blogv2/dist/pc/css/detail_enter-38ddee24dc.min.css">
    <style>
        #content_views{
            -webkit-touch-callout: none;
            -webkit-user-select: none;
            -khtml-user-select: none;
            -moz-user-select: none;
            -ms-user-select: none; 
            user-select: none; 
        }
    </style>
    <script type="application/ld+json">{"@context":"https://ziyuan.baidu.com/contexts/cambrian.jsonld","@id":"https://blog.csdn.net/java1314777/article/details/135024120","appid":"1638831770136827","pubDate":"2023-12-15T19:39:51","title":"YOLOv8改进 | 2023Neck篇 | 利用Gold-YOLO改进YOLOv8对小目标检测-CSDN博客","upDate":"2024-01-05T01:14:32"}</script>
        <link rel="stylesheet" type="text/css" href="https://csdnimg.cn/release/blogv2/dist/pc/themesSkin/skin-blackwhale/skin-blackwhale-fcd12bc8ae.min.css">
    <script src="https://csdnimg.cn/public/common/libs/jquery/jquery-1.9.1.min.js" type="text/javascript"></script>
    <script type="text/javascript">
        var isCorporate = false;//注释删除enterprise
        var username =  "java1314777";
        var skinImg = "white";
        var blog_address = "https://snu77.blog.csdn.net";
        var currentUserName = "DreamSun527";
        var isOwner = false;
        var loginUrl = "http://passport.csdn.net/account/login?from=https://blog.csdn.net/java1314777/article/details/135024120";
        var blogUrl = "https://blog.csdn.net/";
        var avatar = "https://profile-avatar.csdnimg.cn/27160f4941a54d07b535ceabcfa4a800_java1314777.jpg!1";
        var articleTitle = "YOLOv8改进 | 2023Neck篇 | 利用Gold-YOLO改进YOLOv8对小目标检测";
        var articleDesc = "文章浏览阅读2.1k次，点赞31次，收藏27次。本文给大家带来的改进机制是Gold-YOLO利用其Neck改进v8的Neck，GoLd-YOLO引入了一种新的机制——信息聚集-分发（Gather-and-Distribute, GD）。这个机制通过全局融合不同层次的特征并将融合后的全局信息注入到各个层级中，从而实现更高效的信息交互和融合。这种方法增强了模型的颈部（neck）信息融合能力(有点类似于长颈鹿的脖子该Neck部分很长)，同时也没有显著增加延迟，提高了模型在检测不同大小物体时的性能，同时欢迎大家订阅本专栏，本专栏每周更新3-5篇最新机制，更有包含_gold-yolo";
        var articleTitles = "YOLOv8改进 | 2023Neck篇 | 利用Gold-YOLO改进YOLOv8对小目标检测-CSDN博客";
        var nickName = "Snu77";
        var articleDetailUrl = "https://snu77.blog.csdn.net/article/details/135024120";
        var vipUrlV = "https://mall.csdn.net/svip?utm_source=learningVIPX";
        if(window.location.host.split('.').length == 3) {
            blog_address = blogUrl + username;
        }
        var skinStatus = "Black";
        var robotModule = '';
        var robotModuleJs = '';
        var blogStaticHost = "https://csdnimg.cn/release/blogv2/"
        var mallTestStyle = "control"
    </script>
        <meta name="toolbar" content='{"type":"1","fixModel":"1"}'>
        <script>
            window.csdn = window.csdn ? window.csdn : {};
            window.csdn.toolbarIsBlack = true;
            window.csdn.sideToolbar = {
                options: {
                    theme : "black"
                }
            }
        </script>
    <script src="https://g.csdnimg.cn/??fixed-sidebar/1.1.7/fixed-sidebar.js" type="text/javascript"></script>
    <script src='//g.csdnimg.cn/common/csdn-report/report.js' type='text/javascript'></script>
    <link rel="stylesheet" type="text/css" href="https://csdnimg.cn/public/sandalstrap/1.4/css/sandalstrap.min.css">
    <style>
        .MathJax, .MathJax_Message, .MathJax_Preview{
            display: none
        }
    </style>
    <script src="https://dup.baidustatic.com/js/ds.js"></script>
</head>
  <body class="nodata is_black_skin " style="">
    <div id="toolbarBox" style="min-height: 48px;"></div>
        <script>
            var toolbarSearchExt = '{"landingWord":["gold-yolo"],"queryWord":"","tag":["人工智能","计算机视觉","深度学习","YOLO","pytorch","python","目标检测"],"title":"YOLOv8改进 | 2023Neck篇 | 利用Gold-YOLO改进YOLOv8对小目标检测"}';
        </script>
    <script src="https://g.csdnimg.cn/common/csdn-toolbar/csdn-toolbar.js" type="text/javascript"></script>
    <script>
    (function(){
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
    </script>

    <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/pc/css/blog_code-01256533b5.min.css">
    <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/chart-3456820cac.css" />
    <link rel="stylesheet" href="https://g.csdnimg.cn/lib/swiper/6.0.4/css/swiper.css" />
    <script src="https://g.csdnimg.cn/lib/swiper/6.0.4/js/swiper.js" async></script>
    <script>
      var articleId = 135024120;
      var commentscount = 3;
      var commentAuth = 2;
      var curentUrl = "https://blog.csdn.net/java1314777/article/details/135024120";
      var myUrl = "https://my.csdn.net/";
        var highlight = ["2023neck","pytorch","python","计算机视觉","gold","yolo","目标检测","深度学习","人工智能","v8","利用","改进","篇"];//高亮数组
        var isRecommendModule = true;
          var isBaiduPre = true;
          var baiduCount = 2;
          var setBaiduJsCount = 10;
      var share_card_url = "https://app-blog.csdn.net/share?article_id=135024120&username=java1314777"
      var mallVipUrl = "https://mall.csdn.net/vip?vipSource=article"
      var vipArticleAbStyle = "t_2"
      var vipArticleCpStyle = "t_2"
      var articleType = 1;
      var baiduKey = "gold-yolo";
      var copyPopSwitch = true;
      var needInsertBaidu = true;
      var recommendRegularDomainArr = ["blog.csdn.net/.+/article/details/","download.csdn.net/download/","edu.csdn.net/course/detail/","ask.csdn.net/questions/","bbs.csdn.net/topics/","www.csdn.net/gather_.+/"]
      var codeStyle = "tomorrow-night";
      var baiduSearchType = "baidulandingword";
      var sharData = "{\"hot\":[{\"id\":1,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/a5f4260710904e538002a6ab337939b3.png\"},{\"id\":2,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/188b37199a2c4b74b1d9ffc39e0d52de.png\"},{\"id\":3,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/14ded358b631444581edd98a256bc5af.png\"},{\"id\":4,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/1470f23a770444d986ad551b9c33c5be.png\"},{\"id\":5,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/c329f5181dc74f6c9bd28c982bb9f91d.png\"},{\"id\":6,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/ccd8a3305e81460f9c505c95b432a65f.png\"},{\"id\":7,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/bc89d8283389440d97fc4d30e30f45e1.png\"},{\"id\":8,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/452d485b4a654f5592390550d2445edf.png\"},{\"id\":9,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/f8b9939db2ed474a8f43a643015fc8b7.png\"},{\"id\":10,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/6de8864187ab4ed3b1db0856369c36ff.png\"},{\"id\":11,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/673cc3470ff74072acba958dc0c46e2d.png\"},{\"id\":12,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/930c119760ac4491804db80f9c6d4e3f.png\"},{\"id\":13,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/15e6befb05a24233bc2b65e96aa8d972.png\"},{\"id\":14,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/2075fd6822184b95a41e214de4daec13.png\"},{\"id\":15,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/859b1552db244eb6891a809263a5c657.png\"},{\"id\":16,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/0be2f920f1f74290a98921974a9613fd.png\"},{\"id\":17,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/2e97e00b43f14afab494ea55ef3f4a6e.png\"},{\"id\":18,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/ff4ab252f46e444686f5135d6ebbfec0.png\"},{\"id\":19,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/ae029bbe99564e79911657912d36524f.png\"},{\"id\":20,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/b3ece39963de440388728e9e7b9bf427.png\"},{\"id\":21,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/6f14651a99ba486e926d63b6fa692997.png\"},{\"id\":22,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/83ceddf050084875a341e32dcceca721.png\"},{\"id\":23,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/b90368b8fd5d4c6c8c79a707d877cf7c.png\"},{\"id\":24,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/aeffae14ecf14e079b2616528c9a393b.png\"},{\"id\":25,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/c5a06b5a13d44d16bed868fc3384897a.png\"},{\"id\":26,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/08b697658b844b318cea3b119e9541ef.png\"},{\"id\":27,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/68ccb0b8d09346ac961d2b5c1a8c77bf.png\"},{\"id\":28,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/a2227a247e37418cbe0ea972ba6a859b.png\"},{\"id\":29,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/3a42825fede748f9993e5bb844ad350d.png\"},{\"id\":30,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/8882abc1dd484224b636966ea38555c3.png\"},{\"id\":31,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/4f6a5f636a3e444d83cf8cc06d87a159.png\"},{\"id\":32,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/1953ef79c56b4407b78d7181bdff11c3.png\"},{\"id\":33,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/c04a2a4f772948ed85b5b0380ed36287.png\"},{\"id\":34,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/5b4fecd05091405ea04d8c0f53e9f2c7.png\"},{\"id\":35,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/b89f576d700344e280d6ceb2a66c2420.png\"},{\"id\":36,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/1c65780e11804bbd9971ebadb3d78bcf.png\"},{\"id\":37,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/d590db2055f345db9706eb68a7ec151a.png\"},{\"id\":38,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/fe602f80700b4f6fb3c4a9e4c135510e.png\"},{\"id\":39,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/39ff2fcd31e04feba301a071976a0ba7.png\"},{\"id\":40,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/f9b61b3d113f436b828631837f89fb39.png\"},{\"id\":41,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/df1aca5f610c4ad48cd16da88c9c8499.png\"},{\"id\":42,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/d7acf73a1e6b41399a77a85040e10961.png\"},{\"id\":43,\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/b7f1b63542524b97962ff649ab4e7e23.png\"}],\"vip\":[{\"id\":1,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101150.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101154.png\"},{\"id\":2,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101204.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101208.png\"},{\"id\":3,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101211.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101215.png\"},{\"id\":4,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101218.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101220.png\"},{\"id\":5,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101223.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220920101226.png\"},{\"id\":6,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220922100635.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220922100639.png\"},{\"id\":7,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220922100642.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220922100644.png\"},{\"id\":8,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220922100647.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220922100649.png\"},{\"id\":9,\"vipUrl\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220922100652.png\",\"url\":\"https:\\/\\/img-home.csdnimg.cn\\/images\\/20220922100655.png\"},{\"id\":10,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/55de67481fde4b04b97ad78f11fe369a.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/bb2418fb537e4d78b10d8765ccd810c5.png\"},{\"id\":11,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/579c713394584d128104ef1044023954.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/f420d9fbcf5548079d31b5e809b6d6cd.png\"},{\"id\":12,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/75b7f3155ba642f5a4cc16b7baf44122.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/a9030f5877be401f8b340b80b0d91e64.png\"},{\"id\":13,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/0903d33cafa54934be3780aa54ae958d.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/2cd8c8929f5a42fca5da2a0aeb456203.png\"},{\"id\":14,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/949fd7c22884439fbfc3c0e9c3b8dee7.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/dafbea9bd9eb4f3b962b48dc41657f89.png\"},{\"id\":15,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/4119cfddd71d4e6a8a27a18dbb74d90e.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/c56310c8b6384d9e85388e4e342ce508.png\"},{\"id\":16,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/121575274da142bcbbbbc2e8243dd411.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/5013993de06542f881018bb9abe2edf7.png\"},{\"id\":17,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/4d97aa6dd4fe4f09a6bef5bdf8a6abcd.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/76f23877b6ad4066ad45ce8e31b4b977.png\"},{\"id\":18,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/fdb619daf21b4c829de63b9ebc78859d.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/a1abe5d27a5441f599adfe662f510243.png\"},{\"id\":19,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/676b7707bb11410f8f56bc0ed2b2345c.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/7ac5b467fbf24e1d8c2de3f3332c4f54.png\"},{\"id\":20,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/0becb8cc227e4723b765bdd69a20fd4a.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/fdec85b26091486b9a89d0b8d45c3749.png\"},{\"id\":21,\"vipUrl\":\"https:\\/\\/img-blog.csdnimg.cn\\/1a6c06235ad44941b38c54cbc25a370c.png\",\"url\":\"https:\\/\\/img-blog.csdnimg.cn\\/410a06cda2d44b0c84578f88275caf70.png\"}],\"map\":{\"hot\":\"热门\",\"vip\":\"VIP\"}}";
      
      var canRead = true;
      var blogMoveHomeArticle = false;
      var showSearchText = "";
      var articleSource = 1;
      var articleReport = '{"pid": "blog", "spm":"1001.2101"}';
        var baiduSearchChannel = 'pc_relevant'
        var baiduSearchIdentification = '.235^v43^pc_blog_bottom_relevance_base5'
        var distRequestId = '1709120647945_16439'
        var initRewardObject = {
          giver: "DreamSun527",
          anchor: "java1314777",
          articleId: "135024120",
          sign: "adb60dfa0b92fd5723f3ccfaa9b5a252",
        }
        var isLikeStatus = false;
        var isUnLikeStatus = false;
        var studyLearnWord = "";
        var unUseCount = 0;
        var codeMaxSize = 0;
        var overCost = true;
        var isCurrentUserVip = false;
        var contentViewsHeight = 0;
        var contentViewsCount = 0;
        var contentViewsCountLimit = 5;
        var isShowConcision = true
      var isCookieConcision = false
      var isHasDirectoryModel = false
      var isShowSideModel = false
      var isShowDirectoryModel = true
      function getCookieConcision(sName){
        var allCookie = document.cookie.split("; ");
        for (var i=0; i < allCookie.length; i++){
          var aCrumb = allCookie[i].split("=");
          if (sName == aCrumb[0])
            return aCrumb[1];
        }
        return null;
      }
      if (getCookieConcision('blog_details_concision') && getCookieConcision('blog_details_concision') == 0){
        isCookieConcision = true
        isShowSideModel = true
        isShowDirectoryModel = false
      }
    </script>
        <div class="main_father clearfix d-flex justify-content-center mainfather-concision" style="height:100%;">
          <div class="container clearfix container-concision" id="mainBox">
          <script>
          if (!isCookieConcision) {
            $('.main_father').removeClass('mainfather-concision')
            $('.main_father .container').removeClass('container-concision')
          } else {
            $('#mainBox').css('margin-right', '0')
          }
          </script>
          <main>
<script type="text/javascript">
    var resourceId =  "";
    function getQueryString(name) {   
      var reg = new RegExp("(^|&)" + name + "=([^&]*)(&|$)"); //构造一个含有目标参数的正则表达式对象  
      var r = window.location.search.substr(1).match(reg);  //匹配目标参数
      if( r != null ) return decodeURIComponent( r[2] ); return '';   
    }
    function stripscript(s){ 
      var pattern = new RegExp("[`~!@#$^&*()=|{}':;',\\[\\].<>/?~！@#￥……&*（）——|{}【】‘；：”“'。，、？%]") 
      var rs = ""; 
      for (var i = 0; i < s.length; i++) { 
        rs = rs+s.substr(i, 1).replace(pattern, ''); 
      } 
      return rs;
    }
    var blogHotWords = stripscript(getQueryString('utm_term')).length > 1 ? stripscript(getQueryString('utm_term')) : ''
</script>
<div class="blog-content-box">
    <div class="article-header-box">
        <div class="article-header">
            <div class="article-title-box">
                <h1 class="title-article" id="articleContentId">YOLOv8改进 | 2023Neck篇 | 利用Gold-YOLO改进YOLOv8对小目标检测</h1>
            </div>
            <div class="article-info-box">
                <div class="article-bar-top">
                    <img class="article-type-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/original.png" alt="">
                    <div class="bar-content">
                      <a class="follow-nickName vip-name" href="https://snu77.blog.csdn.net" target="_blank" rel="noopener" title="Snu77">Snu77</a>
                    <img class="article-time-img article-heard-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newUpTime2.png" alt="">
                    <span class="time">已于&nbsp;2024-01-05 01:15:49&nbsp;修改</span>
                   <div class="read-count-box">
                      <img class="article-read-img article-heard-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/articleReadEyes2.png" alt="">
                      <span class="read-count">阅读量2.1k</span>
                      <a id="blog_detail_zk_collection" class="un-collection" data-report-click='{"mod":"popu_823","spm":"1001.2101.3001.4232","ab":"new"}'>
                          <img class="article-collect-img article-heard-img un-collect-status isdefault" style="display:inline-block" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarCollect2.png" alt="">
                          <img class="article-collect-img article-heard-img collect-status isactive" style="display:none" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarCollectionActive2.png" alt="">
                          <span class="name">收藏</span>
                          <span class="get-collection">
                              27
                          </span>
                      </a>
                      <div class="read-count-box is-like">
                        <img class="article-read-img article-heard-img" style="display:none" id="is-like-imgactive-new" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newHeart2023Active.png" alt="">
                        <img class="article-read-img article-heard-img" style="display:block" id="is-like-img-new" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newHeart2023Black.png" alt="">
                        <span class="read-count" id="blog-digg-num">点赞数
                            31
                        </span>
                      </div>
                    </div>
                  </div>
                </div>
                <div class="blog-tags-box">
                    <div class="tags-box artic-tag-box">
                            <span class="label">分类专栏：</span>
                                <a class="tag-link" href="https://blog.csdn.net/java1314777/category_12483754.html" target="_blank" rel="noopener">YOLOv8有效涨点专栏</a>
                            <span class="label">文章标签：</span>
                                <a rel="nofollow" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"人工智能","ab":"new","extra":"{\"searchword\":\"人工智能\"}"}' class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank" rel="noopener">人工智能</a>
                                <a rel="nofollow" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"计算机视觉","ab":"new","extra":"{\"searchword\":\"计算机视觉\"}"}' class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank" rel="noopener">计算机视觉</a>
                                <a rel="nofollow" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"深度学习","ab":"new","extra":"{\"searchword\":\"深度学习\"}"}' class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank" rel="noopener">深度学习</a>
                                <a rel="nofollow" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"YOLO","ab":"new","extra":"{\"searchword\":\"YOLO\"}"}' class="tag-link" href="https://so.csdn.net/so/search/s.do?q=YOLO&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank" rel="noopener">YOLO</a>
                                <a rel="nofollow" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"pytorch","ab":"new","extra":"{\"searchword\":\"pytorch\"}"}' class="tag-link" href="https://so.csdn.net/so/search/s.do?q=pytorch&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank" rel="noopener">pytorch</a>
                                <a rel="nofollow" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"python","ab":"new","extra":"{\"searchword\":\"python\"}"}' class="tag-link" href="https://so.csdn.net/so/search/s.do?q=python&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank" rel="noopener">python</a>
                                <a rel="nofollow" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"目标检测","ab":"new","extra":"{\"searchword\":\"目标检测\"}"}' class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank" rel="noopener">目标检测</a>
                    </div>
                </div>
                <div class="up-time"><span>于&nbsp;2024-01-05 01:14:32&nbsp;首次发布</span></div>
                <div class="slide-content-box">
                    <div class="article-copyright">
                        <div class="creativecommons">
                            版权声明：本文为博主原创文章，遵循<a href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="noopener"> CC 4.0 BY-SA </a>版权协议，转载请附上原文出处链接和本声明。
                        </div>
                        <div class="article-source-link">
                            本文链接：<a href="https://blog.csdn.net/java1314777/article/details/135024120" target="_blank">https://blog.csdn.net/java1314777/article/details/135024120</a>
                        </div>
                    </div>
                </div>
                
                <div class="operating">
                    <a class="href-article-edit slide-toggle">版权</a>
                </div>
            </div>
        </div>
    </div>
    <div id="blogHuaweiyunAdvert"></div>
        <div id="blogColumnPayAdvert">
            <div class="column-group">
                <div class="column-group-item column-group0 column-group-item-one">
                    <div class="item-l">
                        <a class="item-target" href="https://blog.csdn.net/java1314777/category_12483754.html" target="_blank" title="YOLOv8有效涨点专栏"
                        data-report-view='{"spm":"1001.2101.3001.6332"}'
                        data-report-click='{"spm":"1001.2101.3001.6332"}'>
                            <img class="item-target" src="https://img-blog.csdnimg.cn/direct/d0d498bd4f0c4e17b48ff54e86b67668.png?x-oss-process=image/resize,m_fixed,h_224,w_224" alt="">
                            <span class="title item-target">
                                <span>
                                <span class="tit">YOLOv8有效涨点专栏</span>
                                    <span class="dec">专栏收录该内容</span>
                                </span>
                                <span class="rank"><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/columnHotIcon2.png" alt="">该专栏为热销专栏榜&nbsp;第1名</span>
                            </span>
                        </a>
                    </div>
                    <div class="item-m">
                        <span>125 篇文章</span>
                        <span>340 订阅</span>
                        <span class="old-add-new-box">
                            <span class="price price-style">¥199.90</span>
                            <span class="oldprice price-style">¥99.00</span>
                        </span>
                    </div>
                    <div class="item-r">
                                <a class="item-target article-column-subscribe">已订阅</a>
                    </div>
                </div>
            </div>
        </div>
    <article class="baidu_pl">
        <div id="article_content" class="article_content clearfix">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/kdoc_html_views-1a98987dfd.css">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-044f2cf1dc.css">
                <div id="content_views" class="htmledit_views">
                    <h2 id="%E4%B8%80%E3%80%81%E6%9C%AC%E6%96%87%E4%BB%8B%E7%BB%8D" style="background-color:transparent;">一、本文介绍</h2> 
<p>本文给大家带来的改进机制是<span style="color:#ed7976;"><strong>Gold-YOLO</strong></span>利用其Neck改进v8的Neck&#xff0c;GoLd-YOLO引入了一种新的机制——<span style="color:#1a439c;"><strong>信息聚集-分发</strong></span>&#xff08;Gather-and-Distribute, GD&#xff09;。这个机制通过全局融合不同层次的特征并将融合后的全局信息注入到各个层级中&#xff0c;从而实现更高效的信息交互和融合。这种方法增强了模型的颈部&#xff08;neck&#xff09;信息融合能力<span style="color:#faa572;"><strong>(有点类似于长颈鹿的脖子该Neck部分很长)&#xff0c;</strong></span>同时也没有显著增加延迟&#xff0c;<span style="color:#956fe7;"><strong>提高了模型在检测不同大小物体时的性能&#xff0c;</strong></span><span style="color:#fe2c24;"><strong>同时欢迎大家订阅本专栏&#xff0c;本专栏每周更新3-5篇最新机制&#xff0c;更有包含我所有改进的文件和交流群提供给大家&#xff0c;</strong></span><span style="color:#1a439c;"><strong>同时在这里再次声明&#xff0c;我本人发的对比图片全部真实有效&#xff0c;为对应文章的模型运行结果。</strong></span></p> 
<p><img alt="" height="821" src="https://img-blog.csdnimg.cn/direct/ee43e97a1cd146bb9bad67da0960958c.png" width="1200" /></p> 
<blockquote> 
 <p><strong><span style="color:#fe2c24;">专栏回顾&#xff1a;</span><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><a href="https://blog.csdn.net/java1314777/category_12483754.html" title="YOLOv8改进系列专栏——本专栏持续复习各种顶会内容——科研必备">YOLOv8改进系列专栏——本专栏持续复习各种顶会内容——科研必备</a></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>    </strong> </p> 
</blockquote> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81%E6%9C%AC%E6%96%87%E4%BB%8B%E7%BB%8D-toc" style="margin-left:0px;"><strong><a href="#%E4%B8%80%E3%80%81%E6%9C%AC%E6%96%87%E4%BB%8B%E7%BB%8D" rel="nofollow">一、本文介绍</a></strong></p> 
<p id="%E4%BA%8C%E3%80%81Gold-YOLO%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86-toc" style="margin-left:0px;"><strong><a href="#%E4%BA%8C%E3%80%81Gold-YOLO%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86" rel="nofollow">二、Gold-YOLO模型原理</a></strong></p> 
<p id="%C2%A02.1%C2%A0Gold-YOLO%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86-toc" style="margin-left:40px;"><strong><a href="#%C2%A02.1%C2%A0Gold-YOLO%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86" rel="nofollow"> 2.1 Gold-YOLO的基本原理</a></strong></p> 
<p id="2.2%C2%A0%E8%81%9A%E5%90%88-%E5%88%86%E5%8F%91%E6%9C%BA%E5%88%B6%EF%BC%88GD%EF%BC%89-toc" style="margin-left:40px;"><strong><a href="#2.2%C2%A0%E8%81%9A%E5%90%88-%E5%88%86%E5%8F%91%E6%9C%BA%E5%88%B6%EF%BC%88GD%EF%BC%89" rel="nofollow">2.2 聚合-分发机制&#xff08;GD&#xff09;</a></strong></p> 
<p id="2.3%C2%A0%C2%A0%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88-toc" style="margin-left:40px;"><strong><a href="#2.3%C2%A0%C2%A0%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88" rel="nofollow">2.3  多尺度特征融合</a></strong></p> 
<p id="2.4%C2%A0%C2%A0MAE%E9%A3%8E%E6%A0%BC%E9%A2%84%E8%AE%AD%E7%BB%83-toc" style="margin-left:40px;"><strong><a href="#2.4%C2%A0%C2%A0MAE%E9%A3%8E%E6%A0%BC%E9%A2%84%E8%AE%AD%E7%BB%83" rel="nofollow">2.4  MAE风格预训练</a></strong></p> 
<p id="%E4%B8%89%E3%80%81Gold-YOLO%E6%A0%B8%E5%BF%83%E4%BB%A3%E7%A0%81-toc" style="margin-left:0px;"><strong><a href="#%E4%B8%89%E3%80%81Gold-YOLO%E6%A0%B8%E5%BF%83%E4%BB%A3%E7%A0%81" rel="nofollow">三、Gold-YOLO核心代码</a></strong></p> 
<p id="%E5%9B%9B%E3%80%81Gold-YOLO%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F%C2%A0-toc" style="margin-left:0px;"><strong><a href="#%E5%9B%9B%E3%80%81Gold-YOLO%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F%C2%A0" rel="nofollow">四、Gold-YOLO使用方式 </a></strong></p> 
<p id="4.1%C2%A0RCS-OSA%E6%B7%BB%E5%8A%A0%E6%AD%A5%E9%AA%A4-toc" style="margin-left:40px;"><strong><a href="#4.1%C2%A0RCS-OSA%E6%B7%BB%E5%8A%A0%E6%AD%A5%E9%AA%A4" rel="nofollow">4.1 Gold-YOLO添加步骤</a></strong></p> 
<p id="%E4%BA%94%E3%80%81Gold-YOLO%E7%9A%84yaml%E6%96%87%E4%BB%B6-toc" style="margin-left:0px;"><strong><a href="#%E4%BA%94%E3%80%81Gold-YOLO%E7%9A%84yaml%E6%96%87%E4%BB%B6" rel="nofollow">五、Gold-YOLO的yaml文件</a></strong></p> 
<p id="5.1%20yaml%E6%96%87%E4%BB%B6%C2%A0-toc" style="margin-left:40px;"><strong><a href="#5.1%20yaml%E6%96%87%E4%BB%B6%C2%A0" rel="nofollow">5.1 yaml文件 </a></strong></p> 
<p id="5.2%20%E8%BF%90%E8%A1%8C%E4%BB%A3%E7%A0%81%C2%A0-toc" style="margin-left:40px;"><strong><a href="#5.2%20%E8%BF%90%E8%A1%8C%E4%BB%A3%E7%A0%81%C2%A0" rel="nofollow">5.2 运行代码 </a></strong></p> 
<p id="5.3%20%E6%88%90%E5%8A%9F%E8%BF%90%E8%A1%8C%E6%88%AA%E5%9B%BE-toc" style="margin-left:40px;"><strong><a href="#5.3%20%E6%88%90%E5%8A%9F%E8%BF%90%E8%A1%8C%E6%88%AA%E5%9B%BE" rel="nofollow">5.3 成功运行截图</a></strong></p> 
<p id="%E5%85%AD%E3%80%81%E5%85%A8%E6%96%87%E6%80%BB%E7%BB%93%C2%A0-toc" style="margin-left:0px;"><strong><a href="#%E5%85%AD%E3%80%81%E5%85%A8%E6%96%87%E6%80%BB%E7%BB%93%C2%A0" rel="nofollow">六、全文总结 </a></strong></p> 
<hr id="hr-toc" /> 
<p></p> 
<h2 id="%E4%BA%8C%E3%80%81Gold-YOLO%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86">二、Gold-YOLO模型原理</h2> 
<p><img alt="" height="331" src="https://img-blog.csdnimg.cn/direct/0879e0cce3a34228bc818af8379c51b6.png" width="1200" /></p> 
<p><strong><span style="color:#fe2c24;">论文地址&#xff1a;</span><a class="link-info" href="https://arxiv.org/pdf/2309.11331.pdf" rel="nofollow" title="官方论文地址">官方论文地址</a></strong></p> 
<p><span style="color:#fe2c24;"><strong>代码地址&#xff1a;<a class="link-info" href="https://github.com/huawei-noah/Efficient-Computing/blob/master/Detection/Gold-YOLO/gold_yolo/transformer.py" title="官方代码地址">官方代码地址</a></strong></span></p> 
<p><img alt="" height="260" src="https://img-blog.csdnimg.cn/direct/3457ffe588c54cb6a24377c4c6464452.png" width="1012" /></p> 
<hr /> 
<h3 id="%C2%A02.1%C2%A0Gold-YOLO%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"> 2.1 Gold-YOLO的基本原理</h3> 
<p><span style="color:#fe2c24;"><strong>Gold-YOLO</strong></span>是一种先进的目标检测模型&#xff0c;它通过一种创新的<span style="color:#ff9900;"><strong>聚合-分发&#xff08;Gather-and-Distribute, GD&#xff09;机制</strong></span>来提高信息融合效率。这一机制利用卷积和自注意力操作来处理来自网络不同层的信息。通过这种方式&#xff0c;Gold-YOLO能够更有效地融合多尺度特征&#xff0c;实现低延迟和高准确性之间的理想平衡。此外&#xff0c;Gold-YOLO还首次在YOLO系列中采用了<span style="color:#4da8ee;"><strong>MAE风格的预训练</strong></span>&#xff0c;从而提高了模型的学习效率和准确度。</p> 
<p><span style="color:#fe2c24;"><strong>Gold-YOLO的基本原理可以概括如下&#xff1a;</strong></span></p> 
<p><strong>1. 聚合-分发机制&#xff08;GD&#xff09;</strong>&#xff1a; 通过卷积和自注意力操作实现&#xff0c;这一机制有效地融合了来自网络不同层的信息。</p> 
<p><strong>2. 多尺度特征融合&#xff1a;</strong>GD机制提高了多尺度特征的融合能力&#xff0c;从而提升了目标检测的准确性。</p> 
<p><strong>3. MAE风格预训练&#xff1a;</strong> 首次在YOLO系列中采用&#xff0c;提高了模型的学习效率和准确度。</p> 
<p>下面我将为大家展示<span style="color:#fe2c24;"><strong>Gold-YOLO架构</strong></span>&#xff1a;</p> 
<p class="img-center"><img alt="" height="382" src="https://img-blog.csdnimg.cn/direct/2bef16f10bcf4526b96fc69faa62347d.png" width="1090" /></p> 
<p>主要包括以下几个部分&#xff1a;</p> 
<p><strong>1. 主干&#xff08;Backbone&#xff09;&#xff1a;</strong> 对输入图像进行初步处理&#xff0c;提取特征。<br /><strong>2. 低阶聚合分发&#xff08;Low-GD&#xff09;分支&#xff1a;</strong>用于对较大尺寸特征图进行对齐&#xff08;Low-FAM&#xff09;和融合&#xff08;Low-IFM&#xff09;。<br /><strong>3. 高阶聚合分发&#xff08;High-GD&#xff09;分支&#xff1a;</strong> 用于对较小尺寸特征图进行对齐&#xff08;High-FAM&#xff09;和融合&#xff08;High-IFM&#xff09;。<br /><strong>4. 注入模块&#xff08;Inject&#xff09;&#xff1a;</strong>将融合的信息整合并传递给检测头部。<br /><strong>5. 头部&#xff08;Head&#xff09;&#xff1a;</strong>利用融合后的特征进行目标检测。</p> 
<blockquote> 
 <p><strong>总结&#xff1a;</strong>在这张图中&#xff0c;Gold-YOLO的多尺度特征融合体现在低阶&#xff08;Low-GD&#xff09;和高阶&#xff08;High-GD&#xff09;聚合-分发分支的设计上。这两个分支通过特征对齐模块&#xff08;FAM&#xff09;和信息融合模块&#xff08;IFM&#xff09;来处理不同尺寸的特征图。通过这种结构&#xff0c;Gold-YOLO可以有效地融合来自网络不同深度层次的信息&#xff0c;这对于准确检测不同大小的目标至关重要。</p> 
</blockquote> 
<hr /> 
<h3 id="2.2%C2%A0%E8%81%9A%E5%90%88-%E5%88%86%E5%8F%91%E6%9C%BA%E5%88%B6%EF%BC%88GD%EF%BC%89">2.2 <strong>聚合-分发机制&#xff08;GD&#xff09;</strong></h3> 
<p><span style="color:#fe2c24;"><strong>聚合-分发机制&#xff08;GD&#xff09;</strong></span>是Gold-YOLO模型的核心特征之一&#xff0c;其目的是<span style="color:#4da8ee;"><strong>解决信息融合问题</strong></span>。在这个机制中&#xff0c;采用<span style="color:#956fe7;"><strong>特征对齐模块&#xff08;FAM&#xff09;</strong></span>和<span style="color:#956fe7;"><strong>信息融合模块&#xff08;IFM&#xff09;</strong></span>对不同层级的特征进行聚合&#xff0c;并通过<strong><span style="color:#956fe7;">信息注入模块&#xff08;Inject&#xff09;</span></strong>将融合后的信息分发回网络的各个层级。这样&#xff0c;模型就能更有效地利用多尺度特征&#xff0c;从而在保持低延迟的同时提高目标检测的准确性。</p> 
<p>下面展示给大家的图像展示了Gold-YOLO架构中的<span style="color:#ff9900;"><strong>两个关键模块</strong></span>&#xff1a;</p> 
<p class="img-center"><img alt="" height="461" src="https://img-blog.csdnimg.cn/direct/8f604418a1bb45cc825f9abb98f0b94a.png" width="1200" /></p> 
<p><strong>(a) 信息注入模块<span style="color:#0d0016;">&#xff08;Inject&#xff09;</span>&#xff1a;</strong>该模块通过卷积和Sigmoid激活函数等操作结合本地特征和全局特征&#xff0c;旨在用全局上下文信息增强特征图&#xff0c;这对于准确的目标检测至关重要。</p> 
<p><strong>(b) 轻量级邻层融合&#xff08;LAF&#xff09;模块&#xff1a;</strong>此模块用于改进相邻层特征图的融合。它使用平均池化和双线性上/下采样等操作来对齐和合并特征图&#xff0c;从而确保每一层的本地特征都富含来自其直接邻层的信息。</p> 
<blockquote> 
 <p><strong>总结&#xff1a;</strong>图中展示的信息注入模块和轻量级邻层融合&#xff08;LAF&#xff09;模块是实现高效信息融合的关键组成部分&#xff0c;通过结合不同层的局部&#xff08;本地&#xff09;和全局特征&#xff0c;提高了模型的目标检测性能。</p> 
</blockquote> 
<hr /> 
<h3 id="2.3%C2%A0%C2%A0%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88">2.3  <strong>多尺度特征融合</strong></h3> 
<p><span style="color:#fe2c24;"><strong>多尺度特征融合</strong></span>是一种在目标检测模型中常用的技术&#xff0c;旨在提高模型对不同大小目标的检测能力。通过结合来自网络不同层级的特征&#xff0c;该技术能够捕获从粗糙到精细的多种尺度的信息。低层次特征通常含有更多关于小对象的细节&#xff0c;而高层次特征则捕捉到大对象的语义信息。多尺度特征融合通过<span style="color:#4da8ee;"><strong>聚合这些层级的特征</strong></span>来增强模型的表示能力&#xff0c;使得模型能够更准确地识别和定位图像中的各种尺寸的对象。</p> 
<p>下面展示了<span style="color:#fe2c24;"><strong>Gold-YOLO模型中的聚合-分发结构</strong></span>。</p> 
<p class="img-center"><img alt="" height="194" src="https://img-blog.csdnimg.cn/direct/60f0b09d7bf142e983944c2111c9054e.png" width="1172" /></p> 
<p>图(a)中的<span style="color:#ff9900;"><strong>低阶聚合分发&#xff08;Low-GD&#xff09;</strong></span>分支包括低阶特征对齐模块&#xff08;Low-FAM&#xff09;和低阶信息融合模块&#xff08;Low-IFM&#xff09;。图(b)中的<span style="color:#ff9900;"><strong>高阶聚合分发&#xff08;High-GD&#xff09;</strong></span>分支包含高阶特征对齐模块&#xff08;High-FAM&#xff09;和高阶信息融合模块&#xff08;High-IFM&#xff09;。</p> 
<blockquote> 
 <p><strong>总结&#xff1a;</strong>这两个分支是Gold-YOLO模型中处理不同尺寸特征图并提高目标检测性能的关键部分&#xff0c;通过不同尺度的特征对齐&#xff08;FAM&#xff09;和信息融合&#xff08;IFM&#xff09;模块&#xff0c;增强了模型处理不同尺度特征并提高目标检测性能的能力。</p> 
</blockquote> 
<hr /> 
<h3 id="2.4%C2%A0%C2%A0MAE%E9%A3%8E%E6%A0%BC%E9%A2%84%E8%AE%AD%E7%BB%83">2.4  <strong>MAE风格预训练</strong></h3> 
<p><span style="color:#fe2c24;"><strong>MAE风格预训练&#xff08;Masked Autoencoder for self-supervised learning&#xff09;</strong></span>指的是一种<span style="color:#4da8ee;"><strong>自监督学习方法</strong></span>&#xff0c;用于提升模型在处理大规模数据集时的学习效率和准确性。在这种预训练方法中&#xff0c;模型被训练来重建输入数据中被随机遮蔽的部分&#xff0c;通过这一过程模型学习到了数据的内在表示。这种训练方式<span style="color:#956fe7;"><strong>不依赖于标签数据</strong></span>&#xff0c;使得模型能够学习到丰富的数据表示。<strong>在计算机视觉领域</strong>&#xff0c;MAE风格预训练尤其有效&#xff0c;因为它促使模型捕捉到图像的结构性特征和内容&#xff0c;从而在之后的监督学习任务中&#xff0c;如目标检测或图像分类&#xff0c;能更快地收敛并提高性能。<strong>在Gold-YOLO中</strong>&#xff0c;采用MAE预训练进一步提升了模型对图像特征的理解&#xff0c;从而在目标检测任务中实现了更高的准确率。</p> 
<p></p> 
<hr /> 
<h2 id="%E4%B8%89%E3%80%81Gold-YOLO%E6%A0%B8%E5%BF%83%E4%BB%A3%E7%A0%81">三、Gold-YOLO核心代码</h2> 
<p><strong>使用方式看章节四&#xff0c;同时其中代码使用涉及到mmcv这个库&#xff0c;这个库需要很强的版本特征&#xff0c;如果你们通过pip下载失败&#xff0c;可以通过下面的链接直接下载编译版本的&#xff0c;然后到本地通过pip安装即可&#xff0c;同时我以后发的检测头基本上都需要这个mmcv库。</strong></p> 
<pre><code>import torch
from torch import nn
import torch.nn.functional as F
import numpy as np
from mmcv.cnn import ConvModule, build_norm_layer


__all__ &#61; (&#39;Low_FAM&#39;, &#39;Low_IFM&#39;, &#39;Split&#39;, &#39;SimConv&#39;, &#39;Low_LAF&#39;, &#39;Inject&#39;, &#39;RepBlock&#39;, &#39;High_FAM&#39;, &#39;High_IFM&#39;, &#39;High_LAF&#39;)

class High_LAF(nn.Module):
    def forward(self, x1, x2):
        if torch.onnx.is_in_onnx_export():
            self.pool &#61; onnx_AdaptiveAvgPool2d
        else:
            self.pool &#61; nn.functional.adaptive_avg_pool2d
        
        N, C, H, W &#61; x2.shape
        # output_size &#61; np.array([H, W])
        output_size &#61; [H, W]
        x1 &#61; self.pool(x1, output_size)
        
        return torch.cat([x1, x2], 1)

class High_IFM(nn.Module):
    def __init__(self, block_num, embedding_dim, key_dim, num_heads,
                 mlp_ratio&#61;4., attn_ratio&#61;2., drop&#61;0., attn_drop&#61;0., drop_path&#61;0.,
                 norm_cfg&#61;dict(type&#61;&#39;BN&#39;, requires_grad&#61;True),
                 act_layer&#61;nn.ReLU6):
        super().__init__()
        self.block_num &#61; block_num
        drop_path &#61; [x.item() for x in torch.linspace(0, drop_path[0], drop_path[1])] # 0.1, 2
        self.transformer_blocks &#61; nn.ModuleList()
        for i in range(self.block_num):
            self.transformer_blocks.append(top_Block(
                    embedding_dim, key_dim&#61;key_dim, num_heads&#61;num_heads,
                    mlp_ratio&#61;mlp_ratio, attn_ratio&#61;attn_ratio,
                    drop&#61;drop, drop_path&#61;drop_path[i] if isinstance(drop_path, list) else drop_path,
                    norm_cfg&#61;norm_cfg, act_layer&#61;act_layer))
    
    def forward(self, x):
        # token * N 
        for i in range(self.block_num):
            x &#61; self.transformer_blocks[i](x)
        return x
    
class Mlp(nn.Module):
    def __init__(self, in_features, hidden_features&#61;None, out_features&#61;None, act_layer&#61;nn.ReLU, drop&#61;0.,
                 norm_cfg&#61;dict(type&#61;&#39;BN&#39;, requires_grad&#61;True)):
        super().__init__()
        out_features &#61; out_features or in_features
        hidden_features &#61; hidden_features or in_features
        self.fc1 &#61; Conv2d_BN(in_features, hidden_features, norm_cfg&#61;norm_cfg)
        self.dwconv &#61; nn.Conv2d(hidden_features, hidden_features, 3, 1, 1, bias&#61;True, groups&#61;hidden_features)
        self.act &#61; act_layer()
        self.fc2 &#61; Conv2d_BN(hidden_features, out_features, norm_cfg&#61;norm_cfg)
        self.drop &#61; nn.Dropout(drop)
    
    def forward(self, x):
        x &#61; self.fc1(x)
        x &#61; self.dwconv(x)
        x &#61; self.act(x)
        x &#61; self.drop(x)
        x &#61; self.fc2(x)
        x &#61; self.drop(x)
        return x

class top_Block(nn.Module):
    
    def __init__(self, dim, key_dim, num_heads, mlp_ratio&#61;4., attn_ratio&#61;2., drop&#61;0.,
                 drop_path&#61;0., act_layer&#61;nn.ReLU, norm_cfg&#61;dict(type&#61;&#39;BN2d&#39;, requires_grad&#61;True)):
        super().__init__()
        self.dim &#61; dim
        self.num_heads &#61; num_heads
        self.mlp_ratio &#61; mlp_ratio
        
        self.attn &#61; Attention(dim, key_dim&#61;key_dim, num_heads&#61;num_heads, attn_ratio&#61;attn_ratio, activation&#61;act_layer,
                              norm_cfg&#61;norm_cfg)
        
        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here
        self.drop_path &#61; DropPath(drop_path) if drop_path &gt; 0. else nn.Identity()
        mlp_hidden_dim &#61; int(dim * mlp_ratio)
        self.mlp &#61; Mlp(in_features&#61;dim, hidden_features&#61;mlp_hidden_dim, act_layer&#61;act_layer, drop&#61;drop,
                       norm_cfg&#61;norm_cfg)
    
    def forward(self, x1):
        x1 &#61; x1 &#43; self.drop_path(self.attn(x1))
        x1 &#61; x1 &#43; self.drop_path(self.mlp(x1))
        return x1

def drop_path(x, drop_prob: float &#61; 0., training: bool &#61; False):
    &#34;&#34;&#34;Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).
    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,
    the original name is misleading as &#39;Drop Connect&#39; is a different form of dropout in a separate paper...
    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I&#39;ve opted for
    changing the layer and argument names to &#39;drop path&#39; rather than mix DropConnect as a layer name and use
    &#39;survival rate&#39; as the argument.
    &#34;&#34;&#34;
    if drop_prob &#61;&#61; 0. or not training:
        return x
    keep_prob &#61; 1 - drop_prob
    shape &#61; (x.shape[0],) &#43; (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets
    random_tensor &#61; keep_prob &#43; torch.rand(shape, dtype&#61;x.dtype, device&#61;x.device)
    random_tensor.floor_()  # binarize
    output &#61; x.div(keep_prob) * random_tensor
    return output


class DropPath(nn.Module):
    &#34;&#34;&#34;Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).
    &#34;&#34;&#34;
    
    def __init__(self, drop_prob&#61;None):
        super(DropPath, self).__init__()
        self.drop_prob &#61; drop_prob
    
    def forward(self, x):
        return drop_path(x, self.drop_prob, self.training)

class Attention(torch.nn.Module):
    def __init__(self, dim, key_dim, num_heads,
                 attn_ratio&#61;4,
                 activation&#61;None,
                 norm_cfg&#61;dict(type&#61;&#39;BN&#39;, requires_grad&#61;True), ):
        super().__init__()
        self.num_heads &#61; num_heads
        self.scale &#61; key_dim ** -0.5
        self.key_dim &#61; key_dim
        self.nh_kd &#61; nh_kd &#61; key_dim * num_heads  # num_head key_dim
        self.d &#61; int(attn_ratio * key_dim)
        self.dh &#61; int(attn_ratio * key_dim) * num_heads
        self.attn_ratio &#61; attn_ratio
        
        self.to_q &#61; Conv2d_BN(dim, nh_kd, 1, norm_cfg&#61;norm_cfg)
        self.to_k &#61; Conv2d_BN(dim, nh_kd, 1, norm_cfg&#61;norm_cfg)
        self.to_v &#61; Conv2d_BN(dim, self.dh, 1, norm_cfg&#61;norm_cfg)
        
        self.proj &#61; torch.nn.Sequential(activation(), Conv2d_BN(
                self.dh, dim, bn_weight_init&#61;0, norm_cfg&#61;norm_cfg))
    
    def forward(self, x):  # x (B,N,C)
        B, C, H, W &#61; get_shape(x)
        
        qq &#61; self.to_q(x).reshape(B, self.num_heads, self.key_dim, H * W).permute(0, 1, 3, 2)
        kk &#61; self.to_k(x).reshape(B, self.num_heads, self.key_dim, H * W)
        vv &#61; self.to_v(x).reshape(B, self.num_heads, self.d, H * W).permute(0, 1, 3, 2)
        
        attn &#61; torch.matmul(qq, kk)
        attn &#61; attn.softmax(dim&#61;-1)  # dim &#61; k
        
        xx &#61; torch.matmul(attn, vv)
        
        xx &#61; xx.permute(0, 1, 3, 2).reshape(B, self.dh, H, W)
        xx &#61; self.proj(xx)
        return xx
    
def get_shape(tensor):
    shape &#61; tensor.shape
    if torch.onnx.is_in_onnx_export():
        shape &#61; [i.cpu().numpy() for i in shape]
    return shape
    
class Conv2d_BN(nn.Sequential):
    def __init__(self, a, b, ks&#61;1, stride&#61;1, pad&#61;0, dilation&#61;1,
                 groups&#61;1, bn_weight_init&#61;1,
                 norm_cfg&#61;dict(type&#61;&#39;BN&#39;, requires_grad&#61;True)):
        super().__init__()
        self.inp_channel &#61; a
        self.out_channel &#61; b
        self.ks &#61; ks
        self.pad &#61; pad
        self.stride &#61; stride
        self.dilation &#61; dilation
        self.groups &#61; groups
        
        self.add_module(&#39;c&#39;, nn.Conv2d(
                a, b, ks, stride, pad, dilation, groups, bias&#61;False))
        bn &#61; build_norm_layer(norm_cfg, b)[1]
        nn.init.constant_(bn.weight, bn_weight_init)
        nn.init.constant_(bn.bias, 0)
        self.add_module(&#39;bn&#39;, bn)

class High_FAM(nn.Module):
    def __init__(self, stride, pool_mode&#61;&#39;onnx&#39;):
        super().__init__()
        self.stride &#61; stride
        if pool_mode &#61;&#61; &#39;torch&#39;:
            self.pool &#61; nn.functional.adaptive_avg_pool2d
        elif pool_mode &#61;&#61; &#39;onnx&#39;:
            self.pool &#61; onnx_AdaptiveAvgPool2d
    
    def forward(self, inputs):
        B, C, H, W &#61; get_shape(inputs[-1])
        H &#61; (H - 1) // self.stride &#43; 1
        W &#61; (W - 1) // self.stride &#43; 1
        
        # output_size &#61; np.array([H, W])
        output_size &#61; [H, W]
       
        if not hasattr(self, &#39;pool&#39;):
            self.pool &#61; nn.functional.adaptive_avg_pool2d
        
        if torch.onnx.is_in_onnx_export():
            self.pool &#61; onnx_AdaptiveAvgPool2d
        
        out &#61; [self.pool(inp, output_size) for inp in inputs]
        
        return torch.cat(out, dim&#61;1)

class RepVGGBlock(nn.Module):
    &#39;&#39;&#39;RepVGGBlock is a basic rep-style block, including training and deploy status
    This code is based on https://github.com/DingXiaoH/RepVGG/blob/main/repvgg.py
    &#39;&#39;&#39;
    
    def __init__(self, in_channels, out_channels, kernel_size&#61;3,
                 stride&#61;1, padding&#61;1, dilation&#61;1, groups&#61;1, padding_mode&#61;&#39;zeros&#39;, deploy&#61;False, use_se&#61;False):
        super(RepVGGBlock, self).__init__()
        &#34;&#34;&#34; Initialization of the class.
        Args:
            in_channels (int): Number of channels in the input image
            out_channels (int): Number of channels produced by the convolution
            kernel_size (int or tuple): Size of the convolving kernel
            stride (int or tuple, optional): Stride of the convolution. Default: 1
            padding (int or tuple, optional): Zero-padding added to both sides of
                the input. Default: 1
            dilation (int or tuple, optional): Spacing between kernel elements. Default: 1
            groups (int, optional): Number of blocked connections from input
                channels to output channels. Default: 1
            padding_mode (string, optional): Default: &#39;zeros&#39;
            deploy: Whether to be deploy status or training status. Default: False
            use_se: Whether to use se. Default: False
        &#34;&#34;&#34;
        self.deploy &#61; deploy
        self.groups &#61; groups
        self.in_channels &#61; in_channels
        self.out_channels &#61; out_channels
        
        assert kernel_size &#61;&#61; 3
        assert padding &#61;&#61; 1
        
        padding_11 &#61; padding - kernel_size // 2
        
        self.nonlinearity &#61; nn.ReLU()
        
        if use_se:
            raise NotImplementedError(&#34;se block not supported yet&#34;)
        else:
            self.se &#61; nn.Identity()
        
        if deploy:
            self.rbr_reparam &#61; nn.Conv2d(in_channels&#61;in_channels, out_channels&#61;out_channels, kernel_size&#61;kernel_size,
                                         stride&#61;stride,
                                         padding&#61;padding, dilation&#61;dilation, groups&#61;groups, bias&#61;True,
                                         padding_mode&#61;padding_mode)
        
        else:
            self.rbr_identity &#61; nn.BatchNorm2d(
                    num_features&#61;in_channels) if out_channels &#61;&#61; in_channels and stride &#61;&#61; 1 else None
            self.rbr_dense &#61; conv_bn(in_channels&#61;in_channels, out_channels&#61;out_channels, kernel_size&#61;kernel_size,
                                     stride&#61;stride, padding&#61;padding, groups&#61;groups)
            self.rbr_1x1 &#61; conv_bn(in_channels&#61;in_channels, out_channels&#61;out_channels, kernel_size&#61;1, stride&#61;stride,
                                   padding&#61;padding_11, groups&#61;groups)
    
    def forward(self, inputs):
        &#39;&#39;&#39;Forward process&#39;&#39;&#39;
        if hasattr(self, &#39;rbr_reparam&#39;):
            return self.nonlinearity(self.se(self.rbr_reparam(inputs)))
        
        if self.rbr_identity is None:
            id_out &#61; 0
        else:
            id_out &#61; self.rbr_identity(inputs)
        
        return self.nonlinearity(self.se(self.rbr_dense(inputs) &#43; self.rbr_1x1(inputs) &#43; id_out))
    
    def get_equivalent_kernel_bias(self):
        kernel3x3, bias3x3 &#61; self._fuse_bn_tensor(self.rbr_dense)
        kernel1x1, bias1x1 &#61; self._fuse_bn_tensor(self.rbr_1x1)
        kernelid, biasid &#61; self._fuse_bn_tensor(self.rbr_identity)
        return kernel3x3 &#43; self._pad_1x1_to_3x3_tensor(kernel1x1) &#43; kernelid, bias3x3 &#43; bias1x1 &#43; biasid
    
    def _pad_1x1_to_3x3_tensor(self, kernel1x1):
        if kernel1x1 is None:
            return 0
        else:
            return torch.nn.functional.pad(kernel1x1, [1, 1, 1, 1])
    
    def _fuse_bn_tensor(self, branch):
        if branch is None:
            return 0, 0
        if isinstance(branch, nn.Sequential):
            kernel &#61; branch.conv.weight
            running_mean &#61; branch.bn.running_mean
            running_var &#61; branch.bn.running_var
            gamma &#61; branch.bn.weight
            beta &#61; branch.bn.bias
            eps &#61; branch.bn.eps
        else:
            assert isinstance(branch, nn.BatchNorm2d)
            if not hasattr(self, &#39;id_tensor&#39;):
                input_dim &#61; self.in_channels // self.groups
                kernel_value &#61; np.zeros((self.in_channels, input_dim, 3, 3), dtype&#61;np.float32)
                for i in range(self.in_channels):
                    kernel_value[i, i % input_dim, 1, 1] &#61; 1
                self.id_tensor &#61; torch.from_numpy(kernel_value).to(branch.weight.device)
            kernel &#61; self.id_tensor
            running_mean &#61; branch.running_mean
            running_var &#61; branch.running_var
            gamma &#61; branch.weight
            beta &#61; branch.bias
            eps &#61; branch.eps
        std &#61; (running_var &#43; eps).sqrt()
        t &#61; (gamma / std).reshape(-1, 1, 1, 1)
        return kernel * t, beta - running_mean * gamma / std
    
    def switch_to_deploy(self):
        if hasattr(self, &#39;rbr_reparam&#39;):
            return
        kernel, bias &#61; self.get_equivalent_kernel_bias()
        self.rbr_reparam &#61; nn.Conv2d(in_channels&#61;self.rbr_dense.conv.in_channels,
                                     out_channels&#61;self.rbr_dense.conv.out_channels,
                                     kernel_size&#61;self.rbr_dense.conv.kernel_size, stride&#61;self.rbr_dense.conv.stride,
                                     padding&#61;self.rbr_dense.conv.padding, dilation&#61;self.rbr_dense.conv.dilation,
                                     groups&#61;self.rbr_dense.conv.groups, bias&#61;True)
        self.rbr_reparam.weight.data &#61; kernel
        self.rbr_reparam.bias.data &#61; bias
        for para in self.parameters():
            para.detach_()
        self.__delattr__(&#39;rbr_dense&#39;)
        self.__delattr__(&#39;rbr_1x1&#39;)
        if hasattr(self, &#39;rbr_identity&#39;):
            self.__delattr__(&#39;rbr_identity&#39;)
        if hasattr(self, &#39;id_tensor&#39;):
            self.__delattr__(&#39;id_tensor&#39;)
        self.deploy &#61; True

class RepBlock(nn.Module):
    &#39;&#39;&#39;
        RepBlock is a stage block with rep-style basic block
    &#39;&#39;&#39;
    
    def __init__(self, in_channels, out_channels, n&#61;1, block&#61;RepVGGBlock, basic_block&#61;RepVGGBlock):
        super().__init__()
        
        self.conv1 &#61; block(in_channels, out_channels)
        self.block &#61; nn.Sequential(*(block(out_channels, out_channels) for _ in range(n - 1))) if n &gt; 1 else None
        &#39;&#39;&#39;
        if block &#61;&#61; BottleRep:
            self.conv1 &#61; BottleRep(in_channels, out_channels, basic_block&#61;basic_block, weight&#61;True)
            n &#61; n // 2
            self.block &#61; nn.Sequential(
                    *(BottleRep(out_channels, out_channels, basic_block&#61;basic_block, weight&#61;True) for _ in
                      range(n - 1))) if n &gt; 1 else None
        &#39;&#39;&#39;
    
    def forward(self, x):
        x &#61; self.conv1(x)
        if self.block is not None:
            x &#61; self.block(x)
        return x

class Inject(nn.Module):
    def __init__(
            self,
            inp: int,
            oup: int,
            global_index: int,
            norm_cfg&#61;dict(type&#61;&#39;BN&#39;, requires_grad&#61;True),
            activations&#61;nn.ReLU6,
            global_inp&#61;None,
    ) -&gt; None:
        super().__init__()
        self.global_index &#61; global_index
        self.norm_cfg &#61; norm_cfg
        
        if not global_inp:
            global_inp &#61; inp
        
        self.local_embedding &#61; ConvModule(inp, oup, kernel_size&#61;1, norm_cfg&#61;self.norm_cfg, act_cfg&#61;None)
        self.global_embedding &#61; ConvModule(global_inp, oup, kernel_size&#61;1, norm_cfg&#61;self.norm_cfg, act_cfg&#61;None)
        self.global_act &#61; ConvModule(global_inp, oup, kernel_size&#61;1, norm_cfg&#61;self.norm_cfg, act_cfg&#61;None)
        self.act &#61; h_sigmoid()
    
    def forward(self, x_l, x_g):
        &#39;&#39;&#39;
        x_g: global features
        x_l: local features
        &#39;&#39;&#39;
        x_g &#61; x_g[self.global_index]
        B, C, H, W &#61; x_l.shape
        g_B, g_C, g_H, g_W &#61; x_g.shape
        use_pool &#61; H &lt; g_H

        local_feat &#61; self.local_embedding(x_l)
        global_act &#61; self.global_act(x_g)
        global_feat &#61; self.global_embedding(x_g)
        
        if use_pool:
            avg_pool &#61; get_avg_pool()
            # output_size &#61; np.array([H, W])
            output_size &#61; [H, W]
            
            sig_act &#61; avg_pool(global_act, output_size)
            global_feat &#61; avg_pool(global_feat, output_size)
        
        else:
            sig_act &#61; F.interpolate(self.act(global_act), size&#61;(H, W), mode&#61;&#39;bilinear&#39;, align_corners&#61;False)
            global_feat &#61; F.interpolate(global_feat, size&#61;(H, W), mode&#61;&#39;bilinear&#39;, align_corners&#61;False)
        
        out &#61; local_feat * sig_act &#43; global_feat
        return out
    
class h_sigmoid(nn.Module):
    def __init__(self, inplace&#61;True):
        super(h_sigmoid, self).__init__()
        self.relu &#61; nn.ReLU6(inplace&#61;inplace)
    
    def forward(self, x):
        return self.relu(x &#43; 3) / 6
    
def get_avg_pool():
    if torch.onnx.is_in_onnx_export():
        avg_pool &#61; onnx_AdaptiveAvgPool2d
    else:
        avg_pool &#61; nn.functional.adaptive_avg_pool2d
    return avg_pool

class Low_LAF(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.cv1 &#61; SimConv(in_channels, out_channels, 1, 1)
        self.cv_fuse &#61; SimConv(round(out_channels * 2.5), out_channels, 1, 1)
        self.downsample &#61; nn.functional.adaptive_avg_pool2d
    
    def forward(self, x):
        N, C, H, W &#61; x[1].shape
        # output_size &#61; np.array([H, W])
        output_size &#61; [H, W]

        
        if torch.onnx.is_in_onnx_export():
            self.downsample &#61; onnx_AdaptiveAvgPool2d
            output_size &#61; np.array([H, W])
        
        x0 &#61; self.downsample(x[0], output_size)
        x1 &#61; self.cv1(x[1])
        x2 &#61; F.interpolate(x[2], size&#61;(H, W), mode&#61;&#39;bilinear&#39;, align_corners&#61;False)
        return self.cv_fuse(torch.cat((x0, x1, x2), dim&#61;1))

class SimConv(nn.Module):
    &#39;&#39;&#39;Normal Conv with ReLU VAN_activation&#39;&#39;&#39;
    
    def __init__(self, in_channels, out_channels, kernel_size, stride, groups&#61;1, bias&#61;False, padding&#61;None):
        super().__init__()
        if padding is None:
            padding &#61; kernel_size // 2
        self.conv &#61; nn.Conv2d(
                in_channels,
                out_channels,
                kernel_size&#61;kernel_size,
                stride&#61;stride,
                padding&#61;padding,
                groups&#61;groups,
                bias&#61;bias,
        )
        self.bn &#61; nn.BatchNorm2d(out_channels)
        self.act &#61; nn.ReLU()
    
    def forward(self, x):
        return self.act(self.bn(self.conv(x)))
    
    def forward_fuse(self, x):
        return self.act(self.conv(x))

class Split(nn.Module):
    def __init__(self, trans_channels):
        super().__init__()
        self.trans_channels &#61; trans_channels

    def forward(self, x):
        return x.split(self.trans_channels, dim&#61;1)

class Low_IFM(nn.Module):
    def __init__(self, in_channels, embed_dims, fuse_block_num, out_channels):
        super().__init__()
        self.conv1 &#61; Conv(in_channels, embed_dims, kernel_size&#61;1, stride&#61;1, padding&#61;0)
        self.block &#61; nn.ModuleList([RepVGGBlock(embed_dims, embed_dims) for _ in range(fuse_block_num)]) if fuse_block_num &gt; 0 else nn.Identity
        self.conv2 &#61; Conv(embed_dims, out_channels, kernel_size&#61;1, stride&#61;1, padding&#61;0)
        
    
    def forward(self, x):
        x &#61; self.conv1(x)
        for b in self.block:
            x &#61; b(x)
        out &#61; self.conv2(x)
        return out

class Low_FAM(nn.Module):
    def __init__(self):
        super().__init__()
        self.avg_pool &#61; nn.functional.adaptive_avg_pool2d
    
    def forward(self, x):
        x_l, x_m, x_s, x_n &#61; x
        B, C, H, W &#61; x_s.shape
        # output_size &#61; np.array([H, W])
        output_size &#61; [H, W]

        if torch.onnx.is_in_onnx_export():
            self.avg_pool &#61; onnx_AdaptiveAvgPool2d

        x_l &#61; self.avg_pool(x_l, output_size)
        x_m &#61; self.avg_pool(x_m, output_size)
        x_n &#61; F.interpolate(x_n, size&#61;(H, W), mode&#61;&#39;bilinear&#39;, align_corners&#61;False)

        out &#61; torch.cat([x_l, x_m, x_s, x_n], 1)
        return out


def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups&#61;1, bias&#61;False):
    &#39;&#39;&#39;Basic cell for rep-style block, including conv and bn&#39;&#39;&#39;
    result &#61; nn.Sequential()
    result.add_module(&#39;conv&#39;, nn.Conv2d(in_channels&#61;in_channels, out_channels&#61;out_channels,
                                        kernel_size&#61;kernel_size, stride&#61;stride, padding&#61;padding, groups&#61;groups,
                                        bias&#61;bias))
    result.add_module(&#39;bn&#39;, nn.BatchNorm2d(num_features&#61;out_channels))
    return result

class Conv(nn.Module):
    &#39;&#39;&#39;Normal Conv with SiLU VAN_activation&#39;&#39;&#39;
    
    def __init__(self, in_channels, out_channels, kernel_size, stride, groups&#61;1, bias&#61;False, padding&#61;None):
        super().__init__()
        
        if padding is None:
            padding &#61; kernel_size // 2
        self.conv &#61; nn.Conv2d(
                in_channels,
                out_channels,
                kernel_size&#61;kernel_size,
                stride&#61;stride,
                padding&#61;padding,
                groups&#61;groups,
                bias&#61;bias,
        )
        self.bn &#61; nn.BatchNorm2d(out_channels)
        self.act &#61; nn.SiLU()
    
    def forward(self, x):
        return self.act(self.bn(self.conv(x)))
    
def onnx_AdaptiveAvgPool2d(x, output_size):
    stride_size &#61; np.floor(np.array(x.shape[-2:]) / output_size).astype(np.int32)
    kernel_size &#61; np.array(x.shape[-2:]) - (output_size - 1) * stride_size
    avg &#61; nn.AvgPool2d(kernel_size&#61;list(kernel_size), stride&#61;list(stride_size))
    x &#61; avg(x)
    return x
</code></pre> 
<p></p> 
<hr /> 
<h2 id="%E5%9B%9B%E3%80%81Gold-YOLO%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F%C2%A0">四、Gold-YOLO使用方式 </h2> 
<p>这个Gold-YOLO使用涉及到多个模块的注册&#xff0c;所以我这里提供完整的task.py的给家大家直接覆盖即可&#xff0c;这个模块和我的主干修改有一些冲突涉及到非常多的改动&#xff0c;而且其也没啥代表性的修改&#xff0c;就不出教程了&#xff0c;大家直接复制我的文件覆盖掉你的task.py文件即可&#xff0c;然后在加入其它的改动也可以&#xff0c;但是大家不要用他和我的其它主干融合&#xff0c;同时大家也放心我最近也在赶工整理所有改进的文件(一个人维护代码同时还要创新&#xff0c;速度慢了点希望大家见谅)&#xff0c;然后会在下周建立群&#xff0c;方便大家交流然后把文件上传到群里到时候大家不需要自己修改了&#xff0c;直接运行即可。</p> 
<p></p> 
<hr /> 
<h3 id="4.1%C2%A0RCS-OSA%E6%B7%BB%E5%8A%A0%E6%AD%A5%E9%AA%A4">4.1 Gold-YOLO添加步骤</h3> 
<p>复制下面的文件替换掉大家task.py文件下的所有内容&#xff0c;记得备份好自己的先。</p> 
<pre><code># Ultralytics YOLO &#x1f680;, AGPL-3.0 license

import contextlib
from copy import deepcopy
from pathlib import Path

import torch
import torch.nn as nn

from ultralytics.nn.modules import (AIFI, C1, C2, C3, C3TR, SPP, SPPF, Bottleneck, BottleneckCSP, C2f, C3Ghost, C3x,
                                    Classify, Concat, Conv, Conv2, ConvTranspose, Detect, DWConv, DWConvTranspose2d,
                                    Focus, GhostBottleneck, GhostConv, HGBlock, HGStem, Pose, RepC3, RepConv,
                                    RTDETRDecoder, Segment)
from ultralytics.utils import DEFAULT_CFG_DICT, DEFAULT_CFG_KEYS, LOGGER, colorstr, emojis, yaml_load
from ultralytics.utils.checks import check_requirements, check_suffix, check_yaml
from ultralytics.utils.loss import v8ClassificationLoss, v8DetectionLoss, v8PoseLoss, v8SegmentationLoss
from ultralytics.utils.plotting import feature_visualization
from ultralytics.utils.torch_utils import (fuse_conv_and_bn, fuse_deconv_and_bn, initialize_weights, intersect_dicts,
                                           make_divisible, model_info, scale_img, time_sync)
from .modules.gold_yolo import *
try:
    import thop
except ImportError:
    thop &#61; None


class BaseModel(nn.Module):
    &#34;&#34;&#34;
    The BaseModel class serves as a base class for all the models in the Ultralytics YOLO family.
    &#34;&#34;&#34;

    def forward(self, x, *args, **kwargs):
        &#34;&#34;&#34;
        Forward pass of the model on a single scale.
        Wrapper for &#96;_forward_once&#96; method.

        Args:
            x (torch.Tensor | dict): The input image tensor or a dict including image tensor and gt labels.

        Returns:
            (torch.Tensor): The output of the network.
        &#34;&#34;&#34;
        if isinstance(x, dict):  # for cases of training and validating while training.
            return self.loss(x, *args, **kwargs)
        return self.predict(x, *args, **kwargs)

    def predict(self, x, profile&#61;False, visualize&#61;False, augment&#61;False):
        &#34;&#34;&#34;
        Perform a forward pass through the network.

        Args:
            x (torch.Tensor): The input tensor to the model.
            profile (bool):  Print the computation time of each layer if True, defaults to False.
            visualize (bool): Save the feature maps of the model if True, defaults to False.
            augment (bool): Augment image during prediction, defaults to False.

        Returns:
            (torch.Tensor): The last output of the model.
        &#34;&#34;&#34;
        if augment:
            return self._predict_augment(x)
        return self._predict_once(x, profile, visualize)

    def _predict_once(self, x, profile&#61;False, visualize&#61;False):
        &#34;&#34;&#34;
        Perform a forward pass through the network.

        Args:
            x (torch.Tensor): The input tensor to the model.
            profile (bool):  Print the computation time of each layer if True, defaults to False.
            visualize (bool): Save the feature maps of the model if True, defaults to False.

        Returns:
            (torch.Tensor): The last output of the model.
        &#34;&#34;&#34;
        y, dt &#61; [], []  # outputs
        for m in self.model:
            if m.f !&#61; -1:  # if not from previous layer
                x &#61; y[m.f] if isinstance(m.f, int) else [x if j &#61;&#61; -1 else y[j] for j in m.f]  # from earlier layers
            if profile:
                self._profile_one_layer(m, x, dt)
            try:
                if m.input_nums &gt; 1:
                    # input nums more than one
                    x &#61; m(*x)  # run
                else:
                    x &#61; m(x)
            except AttributeError:
                # AttributeError: &#39;Conv&#39; object has no attribute &#39;input_nums&#39;
                x &#61; m(x)
            y.append(x if m.i in self.save else None)  # save output
            if visualize:
                feature_visualization(x, m.type, m.i, save_dir&#61;visualize)
        return x

    def _predict_augment(self, x):
        &#34;&#34;&#34;Perform augmentations on input image x and return augmented inference.&#34;&#34;&#34;
        LOGGER.warning(f&#39;WARNING ⚠️ {self.__class__.__name__} does not support augmented inference yet. &#39;
                       f&#39;Reverting to single-scale inference instead.&#39;)
        return self._predict_once(x)

    def _profile_one_layer(self, m, x, dt):
        &#34;&#34;&#34;
        Profile the computation time and FLOPs of a single layer of the model on a given input.
        Appends the results to the provided list.

        Args:
            m (nn.Module): The layer to be profiled.
            x (torch.Tensor): The input data to the layer.
            dt (list): A list to store the computation time of the layer.

        Returns:
            None
        &#34;&#34;&#34;
        c &#61; m &#61;&#61; self.model[-1] and isinstance(x, list)  # is final layer list, copy input as inplace fix
        flops &#61; thop.profile(m, inputs&#61;[x.copy() if c else x], verbose&#61;False)[0] / 1E9 * 2 if thop else 0  # FLOPs
        t &#61; time_sync()
        for _ in range(10):
            m(x.copy() if c else x)
        dt.append((time_sync() - t) * 100)
        if m &#61;&#61; self.model[0]:
            LOGGER.info(f&#34;{&#39;time (ms)&#39;:&gt;10s} {&#39;GFLOPs&#39;:&gt;10s} {&#39;params&#39;:&gt;10s}  module&#34;)
        LOGGER.info(f&#39;{dt[-1]:10.2f} {flops:10.2f} {m.np:10.0f}  {m.type}&#39;)
        if c:
            LOGGER.info(f&#34;{sum(dt):10.2f} {&#39;-&#39;:&gt;10s} {&#39;-&#39;:&gt;10s}  Total&#34;)

    def fuse(self, verbose&#61;True):
        &#34;&#34;&#34;
        Fuse the &#96;Conv2d()&#96; and &#96;BatchNorm2d()&#96; layers of the model into a single layer, in order to improve the
        computation efficiency.

        Returns:
            (nn.Module): The fused model is returned.
        &#34;&#34;&#34;
        if not self.is_fused():
            for m in self.model.modules():
                if isinstance(m, (Conv, Conv2, DWConv)) and hasattr(m, &#39;bn&#39;):
                    if isinstance(m, Conv2):
                        m.fuse_convs()
                    m.conv &#61; fuse_conv_and_bn(m.conv, m.bn)  # update conv
                    delattr(m, &#39;bn&#39;)  # remove batchnorm
                    m.forward &#61; m.forward_fuse  # update forward
                if isinstance(m, ConvTranspose) and hasattr(m, &#39;bn&#39;):
                    m.conv_transpose &#61; fuse_deconv_and_bn(m.conv_transpose, m.bn)
                    delattr(m, &#39;bn&#39;)  # remove batchnorm
                    m.forward &#61; m.forward_fuse  # update forward
                if isinstance(m, RepConv):
                    m.fuse_convs()
                    m.forward &#61; m.forward_fuse  # update forward
            self.info(verbose&#61;verbose)

        return self

    def is_fused(self, thresh&#61;10):
        &#34;&#34;&#34;
        Check if the model has less than a certain threshold of BatchNorm layers.

        Args:
            thresh (int, optional): The threshold number of BatchNorm layers. Default is 10.

        Returns:
            (bool): True if the number of BatchNorm layers in the model is less than the threshold, False otherwise.
        &#34;&#34;&#34;
        bn &#61; tuple(v for k, v in nn.__dict__.items() if &#39;Norm&#39; in k)  # normalization layers, i.e. BatchNorm2d()
        return sum(isinstance(v, bn) for v in self.modules()) &lt; thresh  # True if &lt; &#39;thresh&#39; BatchNorm layers in model

    def info(self, detailed&#61;False, verbose&#61;True, imgsz&#61;640):
        &#34;&#34;&#34;
        Prints model information

        Args:
            detailed (bool): if True, prints out detailed information about the model. Defaults to False
            verbose (bool): if True, prints out the model information. Defaults to False
            imgsz (int): the size of the image that the model will be trained on. Defaults to 640
        &#34;&#34;&#34;
        return model_info(self, detailed&#61;detailed, verbose&#61;verbose, imgsz&#61;imgsz)

    def _apply(self, fn):
        &#34;&#34;&#34;
        Applies a function to all the tensors in the model that are not parameters or registered buffers.

        Args:
            fn (function): the function to apply to the model

        Returns:
            A model that is a Detect() object.
        &#34;&#34;&#34;
        self &#61; super()._apply(fn)
        m &#61; self.model[-1]  # Detect()
        if isinstance(m, (Detect, Segment)):
            m.stride &#61; fn(m.stride)
            m.anchors &#61; fn(m.anchors)
            m.strides &#61; fn(m.strides)
        return self

    def load(self, weights, verbose&#61;True):
        &#34;&#34;&#34;
        Load the weights into the model.

        Args:
            weights (dict | torch.nn.Module): The pre-trained weights to be loaded.
            verbose (bool, optional): Whether to log the transfer progress. Defaults to True.
        &#34;&#34;&#34;
        model &#61; weights[&#39;model&#39;] if isinstance(weights, dict) else weights  # torchvision models are not dicts
        csd &#61; model.float().state_dict()  # checkpoint state_dict as FP32
        csd &#61; intersect_dicts(csd, self.state_dict())  # intersect
        self.load_state_dict(csd, strict&#61;False)  # load
        if verbose:
            LOGGER.info(f&#39;Transferred {len(csd)}/{len(self.model.state_dict())} items from pretrained weights&#39;)

    def loss(self, batch, preds&#61;None):
        &#34;&#34;&#34;
        Compute loss

        Args:
            batch (dict): Batch to compute loss on
            preds (torch.Tensor | List[torch.Tensor]): Predictions.
        &#34;&#34;&#34;
        if not hasattr(self, &#39;criterion&#39;):
            self.criterion &#61; self.init_criterion()

        preds &#61; self.forward(batch[&#39;img&#39;]) if preds is None else preds
        return self.criterion(preds, batch)

    def init_criterion(self):
        raise NotImplementedError(&#39;compute_loss() needs to be implemented by task heads&#39;)


class DetectionModel(BaseModel):
    &#34;&#34;&#34;YOLOv8 detection model.&#34;&#34;&#34;

    def __init__(self, cfg&#61;&#39;yolov8n.yaml&#39;, ch&#61;3, nc&#61;None, verbose&#61;True):  # model, input channels, number of classes
        super().__init__()
        self.yaml &#61; cfg if isinstance(cfg, dict) else yaml_model_load(cfg)  # cfg dict

        # Define model
        ch &#61; self.yaml[&#39;ch&#39;] &#61; self.yaml.get(&#39;ch&#39;, ch)  # input channels
        if nc and nc !&#61; self.yaml[&#39;nc&#39;]:
            LOGGER.info(f&#34;Overriding model.yaml nc&#61;{self.yaml[&#39;nc&#39;]} with nc&#61;{nc}&#34;)
            self.yaml[&#39;nc&#39;] &#61; nc  # override YAML value
        self.model, self.save &#61; parse_model(deepcopy(self.yaml), ch&#61;ch, verbose&#61;verbose)  # model, savelist
        self.names &#61; {i: f&#39;{i}&#39; for i in range(self.yaml[&#39;nc&#39;])}  # default names dict
        self.inplace &#61; self.yaml.get(&#39;inplace&#39;, True)

        # Build strides
        m &#61; self.model[-1]  # Detect()
        if isinstance(m, (Detect, Segment, Pose)):
            s &#61; 256  # 2x min stride
            m.inplace &#61; self.inplace
            forward &#61; lambda x: self.forward(x)[0] if isinstance(m, (Segment, Pose)) else self.forward(x)
            m.stride &#61; torch.tensor([s / x.shape[-2] for x in forward(torch.zeros(1, ch, s, s))])  # forward
            self.stride &#61; m.stride
            m.bias_init()  # only run once
        else:
            self.stride &#61; torch.Tensor([32])  # default stride for i.e. RTDETR

        # Init weights, biases
        initialize_weights(self)
        if verbose:
            self.info()
            LOGGER.info(&#39;&#39;)

    def _predict_augment(self, x):
        &#34;&#34;&#34;Perform augmentations on input image x and return augmented inference and train outputs.&#34;&#34;&#34;
        img_size &#61; x.shape[-2:]  # height, width
        s &#61; [1, 0.83, 0.67]  # scales
        f &#61; [None, 3, None]  # flips (2-ud, 3-lr)
        y &#61; []  # outputs
        for si, fi in zip(s, f):
            xi &#61; scale_img(x.flip(fi) if fi else x, si, gs&#61;int(self.stride.max()))
            yi &#61; super().predict(xi)[0]  # forward
            yi &#61; self._descale_pred(yi, fi, si, img_size)
            y.append(yi)
        y &#61; self._clip_augmented(y)  # clip augmented tails
        return torch.cat(y, -1), None  # augmented inference, train

    &#64;staticmethod
    def _descale_pred(p, flips, scale, img_size, dim&#61;1):
        &#34;&#34;&#34;De-scale predictions following augmented inference (inverse operation).&#34;&#34;&#34;
        p[:, :4] /&#61; scale  # de-scale
        x, y, wh, cls &#61; p.split((1, 1, 2, p.shape[dim] - 4), dim)
        if flips &#61;&#61; 2:
            y &#61; img_size[0] - y  # de-flip ud
        elif flips &#61;&#61; 3:
            x &#61; img_size[1] - x  # de-flip lr
        return torch.cat((x, y, wh, cls), dim)

    def _clip_augmented(self, y):
        &#34;&#34;&#34;Clip YOLOv5 augmented inference tails.&#34;&#34;&#34;
        nl &#61; self.model[-1].nl  # number of detection layers (P3-P5)
        g &#61; sum(4 ** x for x in range(nl))  # grid points
        e &#61; 1  # exclude layer count
        i &#61; (y[0].shape[-1] // g) * sum(4 ** x for x in range(e))  # indices
        y[0] &#61; y[0][..., :-i]  # large
        i &#61; (y[-1].shape[-1] // g) * sum(4 ** (nl - 1 - x) for x in range(e))  # indices
        y[-1] &#61; y[-1][..., i:]  # small
        return y

    def init_criterion(self):
        return v8DetectionLoss(self)


class SegmentationModel(DetectionModel):
    &#34;&#34;&#34;YOLOv8 segmentation model.&#34;&#34;&#34;

    def __init__(self, cfg&#61;&#39;yolov8n-seg.yaml&#39;, ch&#61;3, nc&#61;None, verbose&#61;True):
        &#34;&#34;&#34;Initialize YOLOv8 segmentation model with given config and parameters.&#34;&#34;&#34;
        super().__init__(cfg&#61;cfg, ch&#61;ch, nc&#61;nc, verbose&#61;verbose)

    def init_criterion(self):
        return v8SegmentationLoss(self)


class PoseModel(DetectionModel):
    &#34;&#34;&#34;YOLOv8 pose model.&#34;&#34;&#34;

    def __init__(self, cfg&#61;&#39;yolov8n-pose.yaml&#39;, ch&#61;3, nc&#61;None, data_kpt_shape&#61;(None, None), verbose&#61;True):
        &#34;&#34;&#34;Initialize YOLOv8 Pose model.&#34;&#34;&#34;
        if not isinstance(cfg, dict):
            cfg &#61; yaml_model_load(cfg)  # load model YAML
        if any(data_kpt_shape) and list(data_kpt_shape) !&#61; list(cfg[&#39;kpt_shape&#39;]):
            LOGGER.info(f&#34;Overriding model.yaml kpt_shape&#61;{cfg[&#39;kpt_shape&#39;]} with kpt_shape&#61;{data_kpt_shape}&#34;)
            cfg[&#39;kpt_shape&#39;] &#61; data_kpt_shape
        super().__init__(cfg&#61;cfg, ch&#61;ch, nc&#61;nc, verbose&#61;verbose)

    def init_criterion(self):
        return v8PoseLoss(self)


class ClassificationModel(BaseModel):
    &#34;&#34;&#34;YOLOv8 classification model.&#34;&#34;&#34;

    def __init__(self,
                 cfg&#61;&#39;yolov8n-cls.yaml&#39;,
                 model&#61;None,
                 ch&#61;3,
                 nc&#61;None,
                 cutoff&#61;10,
                 verbose&#61;True):  # YAML, model, channels, number of classes, cutoff index, verbose flag
        super().__init__()
        self._from_detection_model(model, nc, cutoff) if model is not None else self._from_yaml(cfg, ch, nc, verbose)

    def _from_detection_model(self, model, nc&#61;1000, cutoff&#61;10):
        &#34;&#34;&#34;Create a YOLOv5 classification model from a YOLOv5 detection model.&#34;&#34;&#34;
        from ultralytics.nn.autobackend import AutoBackend
        if isinstance(model, AutoBackend):
            model &#61; model.model  # unwrap DetectMultiBackend
        model.model &#61; model.model[:cutoff]  # backbone
        m &#61; model.model[-1]  # last layer
        ch &#61; m.conv.in_channels if hasattr(m, &#39;conv&#39;) else m.cv1.conv.in_channels  # ch into module
        c &#61; Classify(ch, nc)  # Classify()
        c.i, c.f, c.type &#61; m.i, m.f, &#39;models.common.Classify&#39;  # index, from, type
        model.model[-1] &#61; c  # replace
        self.model &#61; model.model
        self.stride &#61; model.stride
        self.save &#61; []
        self.nc &#61; nc

    def _from_yaml(self, cfg, ch, nc, verbose):
        &#34;&#34;&#34;Set YOLOv8 model configurations and define the model architecture.&#34;&#34;&#34;
        self.yaml &#61; cfg if isinstance(cfg, dict) else yaml_model_load(cfg)  # cfg dict

        # Define model
        ch &#61; self.yaml[&#39;ch&#39;] &#61; self.yaml.get(&#39;ch&#39;, ch)  # input channels
        if nc and nc !&#61; self.yaml[&#39;nc&#39;]:
            LOGGER.info(f&#34;Overriding model.yaml nc&#61;{self.yaml[&#39;nc&#39;]} with nc&#61;{nc}&#34;)
            self.yaml[&#39;nc&#39;] &#61; nc  # override YAML value
        elif not nc and not self.yaml.get(&#39;nc&#39;, None):
            raise ValueError(&#39;nc not specified. Must specify nc in model.yaml or function arguments.&#39;)
        self.model, self.save &#61; parse_model(deepcopy(self.yaml), ch&#61;ch, verbose&#61;verbose)  # model, savelist
        self.stride &#61; torch.Tensor([1])  # no stride constraints
        self.names &#61; {i: f&#39;{i}&#39; for i in range(self.yaml[&#39;nc&#39;])}  # default names dict
        self.info()

    &#64;staticmethod
    def reshape_outputs(model, nc):
        &#34;&#34;&#34;Update a TorchVision classification model to class count &#39;n&#39; if required.&#34;&#34;&#34;
        name, m &#61; list((model.model if hasattr(model, &#39;model&#39;) else model).named_children())[-1]  # last module
        if isinstance(m, Classify):  # YOLO Classify() head
            if m.linear.out_features !&#61; nc:
                m.linear &#61; nn.Linear(m.linear.in_features, nc)
        elif isinstance(m, nn.Linear):  # ResNet, EfficientNet
            if m.out_features !&#61; nc:
                setattr(model, name, nn.Linear(m.in_features, nc))
        elif isinstance(m, nn.Sequential):
            types &#61; [type(x) for x in m]
            if nn.Linear in types:
                i &#61; types.index(nn.Linear)  # nn.Linear index
                if m[i].out_features !&#61; nc:
                    m[i] &#61; nn.Linear(m[i].in_features, nc)
            elif nn.Conv2d in types:
                i &#61; types.index(nn.Conv2d)  # nn.Conv2d index
                if m[i].out_channels !&#61; nc:
                    m[i] &#61; nn.Conv2d(m[i].in_channels, nc, m[i].kernel_size, m[i].stride, bias&#61;m[i].bias is not None)

    def init_criterion(self):
        &#34;&#34;&#34;Compute the classification loss between predictions and true labels.&#34;&#34;&#34;
        return v8ClassificationLoss()


class RTDETRDetectionModel(DetectionModel):

    def __init__(self, cfg&#61;&#39;rtdetr-l.yaml&#39;, ch&#61;3, nc&#61;None, verbose&#61;True):
        super().__init__(cfg&#61;cfg, ch&#61;ch, nc&#61;nc, verbose&#61;verbose)

    def init_criterion(self):
        &#34;&#34;&#34;Compute the classification loss between predictions and true labels.&#34;&#34;&#34;
        from ultralytics.models.utils.loss import RTDETRDetectionLoss

        return RTDETRDetectionLoss(nc&#61;self.nc, use_vfl&#61;True)

    def loss(self, batch, preds&#61;None):
        if not hasattr(self, &#39;criterion&#39;):
            self.criterion &#61; self.init_criterion()

        img &#61; batch[&#39;img&#39;]
        # NOTE: preprocess gt_bbox and gt_labels to list.
        bs &#61; len(img)
        batch_idx &#61; batch[&#39;batch_idx&#39;]
        gt_groups &#61; [(batch_idx &#61;&#61; i).sum().item() for i in range(bs)]
        targets &#61; {
            &#39;cls&#39;: batch[&#39;cls&#39;].to(img.device, dtype&#61;torch.long).view(-1),
            &#39;bboxes&#39;: batch[&#39;bboxes&#39;].to(device&#61;img.device),
            &#39;batch_idx&#39;: batch_idx.to(img.device, dtype&#61;torch.long).view(-1),
            &#39;gt_groups&#39;: gt_groups}

        preds &#61; self.predict(img, batch&#61;targets) if preds is None else preds
        dec_bboxes, dec_scores, enc_bboxes, enc_scores, dn_meta &#61; preds if self.training else preds[1]
        if dn_meta is None:
            dn_bboxes, dn_scores &#61; None, None
        else:
            dn_bboxes, dec_bboxes &#61; torch.split(dec_bboxes, dn_meta[&#39;dn_num_split&#39;], dim&#61;2)
            dn_scores, dec_scores &#61; torch.split(dec_scores, dn_meta[&#39;dn_num_split&#39;], dim&#61;2)

        dec_bboxes &#61; torch.cat([enc_bboxes.unsqueeze(0), dec_bboxes])  # (7, bs, 300, 4)
        dec_scores &#61; torch.cat([enc_scores.unsqueeze(0), dec_scores])

        loss &#61; self.criterion((dec_bboxes, dec_scores),
                              targets,
                              dn_bboxes&#61;dn_bboxes,
                              dn_scores&#61;dn_scores,
                              dn_meta&#61;dn_meta)
        # NOTE: There are like 12 losses in RTDETR, backward with all losses but only show the main three losses.
        return sum(loss.values()), torch.as_tensor([loss[k].detach() for k in [&#39;loss_giou&#39;, &#39;loss_class&#39;, &#39;loss_bbox&#39;]],
                                                   device&#61;img.device)

    def predict(self, x, profile&#61;False, visualize&#61;False, batch&#61;None, augment&#61;False):
        &#34;&#34;&#34;
        Perform a forward pass through the network.

        Args:
            x (torch.Tensor): The input tensor to the model
            profile (bool):  Print the computation time of each layer if True, defaults to False.
            visualize (bool): Save the feature maps of the model if True, defaults to False
            batch (dict): A dict including gt boxes and labels from dataloader.

        Returns:
            (torch.Tensor): The last output of the model.
        &#34;&#34;&#34;
        y, dt &#61; [], []  # outputs
        for m in self.model[:-1]:  # except the head part
            if m.f !&#61; -1:  # if not from previous layer
                x &#61; y[m.f] if isinstance(m.f, int) else [x if j &#61;&#61; -1 else y[j] for j in m.f]  # from earlier layers
            if profile:
                self._profile_one_layer(m, x, dt)
            x &#61; m(x)  # run
            y.append(x if m.i in self.save else None)  # save output
            if visualize:
                feature_visualization(x, m.type, m.i, save_dir&#61;visualize)
        head &#61; self.model[-1]
        x &#61; head([y[j] for j in head.f], batch)  # head inference
        return x


class Ensemble(nn.ModuleList):
    &#34;&#34;&#34;Ensemble of models.&#34;&#34;&#34;

    def __init__(self):
        &#34;&#34;&#34;Initialize an ensemble of models.&#34;&#34;&#34;
        super().__init__()

    def forward(self, x, augment&#61;False, profile&#61;False, visualize&#61;False):
        &#34;&#34;&#34;Function generates the YOLOv5 network&#39;s final layer.&#34;&#34;&#34;
        y &#61; [module(x, augment, profile, visualize)[0] for module in self]
        # y &#61; torch.stack(y).max(0)[0]  # max ensemble
        # y &#61; torch.stack(y).mean(0)  # mean ensemble
        y &#61; torch.cat(y, 2)  # nms ensemble, y shape(B, HW, C)
        return y, None  # inference, train output


# Functions ------------------------------------------------------------------------------------------------------------


&#64;contextlib.contextmanager
def temporary_modules(modules&#61;None):
    &#34;&#34;&#34;
    Context manager for temporarily adding or modifying modules in Python&#39;s module cache (&#96;sys.modules&#96;).

    This function can be used to change the module paths during runtime. It&#39;s useful when refactoring code,
    where you&#39;ve moved a module from one location to another, but you still want to support the old import
    paths for backwards compatibility.

    Args:
        modules (dict, optional): A dictionary mapping old module paths to new module paths.

    Example:
        &#96;&#96;&#96;python
        with temporary_modules({&#39;old.module.path&#39;: &#39;new.module.path&#39;}):
            import old.module.path  # this will now import new.module.path
        &#96;&#96;&#96;

    Note:
        The changes are only in effect inside the context manager and are undone once the context manager exits.
        Be aware that directly manipulating &#96;sys.modules&#96; can lead to unpredictable results, especially in larger
        applications or libraries. Use this function with caution.
    &#34;&#34;&#34;
    if not modules:
        modules &#61; {}

    import importlib
    import sys
    try:
        # Set modules in sys.modules under their old name
        for old, new in modules.items():
            sys.modules[old] &#61; importlib.import_module(new)

        yield
    finally:
        # Remove the temporary module paths
        for old in modules:
            if old in sys.modules:
                del sys.modules[old]


def torch_safe_load(weight):
    &#34;&#34;&#34;
    This function attempts to load a PyTorch model with the torch.load() function. If a ModuleNotFoundError is raised,
    it catches the error, logs a warning message, and attempts to install the missing module via the
    check_requirements() function. After installation, the function again attempts to load the model using torch.load().

    Args:
        weight (str): The file path of the PyTorch model.

    Returns:
        (dict): The loaded PyTorch model.
    &#34;&#34;&#34;
    from ultralytics.utils.downloads import attempt_download_asset

    check_suffix(file&#61;weight, suffix&#61;&#39;.pt&#39;)
    file &#61; attempt_download_asset(weight)  # search online if missing locally
    try:
        with temporary_modules({
                &#39;ultralytics.yolo.utils&#39;: &#39;ultralytics.utils&#39;,
                &#39;ultralytics.yolo.v8&#39;: &#39;ultralytics.models.yolo&#39;,
                &#39;ultralytics.yolo.data&#39;: &#39;ultralytics.data&#39;}):  # for legacy 8.0 Classify and Pose models
            return torch.load(file, map_location&#61;&#39;cpu&#39;), file  # load

    except ModuleNotFoundError as e:  # e.name is missing module name
        if e.name &#61;&#61; &#39;models&#39;:
            raise TypeError(
                emojis(f&#39;ERROR ❌️ {weight} appears to be an Ultralytics YOLOv5 model originally trained &#39;
                       f&#39;with https://github.com/ultralytics/yolov5.\nThis model is NOT forwards compatible with &#39;
                       f&#39;YOLOv8 at https://github.com/ultralytics/ultralytics.&#39;
                       f&#34;\nRecommend fixes are to train a new model using the latest &#39;ultralytics&#39; package or to &#34;
                       f&#34;run a command with an official YOLOv8 model, i.e. &#39;yolo predict model&#61;yolov8n.pt&#39;&#34;)) from e
        LOGGER.warning(f&#34;WARNING ⚠️ {weight} appears to require &#39;{e.name}&#39;, which is not in ultralytics requirements.&#34;
                       f&#34;\nAutoInstall will run now for &#39;{e.name}&#39; but this feature will be removed in the future.&#34;
                       f&#34;\nRecommend fixes are to train a new model using the latest &#39;ultralytics&#39; package or to &#34;
                       f&#34;run a command with an official YOLOv8 model, i.e. &#39;yolo predict model&#61;yolov8n.pt&#39;&#34;)
        check_requirements(e.name)  # install missing module

        return torch.load(file, map_location&#61;&#39;cpu&#39;), file  # load


def attempt_load_weights(weights, device&#61;None, inplace&#61;True, fuse&#61;False):
    &#34;&#34;&#34;Loads an ensemble of models weights&#61;[a,b,c] or a single model weights&#61;[a] or weights&#61;a.&#34;&#34;&#34;

    ensemble &#61; Ensemble()
    for w in weights if isinstance(weights, list) else [weights]:
        ckpt, w &#61; torch_safe_load(w)  # load ckpt
        args &#61; {**DEFAULT_CFG_DICT, **ckpt[&#39;train_args&#39;]} if &#39;train_args&#39; in ckpt else None  # combined args
        model &#61; (ckpt.get(&#39;ema&#39;) or ckpt[&#39;model&#39;]).to(device).float()  # FP32 model

        # Model compatibility updates
        model.args &#61; args  # attach args to model
        model.pt_path &#61; w  # attach *.pt file path to model
        model.task &#61; guess_model_task(model)
        if not hasattr(model, &#39;stride&#39;):
            model.stride &#61; torch.tensor([32.])

        # Append
        ensemble.append(model.fuse().eval() if fuse and hasattr(model, &#39;fuse&#39;) else model.eval())  # model in eval mode

    # Module updates
    for m in ensemble.modules():
        t &#61; type(m)
        if t in (nn.Hardswish, nn.LeakyReLU, nn.ReLU, nn.ReLU6, nn.SiLU, Detect, Segment):
            m.inplace &#61; inplace
        elif t is nn.Upsample and not hasattr(m, &#39;recompute_scale_factor&#39;):
            m.recompute_scale_factor &#61; None  # torch 1.11.0 compatibility

    # Return model
    if len(ensemble) &#61;&#61; 1:
        return ensemble[-1]

    # Return ensemble
    LOGGER.info(f&#39;Ensemble created with {weights}\n&#39;)
    for k in &#39;names&#39;, &#39;nc&#39;, &#39;yaml&#39;:
        setattr(ensemble, k, getattr(ensemble[0], k))
    ensemble.stride &#61; ensemble[torch.argmax(torch.tensor([m.stride.max() for m in ensemble])).int()].stride
    assert all(ensemble[0].nc &#61;&#61; m.nc for m in ensemble), f&#39;Models differ in class counts {[m.nc for m in ensemble]}&#39;
    return ensemble


def attempt_load_one_weight(weight, device&#61;None, inplace&#61;True, fuse&#61;False):
    &#34;&#34;&#34;Loads a single model weights.&#34;&#34;&#34;
    ckpt, weight &#61; torch_safe_load(weight)  # load ckpt
    args &#61; {**DEFAULT_CFG_DICT, **(ckpt.get(&#39;train_args&#39;, {}))}  # combine model and default args, preferring model args
    model &#61; (ckpt.get(&#39;ema&#39;) or ckpt[&#39;model&#39;]).to(device).float()  # FP32 model

    # Model compatibility updates
    model.args &#61; {k: v for k, v in args.items() if k in DEFAULT_CFG_KEYS}  # attach args to model
    model.pt_path &#61; weight  # attach *.pt file path to model
    model.task &#61; guess_model_task(model)
    if not hasattr(model, &#39;stride&#39;):
        model.stride &#61; torch.tensor([32.])

    model &#61; model.fuse().eval() if fuse and hasattr(model, &#39;fuse&#39;) else model.eval()  # model in eval mode

    # Module updates
    for m in model.modules():
        t &#61; type(m)
        if t in (nn.Hardswish, nn.LeakyReLU, nn.ReLU, nn.ReLU6, nn.SiLU, Detect, Segment):
            m.inplace &#61; inplace
        elif t is nn.Upsample and not hasattr(m, &#39;recompute_scale_factor&#39;):
            m.recompute_scale_factor &#61; None  # torch 1.11.0 compatibility

    # Return model and ckpt
    return model, ckpt


def parse_model(d, ch, verbose&#61;True):  # model_dict, input_channels(3)
    &#34;&#34;&#34;Parse a YOLO model.yaml dictionary into a PyTorch model.&#34;&#34;&#34;
    import ast

    # Args
    max_channels &#61; float(&#39;inf&#39;)
    nc, act, scales &#61; (d.get(x) for x in (&#39;nc&#39;, &#39;activation&#39;, &#39;scales&#39;))
    depth, width, kpt_shape &#61; (d.get(x, 1.0) for x in (&#39;depth_multiple&#39;, &#39;width_multiple&#39;, &#39;kpt_shape&#39;))
    if scales:
        scale &#61; d.get(&#39;scale&#39;)
        if not scale:
            scale &#61; tuple(scales.keys())[0]
            LOGGER.warning(f&#34;WARNING ⚠️ no model scale passed. Assuming scale&#61;&#39;{scale}&#39;.&#34;)
        depth, width, max_channels &#61; scales[scale]

    if act:
        Conv.default_act &#61; eval(act)  # redefine default activation, i.e. Conv.default_act &#61; nn.SiLU()
        if verbose:
            LOGGER.info(f&#34;{colorstr(&#39;activation:&#39;)} {act}&#34;)  # print

    if verbose:
        LOGGER.info(f&#34;\n{&#39;&#39;:&gt;3}{&#39;from&#39;:&gt;20}{&#39;n&#39;:&gt;3}{&#39;params&#39;:&gt;10}  {&#39;module&#39;:&lt;45}{&#39;arguments&#39;:&lt;30}&#34;)
    ch &#61; [ch]
    layers, save, c2 &#61; [], [], ch[-1]  # layers, savelist, ch out
    for i, (f, n, m, args) in enumerate(d[&#39;backbone&#39;] &#43; d[&#39;head&#39;]):  # from, number, module, args
        m &#61; getattr(torch.nn, m[3:]) if &#39;nn.&#39; in m else globals()[m]  # get module
        for j, a in enumerate(args):
            if isinstance(a, str):
                with contextlib.suppress(ValueError):
                    args[j] &#61; locals()[a] if a in locals() else ast.literal_eval(a)

        n &#61; n_ &#61; max(round(n * depth), 1) if n &gt; 1 else n  # depth gain
        if m in (Classify, Conv, ConvTranspose, GhostConv, Bottleneck, GhostBottleneck, SPP, SPPF, DWConv, Focus,
                 BottleneckCSP, C1, C2, C2f, C3, C3TR, C3Ghost, nn.ConvTranspose2d, DWConvTranspose2d, C3x, RepC3,
                 SimConv, nn.Conv2d):
            c1, c2 &#61; ch[f], args[0]
            if c2 !&#61; nc:  # if c2 not equal to number of classes (i.e. for Classify() output)
                c2 &#61; make_divisible(min(c2, max_channels) * width, 8)
            args &#61; [c1, c2, *args[1:]]
            if m in (BottleneckCSP, C1, C2, C2f, C3, C3TR, C3Ghost, C3x, RepC3):
                args.insert(2, n)  # number of repeats
                n &#61; 1
        elif m is AIFI:
            args &#61; [ch[f], *args]
        elif m in (HGStem, HGBlock):
            c1, cm, c2 &#61; ch[f], args[0], args[1]
            args &#61; [c1, cm, c2, *args[2:]]
            if m is HGBlock:
                args.insert(4, n)  # number of repeats
                n &#61; 1
        elif m is nn.BatchNorm2d:
            args &#61; [ch[f]]
        # --------------GOLD-YOLO--------------
        elif m in (Low_FAM, High_FAM, High_LAF):
            c2 &#61; sum(ch[x] for x in f)
        elif m is Low_IFM:
            c1, c2 &#61; ch[f], args[2]
            if c2 !&#61; nc:  # if c2 not equal to number of classes (i.e. for Classify() output)
                c2 &#61; make_divisible(min(c2, max_channels) * width, 8)
            args &#61; [c1, *args[:-1], c2]
        elif m is Low_LAF:
            c1, c2 &#61; ch[f[1]], args[0]
            if c2 !&#61; nc:  # if c2 not equal to number of classes (i.e. for Classify() output)
                c2 &#61; make_divisible(min(c2, max_channels) * width, 8)
            args &#61; [c1, c2, *args[1:]]
        elif m is Inject:
            global_index &#61; args[1]
            c1, c2 &#61; ch[f[1]][global_index], args[0]
            if c2 !&#61; nc:  # if c2 not equal to number of classes (i.e. for Classify() output)
                c2 &#61; make_divisible(min(c2, max_channels) * width, 8)
            args &#61; [c1, c2, global_index]
        elif m is RepBlock:
            c1, c2 &#61; ch[f], args[0]
            if c2 !&#61; nc:  # if c2 not equal to number of classes (i.e. for Classify() output)
                c2 &#61; make_divisible(min(c2, max_channels) * width, 8)
            nums_repeat &#61; max(round(args[1] * depth), 1) if args[1] &gt; 1 else args[1]  # depth gain
            args &#61; [c1, c2, nums_repeat]
        elif m is Split:
            c2 &#61; []
            for arg in args:
                if arg !&#61; nc:  # if c2 not equal to number of classes (i.e. for Classify() output)
                    c2.append(make_divisible(min(arg, max_channels) * width, 8))
            args &#61; [c2]
        # --------------GOLD-YOLO--------------
        elif m in (Concat, Low_FAM, High_FAM, High_LAF):
            c2 &#61; sum(ch[x] for x in f)
        elif m in (Detect, Segment, Pose):
            args.append([ch[x] for x in f])
            if m is Segment:
                args[2] &#61; make_divisible(min(args[2], max_channels) * width, 8)
        elif m is RTDETRDecoder:  # special case, channels arg must be passed in index 1
            args.insert(1, [ch[x] for x in f])

        else:
            # High_IFM
            c2 &#61; ch[f]
        m_ &#61; nn.Sequential(*(m(*args) for _ in range(n))) if n &gt; 1 else m(*args)  # module
        t &#61; str(m)[8:-2].replace(&#39;__main__.&#39;, &#39;&#39;)  # module type
        m.np &#61; sum(x.numel() for x in m_.parameters())# number params
        m_.i, m_.f, m_.type &#61; i, f, t  # attach index, &#39;from&#39; index, type

        if m in [Inject, High_LAF]:
            # input nums
            m_.input_nums &#61; len(f)
        else:
            m_.input_nums &#61; 1

        if verbose:
            LOGGER.info(f&#39;{i:&gt;3}{str(f):&gt;20}{n_:&gt;3}{m.np:10.0f}  {t:&lt;45}{str(args):&lt;30}&#39;)  # print
        save.extend(x % i for x in ([f] if isinstance(f, int) else f) if x !&#61; -1)  # append to savelist
        layers.append(m_)
        if i &#61;&#61; 0:
            ch &#61; []
        ch.append(c2)
    return nn.Sequential(*layers), sorted(save)


def yaml_model_load(path):
    &#34;&#34;&#34;Load a YOLOv8 model from a YAML file.&#34;&#34;&#34;
    import re

    path &#61; Path(path)
    if path.stem in (f&#39;yolov{d}{x}6&#39; for x in &#39;nsmlx&#39; for d in (5, 8)):
        new_stem &#61; re.sub(r&#39;(\d&#43;)([nslmx])6(.&#43;)?$&#39;, r&#39;\1\2-p6\3&#39;, path.stem)
        LOGGER.warning(f&#39;WARNING ⚠️ Ultralytics YOLO P6 models now use -p6 suffix. Renaming {path.stem} to {new_stem}.&#39;)
        path &#61; path.with_name(new_stem &#43; path.suffix)

    unified_path &#61; re.sub(r&#39;(\d&#43;)([nslmx])(.&#43;)?$&#39;, r&#39;\1\3&#39;, str(path))  # i.e. yolov8x.yaml -&gt; yolov8.yaml
    yaml_file &#61; check_yaml(unified_path, hard&#61;False) or check_yaml(path)
    d &#61; yaml_load(yaml_file)  # model dict
    d[&#39;scale&#39;] &#61; guess_model_scale(path)
    d[&#39;yaml_file&#39;] &#61; str(path)
    return d


def guess_model_scale(model_path):
    &#34;&#34;&#34;
    Takes a path to a YOLO model&#39;s YAML file as input and extracts the size character of the model&#39;s scale.
    The function uses regular expression matching to find the pattern of the model scale in the YAML file name,
    which is denoted by n, s, m, l, or x. The function returns the size character of the model scale as a string.

    Args:
        model_path (str | Path): The path to the YOLO model&#39;s YAML file.

    Returns:
        (str): The size character of the model&#39;s scale, which can be n, s, m, l, or x.
    &#34;&#34;&#34;
    with contextlib.suppress(AttributeError):
        import re
        return re.search(r&#39;yolov\d&#43;([nslmx])&#39;, Path(model_path).stem).group(1)  # n, s, m, l, or x
    return &#39;&#39;


def guess_model_task(model):
    &#34;&#34;&#34;
    Guess the task of a PyTorch model from its architecture or configuration.

    Args:
        model (nn.Module | dict): PyTorch model or model configuration in YAML format.

    Returns:
        (str): Task of the model (&#39;detect&#39;, &#39;segment&#39;, &#39;classify&#39;, &#39;pose&#39;).

    Raises:
        SyntaxError: If the task of the model could not be determined.
    &#34;&#34;&#34;

    def cfg2task(cfg):
        &#34;&#34;&#34;Guess from YAML dictionary.&#34;&#34;&#34;
        m &#61; cfg[&#39;head&#39;][-1][-2].lower()  # output module name
        if m in (&#39;classify&#39;, &#39;classifier&#39;, &#39;cls&#39;, &#39;fc&#39;):
            return &#39;classify&#39;
        if m &#61;&#61; &#39;detect&#39;:
            return &#39;detect&#39;
        if m &#61;&#61; &#39;segment&#39;:
            return &#39;segment&#39;
        if m &#61;&#61; &#39;pose&#39;:
            return &#39;pose&#39;

    # Guess from model cfg
    if isinstance(model, dict):
        with contextlib.suppress(Exception):
            return cfg2task(model)

    # Guess from PyTorch model
    if isinstance(model, nn.Module):  # PyTorch model
        for x in &#39;model.args&#39;, &#39;model.model.args&#39;, &#39;model.model.model.args&#39;:
            with contextlib.suppress(Exception):
                return eval(x)[&#39;task&#39;]
        for x in &#39;model.yaml&#39;, &#39;model.model.yaml&#39;, &#39;model.model.model.yaml&#39;:
            with contextlib.suppress(Exception):
                return cfg2task(eval(x))

        for m in model.modules():
            if isinstance(m, Detect):
                return &#39;detect&#39;
            elif isinstance(m, Segment):
                return &#39;segment&#39;
            elif isinstance(m, Classify):
                return &#39;classify&#39;
            elif isinstance(m, Pose):
                return &#39;pose&#39;

    # Guess from model filename
    if isinstance(model, (str, Path)):
        model &#61; Path(model)
        if &#39;-seg&#39; in model.stem or &#39;segment&#39; in model.parts:
            return &#39;segment&#39;
        elif &#39;-cls&#39; in model.stem or &#39;classify&#39; in model.parts:
            return &#39;classify&#39;
        elif &#39;-pose&#39; in model.stem or &#39;pose&#39; in model.parts:
            return &#39;pose&#39;
        elif &#39;detect&#39; in model.parts:
            return &#39;detect&#39;

    # Unable to determine task from model
    LOGGER.warning(&#34;WARNING ⚠️ Unable to automatically guess model task, assuming &#39;task&#61;detect&#39;. &#34;
                   &#34;Explicitly define task for your model, i.e. &#39;task&#61;detect&#39;, &#39;segment&#39;, &#39;classify&#39;, or &#39;pose&#39;.&#34;)
    return &#39;detect&#39;  # assume detect
</code></pre> 
<p></p> 
<hr /> 
<h2 id="%E4%BA%94%E3%80%81Gold-YOLO%E7%9A%84yaml%E6%96%87%E4%BB%B6">五、Gold-YOLO的yaml文件</h2> 
<h3 id="5.1%20yaml%E6%96%87%E4%BB%B6%C2%A0">5.1 yaml文件 </h3> 
<p><span style="color:#fe2c24;"><strong>复制下面的yaml文件&#xff0c;然后利用我给的运行代码进行运行。</strong></span></p> 
<pre><code># Ultralytics YOLO &#x1f680;, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 80  # number of classes
scales: # model compound scaling constants, i.e. &#39;model&#61;yolov8n.yaml&#39; will call yolov8.yaml with scale &#39;n&#39;
  # [depth, width, max_channels]
  n: [0.33, 0.25, 2048]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [0.33, 0.50, 1024]  # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs
  m: [0.67, 0.75, 768]   # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs
  l: [1.00, 1.00, 512]   # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  x: [1.00, 1.25, 512]   # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs

# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]]  # 1-P2/4
  - [-1, 3, C2f, [128, True]] # 2-c2
  - [-1, 1, Conv, [256, 3, 2]]  # 3-P3/8
  - [-1, 6, C2f, [256, True]] # 4-c3
  - [-1, 1, Conv, [512, 3, 2]]  # 5-P4/16
  - [-1, 6, C2f, [512, True]] # 6-c4
  - [-1, 1, Conv, [1024, 3, 2]]  # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]]  # 9-c5

# YOLOv8.0n head
head:
  - [[2, 4, 6, -1], 1, Low_FAM, []]
  - [-1, 1, Low_IFM, [96, 3, 768]]
  - [-1, 1, Split, [512, 256]] # 12-low_global_info

  - [9, 1, SimConv, [512, 1, 1]] # 13-c5_half
  - [[4, 6, -1], 1, Low_LAF, [512]]   
  - [[-1, 12], 1, Inject, [512, 0]]   
  - [-1, 1, RepBlock, [512, 12]] # 16-p4

  - [-1, 1, SimConv, [256, 1, 1]] # 17-p4_half
  - [[2, 4, -1], 1, Low_LAF, [256]]   
  - [[-1, 12], 1, Inject, [256, 1]]   
  - [-1, 1, RepBlock, [256, 12]] # 20-p3

  - [[-1, 16, 9], 1, High_FAM, [1, &#39;torch&#39;]]  
  - [-1, 1, High_IFM, [2, 448, 8, 4, 1, 2, 0, 0, [0.1, 2]]]
  - [-1, 1, nn.Conv2d, [1536, 1, 1, 0]]  
  - [-1, 1, Split, [512, 1024]] # 24-high_global_info  

  - [[20, 17], 1, High_LAF, []]
  - [[-1, 24], 1, Inject, [512, 0]]   
  - [-1, 1, RepBlock, [512, 12]] # 27-n4

  - [[-1, 13], 1, High_LAF, []]
  - [[-1, 24], 1, Inject, [1024, 1]]   
  - [-1, 1, RepBlock, [1024, 12]] # 30-n5

  - [[20, 27, 30], 1, Detect, [nc]]  # Detect(P3, N4, N5)
</code></pre> 
<hr /> 
<h3 id="5.2%20%E8%BF%90%E8%A1%8C%E4%BB%A3%E7%A0%81%C2%A0">5.2 运行代码 </h3> 
<p>创建一个run.py文件放在v8项目的根目录下。</p> 
<pre><code>import warnings
warnings.filterwarnings(&#39;ignore&#39;)
from ultralytics import YOLO

if __name__ &#61;&#61; &#39;__main__&#39;:
    model &#61; YOLO(&#34;替换你的模型yaml文件路径&#34;)
    model.load(&#39;yolov8n.pt&#39;) # 我这里用的n的权重文件&#xff0c;大家可以自行替换自己的版本的
    model.train(data&#61;r&#39;替换你的数据集yaml文件地址&#39;,
                cache&#61;False,
                imgsz&#61;640,
                epochs&#61;150,
                batch&#61;16,
                close_mosaic&#61;0,
                workers&#61;0,
                device&#61;0,
                optimizer&#61;&#39;SGD&#39;, # using SGD
                amp&#61;False,# close amp
                )
</code></pre> 
<p></p> 
<hr /> 
<h3 id="5.3%20%E6%88%90%E5%8A%9F%E8%BF%90%E8%A1%8C%E6%88%AA%E5%9B%BE">5.3 成功运行截图</h3> 
<p><img alt="" height="848" src="https://img-blog.csdnimg.cn/direct/c749570f6f144ac189c0a54e25f387ee.png" width="1061" /></p> 
<p></p> 
<hr /> 
<h2 id="%E5%85%AD%E3%80%81%E5%85%A8%E6%96%87%E6%80%BB%E7%BB%93%C2%A0" style="background-color:transparent;">六、全文总结 </h2> 
<p>到此本文的正式分享内容就结束了&#xff0c;在这里给大家推荐我的YOLOv8改进有效涨点专栏&#xff0c;本专栏目前为新开的平均质量分98分&#xff0c;后期我会根据各种最新的前沿顶会进行论文复现&#xff0c;也会对一些老的改进机制进行补充&#xff0c;<span style="color:#fe2c24;"><strong>目前本专栏免费阅读(暂时&#xff0c;大家尽早关注不迷路~)&#xff0c;</strong></span>如果大家觉得本文帮助到你了&#xff0c;订阅本专栏&#xff0c;关注后续更多的更新~</p> 
<blockquote> 
 <p><strong><span style="color:#fe2c24;">专栏回顾&#xff1a;</span><strong><a href="https://blog.csdn.net/java1314777/category_12483754.html" title="YOLOv8改进系列专栏——本专栏持续复习各种顶会内容——科研必备">YOLOv8改进系列专栏——本专栏持续复习各种顶会内容——科研必备</a></strong></strong></p> 
</blockquote> 
<p><img alt="" height="396" src="https://img-blog.csdnimg.cn/direct/bd80c2385d0548e9a87edc73f9261794.gif" width="1200" />​</p> 
<p></p>
                </div>
        </div>
        <div id="treeSkill"></div>
        <div id="blogExtensionBox" style="width:400px;margin:auto;margin-top:12px" class="blog-extension-box"></div>
    </article>
<script>
  $(function() {
    setTimeout(function () {
      var mathcodeList = document.querySelectorAll('.htmledit_views img.mathcode');
      if (mathcodeList.length > 0) {
        for (let i = 0; i < mathcodeList.length; i++) {
          if (mathcodeList[i].naturalWidth === 0 || mathcodeList[i].naturalHeight === 0) {
            var alt = mathcodeList[i].alt;
            alt = '\\(' + alt + '\\)';
            var curSpan = $('<span class="img-codecogs"></span>');
            curSpan.text(alt);
            $(mathcodeList[i]).before(curSpan);
            $(mathcodeList[i]).remove();
          }
        }
        MathJax.Hub.Queue(["Typeset",MathJax.Hub]);
      }
    }, 1000)
  });
</script>
</div>
<div class="directory-boxshadow-dialog" style="display:none;">
  <div class="directory-boxshadow-dialog-box">
  </div>
  <div class="vip-limited-time-offer-box">
    <div class="vip-limited-time-offer-content">
      <img class="limited-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/vip-limited-close.png">
      <div class="limited-box">
        <span class="limited-num"></span>
        <span class="limited-quan"> 优惠劵</span>
      </div>
      <div class="limited-time-box">
        <span class="time-hour"></span>
        <span class="time-minite"></span>
        <span class="time-second"></span>
      </div>
      <a class="limited-time-btn" href="https://mall.csdn.net/vip" data-report-click='{"spm":"1001.2101.3001.9621"}' data-report-query='spm=1001.2101.3001.9621'></a>
    </div>
  </div>
</div>    <div class="more-toolbox-new" id="toolBarBox">
      <div class="left-toolbox">
        <div class="toolbox-left">
            <div class="profile-box">
              <a class="profile-href" target="_blank" href="https://snu77.blog.csdn.net"><img class="profile-img" src="https://profile-avatar.csdnimg.cn/27160f4941a54d07b535ceabcfa4a800_java1314777.jpg!1">
                <span class="profile-name">
                  Snu77
                </span>
              </a>
            </div>
            <div class="profile-attend">
              
                <a class="tool-attend tool-bt-button tool-unbt-attend" href="javascript:;" data-report-view='{"mod":"1592215036_002","spm":"1001.2101.3001.4232","extend1":"已关注"}'>已关注</a>
              <a class="tool-item-follow active-animation" style="display:none;">关注</a>
            </div>
        </div>
        <div class="toolbox-middle">
          <ul class="toolbox-list">
            <li class="tool-item tool-item-size tool-active is-like" id="is-like">
              <a class="tool-item-href">
                <img style="display:none;" id="is-like-imgactive-animation-like" class="animation-dom active-animation" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarThumbUpactive.png" alt="">
                <img class="isactive" style="display:none" id="is-like-imgactive" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newHeart2021Active.png" alt="">
                <img class="isdefault" style="display:block" id="is-like-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newHeart2021Black.png" alt="">
                <span id="spanCount" class="count ">
                    31
                </span>
              </a>
              <div class="tool-hover-tip"><span class="text space">点赞</span></div>
            </li>
            <li class="tool-item tool-item-size tool-active is-unlike" id="is-unlike">
              <a class="tool-item-href">
                <img class="isactive" style="margin-right:0px;display:none" id="is-unlike-imgactive" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newUnHeart2021Active.png" alt="">
                <img class="isdefault" style="margin-right:0px;display:block" id="is-unlike-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newUnHeart2021Black.png" alt="">
                <span id="unlikeCount" class="count "></span>
              </a>
              <div class="tool-hover-tip"><span class="text space">踩</span></div>
            </li>
            <li class="tool-item tool-item-size tool-active is-collection ">
              <a class="tool-item-href" href="javascript:;" data-report-click='{"mod":"popu_824","spm":"1001.2101.3001.4130","ab":"new"}'>
                <img style="display:none" id="is-collection-img-collection" class="animation-dom active-animation" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarCollectionActive.png" alt="">
                <img class="isdefault" id="is-collection-img" style="display:block" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCollectBlack.png" alt="">
                <img class="isactive" id="is-collection-imgactive" style="display:none" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCollectActive.png" alt="">
                <span class="count get-collection " data-num="27" id="get-collection">
                    27
                </span>
              </a>
              <div class="tool-hover-tip collect">
                <div class="collect-operate-box">
                  <span class="collect-text" id="is-collection">
                    收藏
                  </span>
                </div>
              </div>
              <div class="tool-active-list">
                <div class="text">
                  觉得还不错?
                  <span class="collect-text" id="tool-active-list-collection">
                    一键收藏
                  </span>
                 <img id="tool-active-list-close" src="https://csdnimg.cn/release/blogv2/dist/pc/img/collectionCloseBlack.png" alt="">
                </div>
              </div>
            </li>
                <li class="tool-item tool-item-size tool-active tool-item-reward">
                  <a class="tool-item-href" href="javascript:;" data-report-click='{"mod":"popu_830","spm":"1001.2101.3001.4237","dest":"","ab":"new"}'>
                    <img class="isdefault reward-bt" id="rewardBtNew" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newRewardBlack.png" alt="打赏">
                    <span class="count"></span>
                  </a>
                  <div class="tool-hover-tip"><span class="text space">打赏</span></div>
                </li>
          <li class="tool-item tool-item-size tool-active tool-item-comment">
            <div class="guide-rr-first">
              <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/guideRedReward01.png" alt="">
              <button class="btn-guide-known">知道了</button>
            </div>
              <a class="tool-item-href go-side-comment" data-report-click='{"spm":"1001.2101.3001.7009"}'>
              <img class="isdefault" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newComment2021Black.png" alt="">
              <span class="count">
                  3
              </span>
            </a>
            <div class="tool-hover-tip"><span class="text space">评论</span></div>
          </li>
          <li class="tool-item tool-item-bar">
          </li>
          <li class="tool-item tool-item-size tool-active tool-QRcode" data-type="article" id="tool-share">
            <a class="tool-item-href" href="javascript:;" data-report-click='{"mod":"1582594662_002","spm":"1001.2101.3001.4129","ab":"new"}'>
              <img class="isdefault" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newShareBlack.png" alt="">
            </a>
              <div class="QRcode" id="tool-QRcode">
            <div class="share-bg-icon icon1" id="shareBgIcon"></div>
              <div class="share-bg-box">
                <div class="share-content">
                    <img class="share-avatar" src="https://profile-avatar.csdnimg.cn/27160f4941a54d07b535ceabcfa4a800_java1314777.jpg!1" alt="">
                  <div class="share-tit">
                    YOLOv8改进 | 2023Neck篇 | 利用Gold-YOLO改进YOLOv8对小目标检测
                  </div>
                  <div class="share-dec">
                    本文给大家带来的改进机制是Gold-YOLO利用其Neck改进v8的Neck，GoLd-YOLO引入了一种新的机制——信息聚集-分发（Gather-and-Distribute, GD）。这个机制通过全局融合不同层次的特征并将融合后的全局信息注入到各个层级中，从而实现更高效的信息交互和融合。这种方法增强了模型的颈部（neck）信息融合能力(有点类似于长颈鹿的脖子该Neck部分很长)，同时也没有显著增加延迟，提高了模型在检测不同大小物体时的性能，同时欢迎大家订阅本专栏，本专栏每周更新3-5篇最新机制，更有包含
                  </div>
                  <a id="copyPosterUrl" class="url" data-report-click='{"spm":"1001.2101.3001.7493"}' data-report-view='{"spm":"1001.2101.3001.7493"}'>复制链接</a>
                </div>
                <div class="share-code">
                  <div class="share-code-box" id='shareCode'></div>
                  <div class="share-code-text">扫一扫</div>
                </div>
              </div>
                <div class="share-code-type">
                </div>
            </div>
          </li>
        </ul>
      </div>
      <div class="toolbox-right">
            <div class="tool-directory">
                <a class="bt-columnlist-show"
                  data-id="12483754"
                  data-free="false"
                  data-subscribe="true"
                  data-title="YOLOv8有效涨点专栏"
                  data-img="https://img-blog.csdnimg.cn/direct/d0d498bd4f0c4e17b48ff54e86b67668.png?x-oss-process=image/resize,m_fixed,h_224,w_224"
                  data-url="https://blog.csdn.net/java1314777/category_12483754.html"
                  data-sum="125"
                  data-people="340"
                  data-price="199.90"
                  data-hotRank="1"
                  data-status="true"
                  data-oldprice="99.00"
                  data-join="false"
                  data-studyvip="false"
                  data-studysubscribe="false"
                  data-report-view='{"spm":"1001.2101.3001.6334","extend1":"专栏目录"}'
                  data-report-click='{"spm":"1001.2101.3001.6334","extend1":"专栏目录"}'>专栏目录</a>
          </div>
                <div class="tool-column">
                    <a class="tool-bt-button tool-unbt-subscribe" href="javascript:;" data-report-view='{"mod":"1592215036_001","spm":"1001.2101.3001.4405","extend1":"已订阅"}' data-report-click='{"mod":"1592215036_001","spm":"1001.2101.3001.4405","extend1":"已订阅"}'>已订阅</a>
                </div>
</div>
</div>
</div>
<script type=text/javascript crossorigin src="https://csdnimg.cn/release/phoenix/production/qrcode-7c90a92189.min.js"></script>
<script src="//g.csdnimg.cn/??sharewx/1.2.1/sharewx.js" type="text/javascript"></script>
<script type="text/javascript" crossorigin src="https://g.csdnimg.cn/common/csdn-login-box/csdn-login-box.js"></script>
<script type="text/javascript" crossorigin src="https://g.csdnimg.cn/collection-box/2.1.2/collection-box.js"></script>                <div class="first-recommend-box recommend-box ">
<div class="recommend-item-box type_download clearfix" data-url="https://download.csdn.net/download/qq_45346915/88506902"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6661.1","mod":"popu_871","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant_t0.none-task-download-2~default~CTRLIST~Paid-1-88506902-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"1","strategy":"2~default~CTRLIST~Paid","dest":"https://download.csdn.net/download/qq_45346915/88506902"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://download.csdn.net/download/qq_45346915/88506902" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6661.1","mod":"popu_871","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant_t0.none-task-download-2~default~CTRLIST~Paid-1-88506902-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"1","strategy":"2~default~CTRLIST~Paid","dest":"https://download.csdn.net/download/qq_45346915/88506902"}'  data-report-query='spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-download-2%7Edefault%7ECTRLIST%7EPaid-1-88506902-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant_t0.none-task-download-2%7Edefault%7ECTRLIST%7EPaid-1-88506902-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>YOLO</em><em>v8</em><em>改进</em>，融合<em>Gold</em>-<em>YOLO</em> Neck</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info display-flex">
					<span class="info-block">11-06</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://download.csdn.net/download/qq_45346915/88506902" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6661.1","mod":"popu_871","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant_t0.none-task-download-2~default~CTRLIST~Paid-1-88506902-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"1","strategy":"2~default~CTRLIST~Paid","dest":"https://download.csdn.net/download/qq_45346915/88506902"}'  data-report-query='spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-download-2%7Edefault%7ECTRLIST%7EPaid-1-88506902-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant_t0.none-task-download-2%7Edefault%7ECTRLIST%7EPaid-1-88506902-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1"><em>YOLO</em><em>v8</em><em>改进</em>，融合<em>Gold</em>-<em>YOLO</em> Neck</div>
			</a>
		</div>
	</div>
</div>
                </div>
              <script src="https://csdnimg.cn/release/blogv2/dist/components/js/pc_wap_commontools-094b8ec121.min.js" type="text/javascript" async></script>
                <div class="second-recommend-box recommend-box ">
<div class="recommend-item-box type_blog clearfix" data-url="https://aiaiai.blog.csdn.net/article/details/133951482"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.1","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-133951482-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"1","strategy":"2~default~CTRLIST~Rate","dest":"https://aiaiai.blog.csdn.net/article/details/133951482"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://aiaiai.blog.csdn.net/article/details/133951482" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.1","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-133951482-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"1","strategy":"2~default~CTRLIST~Rate","dest":"https://aiaiai.blog.csdn.net/article/details/133951482"}'  data-report-query='spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-133951482-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-133951482-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1">基于<em>YOLO</em><em>v8</em>的人脸检测小目标识别算法：<em>Gold</em>-<em>YOLO</em>，信息聚集-分发（Gather-and-Distribute Mechanism）机制 | 华为诺亚NeurIPS23</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/CV_20231007" target="_blank"><span class="blog-title">会AI的学姐</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">10-23</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					866
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://aiaiai.blog.csdn.net/article/details/133951482" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.1","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-133951482-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"1","strategy":"2~default~CTRLIST~Rate","dest":"https://aiaiai.blog.csdn.net/article/details/133951482"}'  data-report-query='spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-133951482-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-133951482-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1"><em>Gold</em>-<em>YOLO</em>在人脸检测小目标识别算法中，mAP@0.5从原始的0.931提升至0.935，mAP50-95从原始的0.431提升至0.435</div>
			</a>
		</div>
	</div>
</div>
                </div>
<a id="commentBox" name="commentBox"></a>
  <div id="pcCommentBox" class="comment-box comment-box-new2 login-comment-box-new" style="display:none">
      <div class="has-comment" style="display:block">
        <div class="one-line-box">
          <div class="has-comment-tit go-side-comment">
            <span class="count">3</span>&nbsp;条评论
          </div>
          <div class="has-comment-con comment-operate-item"></div>
          <a class="has-comment-bt-right go-side-comment focus">写评论</a>
        </div>
      </div>
  </div>
              <div class="recommend-box insert-baidu-box recommend-box-style ">
                <div class="recommend-item-box no-index" style="display:none"></div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/qq_44878985/article/details/134718475"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.2","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~YuanLiJiHua~Position-2-134718475-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"2","strategy":"2~default~YuanLiJiHua~Position","dest":"https://blog.csdn.net/qq_44878985/article/details/134718475"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/qq_44878985/article/details/134718475" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.2","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~YuanLiJiHua~Position-2-134718475-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"2","strategy":"2~default~YuanLiJiHua~Position","dest":"https://blog.csdn.net/qq_44878985/article/details/134718475"}'  data-report-query='spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EYuanLiJiHua%7EPosition-2-134718475-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EYuanLiJiHua%7EPosition-2-134718475-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1">【<em>yolo</em><em>v8</em>】与<em>yolo</em>v5的区别及<em>改进</em>详解</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/qq_44878985" target="_blank"><span class="blog-title">qq_44878985的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">11-30</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					4251
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/qq_44878985/article/details/134718475" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.2","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~YuanLiJiHua~Position-2-134718475-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"2","strategy":"2~default~YuanLiJiHua~Position","dest":"https://blog.csdn.net/qq_44878985/article/details/134718475"}'  data-report-query='spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EYuanLiJiHua%7EPosition-2-134718475-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EYuanLiJiHua%7EPosition-2-134718475-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1"><em>yolo</em><em>v8</em>-----有点厉害的<em>目标检测</em>框架.</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/amusi1994/article/details/133191603"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.3","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-133191603-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"3","strategy":"2~default~CTRLIST~Rate","dest":"https://blog.csdn.net/amusi1994/article/details/133191603"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/amusi1994/article/details/133191603" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.3","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-133191603-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"3","strategy":"2~default~CTRLIST~Rate","dest":"https://blog.csdn.net/amusi1994/article/details/133191603"}'  data-report-query='spm=1001.2101.3001.6650.3&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-3-133191603-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-3-133191603-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1">NeurIPS 2023 | 超越<em>YOLO</em>系列！华为提出<em>Gold</em>-<em>YOLO</em>：实时<em>目标检测</em>新SOTA</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/amusi1994" target="_blank"><span class="blog-title">阿木寺的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">09-22</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					2785
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/amusi1994/article/details/133191603" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.3","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-133191603-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"3","strategy":"2~default~CTRLIST~Rate","dest":"https://blog.csdn.net/amusi1994/article/details/133191603"}'  data-report-query='spm=1001.2101.3001.6650.3&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-3-133191603-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-3-133191603-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">点击下方卡片，关注&ldquo;CVer&rdquo;公众号AI/CV重磅干货，第一时间送达点击进入&mdash;&gt;【<em>目标检测</em>和Transformer】交流群作者：王云鹤（源：知乎，已授权）| 编辑：CVer公众号https://zhuanlan.zhihu.com/p/657742732在CVer微信公众号后台回复：<em>Gold</em>，可以下载本论文pdf、代码<em>Gold</em>-<em>YOLO</em>: Efficient Object Detector ...</div>
			</a>
		</div>
	</div>
</div>
		<dl id="recommend-item-box-tow" class="recommend-item-box type_blog clearfix">
			
		</dl>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/weixin_51692073/article/details/133780102"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.4","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-4-133780102-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"4","strategy":"2~default~CTRLIST~Rate","dest":"https://blog.csdn.net/weixin_51692073/article/details/133780102"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/weixin_51692073/article/details/133780102" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.4","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-4-133780102-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"4","strategy":"2~default~CTRLIST~Rate","dest":"https://blog.csdn.net/weixin_51692073/article/details/133780102"}'  data-report-query='spm=1001.2101.3001.6650.4&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-133780102-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-133780102-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>YOLO</em><em>v8</em>最新<em>改进</em>系列：<em>YOLO</em><em>v8</em>华为提出<em>Gold</em>-<em>YOLO</em>，高效实时<em>目标检测</em>器，精度再提升，多目标、小目标无处遁形！</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/weixin_51692073" target="_blank"><span class="blog-title">weixin_51692073的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">10-12</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					6289
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/weixin_51692073/article/details/133780102" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.4","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-4-133780102-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"4","strategy":"2~default~CTRLIST~Rate","dest":"https://blog.csdn.net/weixin_51692073/article/details/133780102"}'  data-report-query='spm=1001.2101.3001.6650.4&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-133780102-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-133780102-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1"><em>YOLO</em><em>v8</em>华为提出<em>Gold</em>-<em>YOLO</em>，高效实时<em>目标检测</em>器，精度再提升，多目标、小目标无处遁形！</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/qq_45346915/article/details/134239123"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.5","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-5-134239123-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"5","strategy":"2~default~CTRLIST~Rate","dest":"https://blog.csdn.net/qq_45346915/article/details/134239123"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/qq_45346915/article/details/134239123" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.5","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-5-134239123-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"5","strategy":"2~default~CTRLIST~Rate","dest":"https://blog.csdn.net/qq_45346915/article/details/134239123"}'  data-report-query='spm=1001.2101.3001.6650.5&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-5-134239123-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-5-134239123-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>YOLO</em><em>v8</em><em>改进</em>：融合<em>Gold</em>-<em>YOLO</em> Neck(RepGDNeck)</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/qq_45346915" target="_blank"><span class="blog-title">羲洋的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">11-06</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					1003
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/qq_45346915/article/details/134239123" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.5","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-5-134239123-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"5","strategy":"2~default~CTRLIST~Rate","dest":"https://blog.csdn.net/qq_45346915/article/details/134239123"}'  data-report-query='spm=1001.2101.3001.6650.5&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-5-134239123-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-5-134239123-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1"><em>YOLO</em><em>v8</em><em>改进</em>：融合<em>Gold</em>-<em>YOLO</em> Neck(RepGDNeck)</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/yohnyang/article/details/128772295"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.6","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-6-128772295-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"6","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/yohnyang/article/details/128772295"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/yohnyang/article/details/128772295" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.6","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-6-128772295-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"6","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/yohnyang/article/details/128772295"}'  data-report-query='spm=1001.2101.3001.6650.6&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-6-128772295-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-6-128772295-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1">（17）<em>目标检测</em>算法之 <em>YOLO</em><em>v8</em> 算法<em>改进</em>详细解析</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/yohnyang" target="_blank"><span class="blog-title">yohnyang的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">01-27</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					9575
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/yohnyang/article/details/128772295" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.6","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-6-128772295-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"6","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/yohnyang/article/details/128772295"}'  data-report-query='spm=1001.2101.3001.6650.6&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-6-128772295-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-6-128772295-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1"><em>目标检测</em>算法之 <em>YOLO</em><em>v8</em> 算法<em>改进</em>详细解析</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://cv2023.blog.csdn.net/article/details/131558274"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.7","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-7-131558274-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"7","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://cv2023.blog.csdn.net/article/details/131558274"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://cv2023.blog.csdn.net/article/details/131558274" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.7","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-7-131558274-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"7","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://cv2023.blog.csdn.net/article/details/131558274"}'  data-report-query='spm=1001.2101.3001.6650.7&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-7-131558274-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-7-131558274-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>Yolo</em><em>V8</em><em>改进</em>---注意力机制:高斯上下文变换器GCT，性能优于ECA、SE等注意力模块 | CVPR2021</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/m0_63774211" target="_blank"><span class="blog-title">各专栏持续更新中，改进创新YOLO，适用v5、v7、v8，所有博客均是原创博客，所有文章禁止转载，违者必究。 By AI小怪兽 AI&amp;CV</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">07-05</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					1876
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://cv2023.blog.csdn.net/article/details/131558274" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.7","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-7-131558274-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"7","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://cv2023.blog.csdn.net/article/details/131558274"}'  data-report-query='spm=1001.2101.3001.6650.7&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-7-131558274-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-7-131558274-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">提出了一种新的通道注意力结构gct，在几乎不引入参数的前提下优于大多SOTA通道注意力模型，如SE、ECA等</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://devpress.csdn.net/v1/article/detail/133163439"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.8","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~activity-8-133163439-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"8","strategy":"2~default~BlogCommendFromBaidu~activity","dest":"https://devpress.csdn.net/v1/article/detail/133163439"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://devpress.csdn.net/v1/article/detail/133163439" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.8","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~activity-8-133163439-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"8","strategy":"2~default~BlogCommendFromBaidu~activity","dest":"https://devpress.csdn.net/v1/article/detail/133163439"}'  data-report-query='spm=1001.2101.3001.6650.8&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Eactivity-8-133163439-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Eactivity-8-133163439-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>深度学习</em>论文: <em>Gold</em>-<em>YOLO</em>: Efficient Object Detector via Gather-and-Distribute Mechanism及其<em>PyTorch</em>实现</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/shanglianlm" target="_blank"><span class="blog-title">mingo_敏</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">09-22</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					2058
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://devpress.csdn.net/v1/article/detail/133163439" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.8","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~activity-8-133163439-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"8","strategy":"2~default~BlogCommendFromBaidu~activity","dest":"https://devpress.csdn.net/v1/article/detail/133163439"}'  data-report-query='spm=1001.2101.3001.6650.8&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Eactivity-8-133163439-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Eactivity-8-133163439-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">在过去的几年中，<em>YOLO</em>系列模型已经成为实时<em>目标检测</em>领域的领先方法。许多研究通过修改架构、增加数据和设计新的损失函数，将基线推向了更高的水平。然而以前的模型仍然存在信息融合问题，尽管特征金字塔网络（FPN）和路径聚合网络（PANet）已经在一定程度上缓解了这个问题。因此，本研究提出了一种先进的聚集和分发机制（GD机制），该机制通过卷积和自注意力操作实现。这种新设计的模型被称为<em>Gold</em>-<em>YOLO</em>，它提升了多尺度特征融合能力，在所有模型尺度上实现了延迟和准确性的理想平衡。</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/qq_42722197/article/details/132680505"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.9","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-9-132680505-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"9","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/qq_42722197/article/details/132680505"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/qq_42722197/article/details/132680505" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.9","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-9-132680505-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"9","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/qq_42722197/article/details/132680505"}'  data-report-query='spm=1001.2101.3001.6650.9&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-9-132680505-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-9-132680505-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1">速递 | <em>YOLO</em><em>v8</em>模型<em>改进</em>的N种方法</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/qq_42722197" target="_blank"><span class="blog-title">小白学视觉</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">09-04</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					3242
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/qq_42722197/article/details/132680505" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.9","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-9-132680505-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"9","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://blog.csdn.net/qq_42722197/article/details/132680505"}'  data-report-query='spm=1001.2101.3001.6650.9&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-9-132680505-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-9-132680505-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">点击上方&ldquo;小白学视觉&rdquo;，选择加&quot;星标&quot;或&ldquo;置顶&rdquo;重磅干货，第一时间送达微信公众号：OpenCV学堂关注获取更多<em>计算机视觉</em>与<em>深度学习</em>知识<em>YOLO</em><em>v8</em>源码到底在哪?很多人也想跟修改<em>YOLO</em>v5源码一样的方式去修改<em>YOLO</em><em>v8</em>的源码，但是在github上面却发现找到的<em>YOLO</em><em>v8</em>项目下面TAG分支是空的，然后就直接从master/main下面把源码克隆出来一通修改了，其实这种方式风险很高，而且也不是正确...</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_course clearfix" data-url="https://edu.csdn.net/course/detail/38688"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.10","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-course-2~default~BlogCommendFromBaidu~Rate-10-38688-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"10","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://edu.csdn.net/course/detail/38688"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://edu.csdn.net/course/detail/38688" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.10","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-course-2~default~BlogCommendFromBaidu~Rate-10-38688-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"10","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://edu.csdn.net/course/detail/38688"}'  data-report-query='spm=1001.2101.3001.6650.10&utm_medium=distribute.pc_relevant.none-task-course-2%7Edefault%7EBlogCommendFromBaidu%7ERate-10-38688-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-course-2%7Edefault%7EBlogCommendFromBaidu%7ERate-10-38688-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>YOLO</em><em>v8</em>实战VisDrone无人机<em>目标检测</em> </div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info display-flex">
					<span class="info-block">06-16</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://edu.csdn.net/course/detail/38688" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.10","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-course-2~default~BlogCommendFromBaidu~Rate-10-38688-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"10","strategy":"2~default~BlogCommendFromBaidu~Rate","dest":"https://edu.csdn.net/course/detail/38688"}'  data-report-query='spm=1001.2101.3001.6650.10&utm_medium=distribute.pc_relevant.none-task-course-2%7Edefault%7EBlogCommendFromBaidu%7ERate-10-38688-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-course-2%7Edefault%7EBlogCommendFromBaidu%7ERate-10-38688-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1"><em>YOLO</em><em>v8</em> 基于先前 <em>YOLO</em> 版本的成功，进一步提升性能和灵活性。VisDrone2019数据集是在不同的无人机平台、不同的场景以及不同的天气和光照条件下收集。数据集包含了多种类型的目标，包括行人、车辆、自行车、摩托车等。由于无人机的高空视角、目标的小尺寸、复杂的背景等因素，VisDrone<em>目标检测</em>任务具有很高的挑战性。本课程将手把手地教大家使用<em>YOLO</em><em>v8</em>训练VisDrone无人机<em>目标检测</em>数据集，完成VisDrone<em>目标检测</em>竞赛实战项目，并尝试涨点技巧。本课程分别在Windows和Ubuntu系统上做项目演示。包括：安装软件环境（Nvidia显卡驱动、cuda和cudnn）、安装<em>PyTorch</em>、安装<em>YOLO</em><em>v8</em>、 下载VisDrone数据集和格式转换（VisDrone-&gt;<em>YOLO</em>，提供格式转换<em>python</em>脚本）、修改配置文件、<em>YOLO</em><em>v8</em>s训练数据集（合适的命令参数选择）、测试训练出的网络模型和性能统计、<em>YOLO</em><em>v8</em>s+增大网络分辨率、<em>YOLO</em><em>v8</em>s+数据增强改变、<em>YOLO</em><em>v8</em>x训练数据集、超参conf和iou阈值改变、其它<em>改进</em>建议、检测结果格式转换及提交(<em>YOLO</em>-&gt;VisDrone，，提供格式转换<em>python</em>脚本)。&nbsp;</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_download clearfix" data-url="https://download.csdn.net/download/weixin_43999691/88419023"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.11","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~Rate-11-88419023-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"11","strategy":"2~default~CTRLIST~Rate","dest":"https://download.csdn.net/download/weixin_43999691/88419023"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://download.csdn.net/download/weixin_43999691/88419023" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.11","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~Rate-11-88419023-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"11","strategy":"2~default~CTRLIST~Rate","dest":"https://download.csdn.net/download/weixin_43999691/88419023"}'  data-report-query='spm=1001.2101.3001.6650.11&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7ERate-11-88419023-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7ERate-11-88419023-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>YOLO</em><em>V8</em>模型转换-ONNX-RKNN</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info display-flex">
					<span class="info-block">10-12</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://download.csdn.net/download/weixin_43999691/88419023" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.11","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~Rate-11-88419023-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"11","strategy":"2~default~CTRLIST~Rate","dest":"https://download.csdn.net/download/weixin_43999691/88419023"}'  data-report-query='spm=1001.2101.3001.6650.11&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7ERate-11-88419023-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7ERate-11-88419023-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">文件中包含内容：
使用平台为RK3588
(1)step1:pt模型转onnx
(2)step2: onnx调用做推理
(3)step3: onnx转rknn模型
(4)step4:rknn模型调用
</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_download clearfix" data-url="https://download.csdn.net/download/qq_52060635/88489264"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.12","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~default-12-88489264-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"12","strategy":"2~default~CTRLIST~default","dest":"https://download.csdn.net/download/qq_52060635/88489264"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://download.csdn.net/download/qq_52060635/88489264" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.12","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~default-12-88489264-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"12","strategy":"2~default~CTRLIST~default","dest":"https://download.csdn.net/download/qq_52060635/88489264"}'  data-report-query='spm=1001.2101.3001.6650.12&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7Edefault-12-88489264-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7Edefault-12-88489264-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1">基于<em>Yolo</em>V5的<em>目标检测</em>，可用于毕业设计</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info display-flex">
					<span class="info-block">10-31</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://download.csdn.net/download/qq_52060635/88489264" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.12","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~default-12-88489264-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"12","strategy":"2~default~CTRLIST~default","dest":"https://download.csdn.net/download/qq_52060635/88489264"}'  data-report-query='spm=1001.2101.3001.6650.12&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7Edefault-12-88489264-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7Edefault-12-88489264-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">由于上传限制，需要数据集的可以联系，或自己找，可做医学图像疾病的检测或者图片物品的检测，也可做视频中人物识别，先使用train.py训练自己的网络，再使用detect.py输出检测结果，检测结果输出文件夹runs包含各项指标，可以和其他<em>yolo</em>系列作比较，可以作为毕设的基线，如果有用，欢迎━(*｀&forall;&acute;*)ノ亻!收藏关注，任何问题可以向我提问。可以使用自己的数据集，默认在cpu上跑，要是使用GPU将.cpu换为cuda即可。
相关知识点可看https://zhuanlan.zhihu.com/p/172121380
<em>Yolo</em>v5的网络结构图，可以看出，还是分为输入端、Backbone、Neck、Prediction四个部分。
详情见我的博文：https://blog.csdn.net/qq_52060635/article/details/134149072?spm=1001.2014.3001.5502</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_download clearfix" data-url="https://download.csdn.net/download/zy_dreamer/87777943"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.13","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~default-13-87777943-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"13","strategy":"2~default~CTRLIST~default","dest":"https://download.csdn.net/download/zy_dreamer/87777943"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://download.csdn.net/download/zy_dreamer/87777943" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.13","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~default-13-87777943-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"13","strategy":"2~default~CTRLIST~default","dest":"https://download.csdn.net/download/zy_dreamer/87777943"}'  data-report-query='spm=1001.2101.3001.6650.13&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7Edefault-13-87777943-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7Edefault-13-87777943-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>改进</em><em>YOLO</em>v5s的道路<em>目标检测</em>算法</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info display-flex">
					<span class="info-block">05-12</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://download.csdn.net/download/zy_dreamer/87777943" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.13","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~CTRLIST~default-13-87777943-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"13","strategy":"2~default~CTRLIST~default","dest":"https://download.csdn.net/download/zy_dreamer/87777943"}'  data-report-query='spm=1001.2101.3001.6650.13&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7Edefault-13-87777943-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7ECTRLIST%7Edefault-13-87777943-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1"><em>YOLO</em>v5s网络结构主要分为输入端、Backbone、Neck和输出端4个部分, 如图1所示．在输入端对图像进行预处理, 完成Mosaic数据增强、自动计算锚框和自适应图像缩放．将图像输入Backbone部分进行Focus操作, 即对图像进行切片操作, 每隔一个像素取一个值,将原始图像划分为4份数据, 该方式可以减少下采样导致的信息损失．跨阶段局部(cross-stage partial, CSP)模块在主干网络中主要是用作局部跨通道融合, <em>利用</em>每层的特征信息获取更加丰富的特征图像．在Neck部分通过上采样层和CSP模块将高层的语义信息与底层的位置信息相融合,进而得到预测的特征图像并将其输入输出端．输出端拥有3种不同尺寸的特征图像,根据各特征生成预测框进行非极大值抑制,保留局部类别置信度较高的预测框</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_download clearfix" data-url="https://download.csdn.net/download/iolahkuy/87855830"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.14","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~OPENSEARCH~Rate-14-87855830-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"14","strategy":"2~default~OPENSEARCH~Rate","dest":"https://download.csdn.net/download/iolahkuy/87855830"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://download.csdn.net/download/iolahkuy/87855830" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.14","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~OPENSEARCH~Rate-14-87855830-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"14","strategy":"2~default~OPENSEARCH~Rate","dest":"https://download.csdn.net/download/iolahkuy/87855830"}'  data-report-query='spm=1001.2101.3001.6650.14&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7EOPENSEARCH%7ERate-14-87855830-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7EOPENSEARCH%7ERate-14-87855830-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>YOLO</em><em>v8</em>自定义对象检测、实例分割、目标跟踪从训练到部署（2023新课）</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info display-flex">
					<span class="info-block">06-02</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://download.csdn.net/download/iolahkuy/87855830" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.14","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~OPENSEARCH~Rate-14-87855830-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"14","strategy":"2~default~OPENSEARCH~Rate","dest":"https://download.csdn.net/download/iolahkuy/87855830"}'  data-report-query='spm=1001.2101.3001.6650.14&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7EOPENSEARCH%7ERate-14-87855830-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7EOPENSEARCH%7ERate-14-87855830-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">分享课程&mdash;&mdash;<em>YOLO</em><em>v8</em>自定义对象检测、实例分割、目标跟踪从训练到部署，2023新课，提供源码+课件+数据。  详解<em>YOLO</em><em>v8</em>模型结构从backbone、neck、header、loss层面详解<em>YOLO</em><em>v8</em>相比<em>YOLO</em>X、<em>YOLO</em>v5、<em>YOLO</em>v6的全面<em>改进</em>与...</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_download clearfix" data-url="https://download.csdn.net/download/Rocky006/87842321"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.15","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~OPENSEARCH~Rate-15-87842321-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"15","strategy":"2~default~OPENSEARCH~Rate","dest":"https://download.csdn.net/download/Rocky006/87842321"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://download.csdn.net/download/Rocky006/87842321" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.15","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~OPENSEARCH~Rate-15-87842321-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"15","strategy":"2~default~OPENSEARCH~Rate","dest":"https://download.csdn.net/download/Rocky006/87842321"}'  data-report-query='spm=1001.2101.3001.6650.15&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7EOPENSEARCH%7ERate-15-87842321-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7EOPENSEARCH%7ERate-15-87842321-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>yolo</em>v5+<em>改进</em>策略+案例分析+资源合集</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info display-flex">
					<span class="info-block">05-30</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://download.csdn.net/download/Rocky006/87842321" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.15","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-download-2~default~OPENSEARCH~Rate-15-87842321-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"15","strategy":"2~default~OPENSEARCH~Rate","dest":"https://download.csdn.net/download/Rocky006/87842321"}'  data-report-query='spm=1001.2101.3001.6650.15&utm_medium=distribute.pc_relevant.none-task-download-2%7Edefault%7EOPENSEARCH%7ERate-15-87842321-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-download-2%7Edefault%7EOPENSEARCH%7ERate-15-87842321-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1"> <em>YOLO</em>v5是一种单阶段<em>目标检测</em>算法，该算法在<em>YOLO</em>v4的基础上添加了一些新的<em>改进</em>思路，使其速度与精度都得到了极大的性能提升。主要的<em>改进</em>思路如下所示： 输入端：在模型训练阶段，提出了一些<em>改进</em>思路，主要包括Mosaic...</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://northd.blog.csdn.net/article/details/136208805"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.16","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-16-136208805-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"16","strategy":"2~default~BLOGTAG~default","dest":"https://northd.blog.csdn.net/article/details/136208805"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://northd.blog.csdn.net/article/details/136208805" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.16","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-16-136208805-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"16","strategy":"2~default~BLOGTAG~default","dest":"https://northd.blog.csdn.net/article/details/136208805"}'  data-report-query='spm=1001.2101.3001.6650.16&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-16-136208805-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-16-136208805-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1">本机windows搭建达摩院与高德联合出品的地理地址自然语言处理模型MGeo实战</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/qq_39813001" target="_blank"><span class="blog-title">North_D的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">02-21</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					1411
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://northd.blog.csdn.net/article/details/136208805" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.16","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-16-136208805-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"16","strategy":"2~default~BLOGTAG~default","dest":"https://northd.blog.csdn.net/article/details/136208805"}'  data-report-query='spm=1001.2101.3001.6650.16&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-16-136208805-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-16-136208805-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">MGeo提炼了常用的地址处理任务并建立了地理语义理解能力评测基准GeoGLUE，使用MGeo底座在GeoGLUE中提供的任务数据集上进行了训练。地址信息处理是对地址相关文本的自动化挖掘、理解与关联。这项技术广泛地应用在社会生活的各个场景之中。例如我们常用的地图软件中就用到了大量的地址信息处理技术来构建POI库，实现POI搜索与推荐；在外卖物流行业中，对于地址的解析、定位准确率的提升则直接带来运力成本的大量降低；</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/abc991835105/article/details/136224057"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.17","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-17-136224057-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"17","strategy":"2~default~BLOGTAG~default","dest":"https://blog.csdn.net/abc991835105/article/details/136224057"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/abc991835105/article/details/136224057" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.17","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-17-136224057-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"17","strategy":"2~default~BLOGTAG~default","dest":"https://blog.csdn.net/abc991835105/article/details/136224057"}'  data-report-query='spm=1001.2101.3001.6650.17&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-17-136224057-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-17-136224057-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1">麻雀算法优化BP神经网络回归分析，麻雀算法优化BP神经网络回归预测，麻雀优化算法<em>改进</em>BP神经网络客流量预测</div>
					<div class="tag">最新发布</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/abc991835105" target="_blank"><span class="blog-title">abc991835105的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">02-22</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					347
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/abc991835105/article/details/136224057" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.17","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-17-136224057-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"17","strategy":"2~default~BLOGTAG~default","dest":"https://blog.csdn.net/abc991835105/article/details/136224057"}'  data-report-query='spm=1001.2101.3001.6650.17&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-17-136224057-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-17-136224057-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">麻雀优化算法，bp神经网络，回归分析
客流量预测</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/richerg85/article/details/136204206"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.18","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-18-136204206-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"18","strategy":"2~default~BLOGTAG~default","dest":"https://blog.csdn.net/richerg85/article/details/136204206"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/richerg85/article/details/136204206" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.18","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-18-136204206-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"18","strategy":"2~default~BLOGTAG~default","dest":"https://blog.csdn.net/richerg85/article/details/136204206"}'  data-report-query='spm=1001.2101.3001.6650.18&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-18-136204206-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-18-136204206-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1">英伟达推出免训练，可生成连贯图片的文生图模型</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/richerg85" target="_blank"><span class="blog-title">richerg85的专栏</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">02-21</span>
					<span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					676
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/richerg85/article/details/136204206" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.18","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-blog-2~default~BLOGTAG~default-18-136204206-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"18","strategy":"2~default~BLOGTAG~default","dest":"https://blog.csdn.net/richerg85/article/details/136204206"}'  data-report-query='spm=1001.2101.3001.6650.18&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-18-136204206-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBLOGTAG%7Edefault-18-136204206-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1">在图像生成过程中，模型会<em>利用</em>预训练模型的内部特征表示来对生成的图像进行对齐，而无需进一步对齐外部来源的图像。SDSA是ConsiStory的核心模块之一，可以在生成的图像批次中共享主体相关的视觉信息,使不同图像中的主体保持一致的外观。ConsiStory中的锚图像提供了主题信息的参考功能，主要用于引导图像生成过程，确保生成的图像在主题上保持一致。1）无法识别和定位图像中的共同主体，文生图像模型没有内置的对象检测或分割模块,很难自动识别不同图像中的相同主体；，避免了传统方法中需要针对每个主题进行训练的难题。</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_chatgpt clearfix" data-url="https://wenku.csdn.net/answer/36013oqwes"  data-report-view='{"ab":"new","spm":"1001.2101.3001.6650.19","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-chatgpt-2~default~CTRLIST~Position-19-36013oqwes-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"19","strategy":"2~default~CTRLIST~Position","dest":"https://wenku.csdn.net/answer/36013oqwes"}'>
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://wenku.csdn.net/answer/36013oqwes" class="tit" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.19","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-chatgpt-2~default~CTRLIST~Position-19-36013oqwes-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"19","strategy":"2~default~CTRLIST~Position","dest":"https://wenku.csdn.net/answer/36013oqwes"}'  data-report-query='spm=1001.2101.3001.6650.19&utm_medium=distribute.pc_relevant.none-task-chatgpt-2%7Edefault%7ECTRLIST%7EPosition-19-36013oqwes-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-chatgpt-2%7Edefault%7ECTRLIST%7EPosition-19-36013oqwes-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
					<div class="left ellipsis-online ellipsis-online-1"><em>yolo</em><em>v8</em><em>改进</em>slim-neck</div>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info display-flex">
					<span class="info-block">10-19</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://wenku.csdn.net/answer/36013oqwes" target="_blank"  data-report-click='{"ab":"new","spm":"1001.2101.3001.6650.19","mod":"popu_387","extra":"{\"highlightScore\":0.0,\"utm_medium\":\"distribute.pc_relevant.none-task-chatgpt-2~default~CTRLIST~Position-19-36013oqwes-blog-135024120.235^v43^pc_blog_bottom_relevance_base5\",\"dist_request_id\":\"1709120647945_16439\"}","dist_request_id":"1709120647945_16439","ab_strategy":"increase_t0_anti_vip","index":"19","strategy":"2~default~CTRLIST~Position","dest":"https://wenku.csdn.net/answer/36013oqwes"}'  data-report-query='spm=1001.2101.3001.6650.19&utm_medium=distribute.pc_relevant.none-task-chatgpt-2%7Edefault%7ECTRLIST%7EPosition-19-36013oqwes-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5&depth_1-utm_source=distribute.pc_relevant.none-task-chatgpt-2%7Edefault%7ECTRLIST%7EPosition-19-36013oqwes-blog-135024120.235%5Ev43%5Epc_blog_bottom_relevance_base5'>
				<div class="desc ellipsis-online ellipsis-online-1"><em>Yolo</em><em>v8</em>是<em>Yolo</em>系列的一个<em>改进</em>版本，其中包括了一些新的特性和<em>改进</em>。其中一个<em>改进</em>是引入了Slim-neck结构，这是一种新的检测器架构设计范式，旨在提高自动驾驶场景下的检测性能。Slim-neck结构通过引入GSConv（Grouped Spatial Convolution）模块来替代传统的卷积层，从而减少了网络的参数数量和计算量，同时提高了检测性能。如果你想了解更多关于<em>Yolo</em><em>v8</em>和Slim-neck的信息，可以参考引用中提供的专栏文章和Github项目。</div>
			</a>
		</div>
	</div>
</div>
              </div>
<div id="recommendNps" class="recommend-nps-box common-nps-box">
  <h3 class="aside-title">“相关推荐”对你有帮助么？</h3>
  <div class="aside-content">
      <ul class="newnps-list">
          <li class="newnps-item" data-type="非常没帮助">
              <div class="newnps-img-box">
                  <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel1.png" alt="">
                  <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey1.png" alt="">
              </div>
              <div class="newnps-text">非常没帮助</div>
          </li>
          <li class="newnps-item" data-type="没帮助">
              <div class="newnps-img-box">
                  <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel2.png" alt="">
                  <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey2.png" alt="">
              </div>
              <div class="newnps-text">没帮助</div>
          </li>
          <li class="newnps-item" data-type="一般">
              <div class="newnps-img-box">
                  <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel3.png" alt="">
                  <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey3.png" alt="">
              </div>
              <div class="newnps-text">一般</div>
          </li>
          <li class="newnps-item" data-type="有帮助">
              <div class="newnps-img-box">
                  <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel4.png" alt="">
                  <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey4.png" alt="">
              </div>
              <div class="newnps-text">有帮助</div>
          </li>
          <li class="newnps-item" data-type="非常有帮助">
              <div class="newnps-img-box">
                  <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel5.png" alt="">
                  <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey5.png" alt="">
              </div>
              <div class="newnps-text">非常有帮助</div>
          </li>
      </ul>
      <div class="newnps-form-box">
      <div class="newnps-form">
          <input type="text" placeholder="请输入建议或反馈后点击提交" class="newnps-input">
          <span class="newnps-btn">提交</span>
      </div>
      </div>
  </div>
</div><div class="blog-footer-bottom" style="margin-top:10px;"></div>
<script src="https://g.csdnimg.cn/common/csdn-footer/csdn-footer.js" data-isfootertrack="false" type="text/javascript"></script>
<script type="text/javascript">
    window.csdn.csdnFooter.options = {
        el: '.blog-footer-bottom',
        type: 2
    }
</script>          </main>
<aside class="blog_container_aside">
<div id="asideProfile" class="aside-box">
    <div class="profile-intro d-flex">
        <div class="avatar-box d-flex justify-content-center flex-column">
            <a href="https://snu77.blog.csdn.net" target="_blank" data-report-click='{"mod":"popu_379","spm":"1001.2101.3001.4121","dest":"https://snu77.blog.csdn.net","ab":"new"}'>
                <img src="https://profile-avatar.csdnimg.cn/27160f4941a54d07b535ceabcfa4a800_java1314777.jpg!1" class="avatar_pic">
            </a>
        </div>
        <div class="user-info d-flex flex-column profile-intro-name-box">
            <div class="profile-intro-name-boxTop">
                <a href="https://snu77.blog.csdn.net" target="_blank" class="" id="uid" title="Snu77" data-report-click='{"mod":"popu_379","spm":"1001.2101.3001.4122","dest":"https://snu77.blog.csdn.net","ab":"new"}'>
                    <span class="name vip-name" username="java1314777">Snu77</span>
                </a>
                <span>
                <a href="https://snu77.blog.csdn.net"  data-report-click='{"spm":"1001.2101.3001.9180"}' target="_blank"><img class="identity" src="https://csdnimg.cn/release/blogv2/dist/mobile/img/vipNew.png" alt=""></a>
                </span>
                <span class="flag expert-blog">
                <span class="bubble">CSDN认证博客专家</span>
                </span>
                <span class="flag company-blog">
                <span class="bubble">CSDN认证企业博客</span>
                </span>
            </div>
            <div class="profile-intro-name-boxFooter">
                <span class="personal-home-page personal-home-years" title="已加入 CSDN 2年">码龄2年</span>
                    <span class="personal-home-page">
                    <a class="personal-home-certification" href="https://i.csdn.net/#/uc/profile?utm_source=14998968" target="_blank" title="人工智能领域优质创作者">
                    <img src="https://img-home.csdnimg.cn/images/20210412060958.png" alt="">
                    人工智能领域优质创作者
                    </a>
                    </span>
            </div>
        </div>
    </div>
    <div class="data-info d-flex item-tiling">
        <dl class="text-center" title="337">
            <a href="https://snu77.blog.csdn.net" data-report-click='{"mod":"1598321000_001","spm":"1001.2101.3001.4310"}' data-report-query="t=1">  
                <dt><span class="count">337</span></dt>
                <dd class="font">原创</dd>
            </a>
        </dl>
        <dl class="text-center" data-report-click='{"mod":"1598321000_002","spm":"1001.2101.3001.4311"}' title="7">
            <a href="https://blog.csdn.net/rank/list/weekly" target="_blank">
                <dt><span class="count">7</span></dt>
                <dd class="font">周排名</dd>
            </a>
        </dl>
        <dl class="text-center" title="1140">
            <a href="https://blog.csdn.net/rank/list/total" data-report-click='{"mod":"1598321000_003","spm":"1001.2101.3001.4312"}' target="_blank">
                <dt><span class="count">1140</span></dt>
                <dd class="font">总排名</dd>
            </a>
        </dl>
        <dl class="text-center" style="min-width:58px" title="592786">  
            <dt><span class="count">59万+</span></dt>
            <dd>访问</dd>
        </dl>
        <dl class="text-center" title="7级,点击查看等级说明">
            <dt><a href="https://blog.csdn.net/blogdevteam/article/details/103478461" target="_blank">
                <img class="level" src="https://csdnimg.cn/identity/blog7.png">
            </a>
            </dt>
            <dd>等级</dd>
        </dl>
    </div>
    <div class="item-rank"></div>
    <div class="data-info d-flex item-tiling">
        <dl class="text-center" title="13269">
            <dt><span class="count">1万+</span></dt>
            <dd>积分</dd>
        </dl>
         <dl class="text-center" id="fanBox" title="25752">
            <dt><span class="count" id="fan">2万+</span></dt>
            <dd>粉丝</dd>
        </dl>
        <dl class="text-center" title="7608">
            <dt><span class="count">7608</span></dt>
            <dd>获赞</dd>
        </dl>
        <dl class="text-center" title="3467">
            <dt><span class="count">3467</span></dt>
            <dd>评论</dd>
        </dl>
        <dl class="text-center" title="9402">
            <dt><span class="count">9402</span></dt>
            <dd>收藏</dd>
        </dl>
    </div>
    <div class="aside-box-footer" data-report-view='{"spm":"3001.4296"}'>
        <div class="badge-box d-flex">
            <div class="badge d-flex">
                <div class="icon-badge" title="MarkDown">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/11887cd76794439ba69942cd77e81457.png" alt="MarkDown">
                    </div>
                </div>
                <div class="icon-badge" title="CUDA入门">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/cd999bc9a00b4283abaff17a468ff189.png" alt="CUDA入门">
                    </div>
                </div>
                <div class="icon-badge" title="云原生入门">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/3d0f343b511d482892084e4bec9ef37b.png" alt="云原生入门">
                    </div>
                </div>
                <div class="icon-badge" title="学无止境">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/0af32a292d094a4cbfd0feff60f3590d.png" alt="学无止境">
                    </div>
                </div>
                <div class="icon-badge" title="习惯养成">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/xiguanyangchengLv1.png" alt="习惯养成">
                    </div>
                </div>
                <div class="icon-badge" title="笔记达人">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/bijidarenLv1.png" alt="笔记达人">
                    </div>
                </div>
                <div class="icon-badge" title="Java工程师·初级">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/s_java_b_lv1@240.png" alt="Java工程师·初级">
                    </div>
                </div>
                <div class="icon-badge" title="Java工程师·高级">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/s_java_a_lv1@240.png" alt="Java工程师·高级">
                    </div>
                </div>
                <div class="icon-badge" title="博客之星–参与">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/76b1d0d897bc4bdabc11a5d89fe552d3.png" alt="博客之星–参与">
                    </div>
                </div>
                <div class="icon-badge" title="Python工程师·初级">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/s_python_b_lv1@240.png" alt="Python工程师·初级">
                    </div>
                </div>
                <div class="icon-badge" title="Vue进阶">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/c1369b46fc9140c3808c8189382cf046.png" alt="Vue进阶">
                    </div>
                </div>
                <div class="icon-badge" title="Python工程师·高级">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/s_python_a_lv1@240.png" alt="Python工程师·高级">
                    </div>
                </div>
                <div class="icon-badge" title="勤写标兵">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/eabb492c5e3343738376cdb052649492.png" alt="勤写标兵">
                    </div>
                </div>
                <div class="icon-badge" title="创作能手">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/qixiebiaobing4@240.png" alt="创作能手">
                    </div>
                </div>
                <div class="icon-badge" title="新秀勋章">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/xinxiu@240.png" alt="新秀勋章">
                    </div>
                </div>
                <div class="icon-badge" title="持之以恒">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/a73a5facfe464b5a9e2b0393b1189042.png" alt="持之以恒">
                    </div>
                </div>
                <div class="icon-badge" title="创作纪念日">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/cz1th.png" alt="创作纪念日">
                    </div>
                </div>
                <div class="icon-badge" title="GitHub">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/medal/github@240.png" alt="GitHub">
                    </div>
                </div>
                <div class="icon-badge" title="笔耕不辍">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/02d34b42a3ee476fb50850304ab67017.png" alt="笔耕不辍">
                    </div>
                </div>
                <div class="icon-badge" title="话题达人">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/dff63da017d0435d83f26031510a70f0.png" alt="话题达人">
                    </div>
                </div>
                <div class="icon-badge" title="知无不言">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/f19b84c244aa4e6d8bf469b4aff1f98c.png" alt="知无不言">
                    </div>
                </div>
                <div class="icon-badge" title="授人以渔">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/53a3e1cbc8b643cd88e0be2ea68200f7.png" alt="授人以渔">
                    </div>
                </div>
                <div class="icon-badge" title="求知">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/c0535f9cefbd4cc0a4878be28bfc4590.png" alt="求知">
                    </div>
                </div>
                <div class="icon-badge" title="受益良多">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/f36bcf8b59434f7e8e4fe5cab12ed731.png" alt="受益良多">
                    </div>
                </div>
                <div class="icon-badge" title="MySQL进阶">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/2b34833c180244d581b07e8aaa9ae3d9.png" alt="MySQL进阶">
                    </div>
                </div>
                <div class="icon-badge" title="Go">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click='{"spm":"3001.4296"}' src="https://csdnimg.cn/23159beb43324e31b1a0ffa3bd651a22.png" alt="Go">
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="profile-intro-name-boxOpration">
        <div class="opt-letter-watch-box">
        <a rel="nofollow" class="bt-button personal-letter" href="https://im.csdn.net/chat/java1314777" target="_blank" rel="noopener">私信</a>
        </div>
        <div class="opt-letter-watch-box"> 
            <a class="attented personal-watch bt-button" id="btnAttent">已关注</a>
        </div>
    </div>
</div>
<a id="remuneration" data-report-click='{"spm":"1001.2101.3001.9809"}' rel="nofollow" href="" class="remuneration-box">
  <img src="" alt="">
</a>
  <div id="asideWriteGuide" class="aside-box side-write-guide-box type-1" data-report-view='{"spm":"3001.9727"}'>
    <div class="content-box">
      <a rel="nofollow" href="https://mp.csdn.net" target="_blank" class="btn-go-write" data-report-query="spm=3001.9727" data-report-click='{"spm":"3001.9727"}'>
        <img src="https://img-home.csdnimg.cn/images/20240218021837.png" alt="写文章">
      </a>
    </div>
  </div>
<div id="asideSearchArticle" class="aside-box">
	<div class="aside-content search-comter">
    <div class="aside-search aside-search-blog">         
        <input type="text" class="input-serch-blog" name="" autocomplete="off" value="" id="search-blog-words" placeholder="搜博主文章">
        <a class="btn-search-blog" data-report-click='{"spm":"1001.2101.3001.9182"}'>
            <img src="//csdnimg.cn/cdn/content-toolbar/csdn-white-search.png?v=1587006908">
        </a>
    </div>
    </div>
</div>



<div id="asideHotArticle" class="aside-box">
	<h3 class="aside-title">热门文章</h3>
	<div class="aside-content">
		<ul class="hotArticle-list">
			<li>
				<a href="https://snu77.blog.csdn.net/article/details/132974960" target="_blank"  data-report-click='{"mod":"popu_541","spm":"1001.2101.3001.4139","dest":"https://snu77.blog.csdn.net/article/details/132974960","ab":"new"}'>
				时间序列预测模型实战案例(三)(LSTM)(Python)(深度学习)时间序列预测(包括运行代码以及代码讲解)
					<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					<span class="read">18875</span>
                </a>
			</li>
			<li>
				<a href="https://snu77.blog.csdn.net/article/details/135309007" target="_blank"  data-report-click='{"mod":"popu_541","spm":"1001.2101.3001.4139","dest":"https://snu77.blog.csdn.net/article/details/135309007","ab":"new"}'>
				YOLOv8改进有效系列目录 | 包含卷积、主干、检测头、注意力机制、Neck上百种创新机制
					<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					<span class="read">17067</span>
                </a>
			</li>
			<li>
				<a href="https://snu77.blog.csdn.net/article/details/134154676" target="_blank"  data-report-click='{"mod":"popu_541","spm":"1001.2101.3001.4139","dest":"https://snu77.blog.csdn.net/article/details/134154676","ab":"new"}'>
				YOLOv8性能评估指标-＞mAP、Precision、Recall、FPS、IoU
					<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					<span class="read">16119</span>
                </a>
			</li>
			<li>
				<a href="https://snu77.blog.csdn.net/article/details/134097996" target="_blank"  data-report-click='{"mod":"popu_541","spm":"1001.2101.3001.4139","dest":"https://snu77.blog.csdn.net/article/details/134097996","ab":"new"}'>
				详解YOLOv8网络结构/环境搭建/数据集获取/训练/推理/验证/导出/部署
					<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					<span class="read">12428</span>
                </a>
			</li>
			<li>
				<a href="https://snu77.blog.csdn.net/article/details/128027977" target="_blank"  data-report-click='{"mod":"popu_541","spm":"1001.2101.3001.4139","dest":"https://snu77.blog.csdn.net/article/details/128027977","ab":"new"}'>
				Win11上Pytorch的安装并在Pycharm上调用PyTorch最新超详细过程并附详细的系统变量添加过程,可解决pycharm中pip不好使的问题
					<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountBlack.png" alt="">
					<span class="read">9005</span>
                </a>
			</li>
		</ul>
	</div>
</div>
<div id="asideCategory" class="aside-box flexible-box">
    <h3 class="aside-title">分类专栏</h3>
    <div class="aside-content">
        <ul>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12483754.html" data-report-click='{"mod":"popu_826","spm":"1001.2101.3001.4230","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12483754.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/direct/d0d498bd4f0c4e17b48ff54e86b67668.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        YOLOv8有效涨点专栏
                    </span>
                        <span class="pay-tag">付费</span>
                </a>
                <span class="special-column-num">125篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12500428.html" data-report-click='{"mod":"popu_826","spm":"1001.2101.3001.4230","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12500428.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/direct/bce35723af3f466e97009ebf18e827aa.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        RT-DETR有效改进专栏
                    </span>
                        <span class="pay-tag">付费</span>
                </a>
                <span class="special-column-num">61篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12500426.html" data-report-click='{"mod":"popu_826","spm":"1001.2101.3001.4230","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12500426.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/direct/6029d5920130491c8f52a4b3005e5f84.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        YOLOv5改进有效专栏
                    </span>
                        <span class="pay-tag">付费</span>
                </a>
                <span class="special-column-num">106篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12583198.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12583198.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/direct/ba2519e7272a4267a3ded30aaa79eb09.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        YOLOv9有效涨点专栏
                    </span>
                </a>
                <span class="special-column-num">2篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12464694.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12464694.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/20201014180756913.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        数据集专栏
                    </span>
                </a>
                <span class="special-column-num">3篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12551123.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12551123.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/direct/85c6dd75fec842e7a1a36ea95aa69562.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        YOLOv5/v7有效涨点
                    </span>
                </a>
                <span class="special-column-num">1篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12510496.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12510496.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/direct/e44ee41c806043f0a3245f74fd5de1db.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        深度学习100题大战
                    </span>
                </a>
                <span class="special-column-num">1篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12486438.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12486438.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/20201014180756738.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        活动专栏
                    </span>
                </a>
                <span class="special-column-num">2篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12285732.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12285732.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/20201014180756919.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        目标检测专栏
                    </span>
                </a>
                <span class="special-column-num">3篇</span>
            </li>
            <li>
                <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12441087.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12441087.html","ab":"new"}'>
                    <div class="special-column-bar "></div>
                    <img src="https://img-blog.csdnimg.cn/direct/5ae08a29357d42a9b849b054be235894.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                    <div class="img-mantle "></div>
                    <span class="title oneline">
                        时间序列预测专栏
                    </span>
                </a>
                <span class="special-column-num">35篇</span>
            </li>
        </ul>
    </div>
    <p class="text-center">
        <a class="flexible-btn" data-fbox="aside-archive"><img class="look-more" src="https://csdnimg.cn/release/blogv2/dist/pc/img/arrowDownBlack.png" alt=""></a>
    </p>
</div>
<div id="asideNewComments" class="aside-box">
    <h3 class="aside-title">最新评论</h3>
    <div class="aside-content">
        <ul class="newcomment-list">
            <li>
                <a class="title text-truncate" target="_blank" href="https://snu77.blog.csdn.net/article/details/136282783#comments_31436253" data-report-click='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/136282783#comments_31436253","ab":"new"}' data-report-view='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/136282783#comments_31436253","ab":"new"}'>YOLOv5改进 | Conv篇 | 全新的SOATA轻量化下采样操作ADown（轻量又涨点，附手撕结构图）</a>
                <p class="comment ellipsis">
                    <a href="https://xiaoming.blog.csdn.net" class="user-name" target="_blank">小   明: </a>
                    <span class="code-comments">您的深度理解和清晰的表达方式使复杂的技术概念变得容易理解。感谢您的无私分享，这对于像我这样的技术爱好者来说是一份宝贵的资源。期待更多精彩的内容！</span>
                </p>
            </li>
            <li>
                <a class="title text-truncate" target="_blank" href="https://snu77.blog.csdn.net/article/details/136346900#comments_31436249" data-report-click='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/136346900#comments_31436249","ab":"new"}' data-report-view='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/136346900#comments_31436249","ab":"new"}'>YOLOv8改进 | 独家创新篇 | 结合SOTA思想利用双主干网络改进YOLOv8（全网独家创新，最重磅的更新）</a>
                <p class="comment ellipsis">
                    <a href="https://xiaoming.blog.csdn.net" class="user-name" target="_blank">小   明: </a>
                    <span class="code-comments">总结的很详细，文章有深度，内容丰富，干货满满，期待博主持续更新，三连支持！！</span>
                </p>
            </li>
            <li>
                <a class="title text-truncate" target="_blank" href="https://snu77.blog.csdn.net/article/details/135305515#comments_31435440" data-report-click='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/135305515#comments_31435440","ab":"new"}' data-report-view='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/135305515#comments_31435440","ab":"new"}'>YOLOv8改进 | 检测头篇 | DynamicHead原论文一比一复现 （不同于网上版本，全网首发）</a>
                <p class="comment ellipsis">
                    <a href="https://snu77.blog.csdn.net" class="user-name" target="_blank">Snu77: </a>
                    <span class="code-comments">安装一下就行，mmcv这是个第三方库。</span>
                </p>
            </li>
            <li>
                <a class="title text-truncate" target="_blank" href="https://snu77.blog.csdn.net/article/details/135305515#comments_31435053" data-report-click='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/135305515#comments_31435053","ab":"new"}' data-report-view='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/135305515#comments_31435053","ab":"new"}'>YOLOv8改进 | 检测头篇 | DynamicHead原论文一比一复现 （不同于网上版本，全网首发）</a>
                <p class="comment ellipsis">
                    <a href="https://blog.csdn.net/m0_59403586" class="user-name" target="_blank">m0_59403586: </a>
                    <span class="code-comments">博主你好，   from mmcv.ops import ModulatedDeformConv2d
ModuleNotFoundError: No module named &#39;mmcv&#39; 这个问题怎么解决</span>
                </p>
            </li>
            <li>
                <a class="title text-truncate" target="_blank" href="https://snu77.blog.csdn.net/article/details/136346900#comments_31434710" data-report-click='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/136346900#comments_31434710","ab":"new"}' data-report-view='{"mod":"popu_542","spm":"1001.2101.3001.4231","dest":"https://snu77.blog.csdn.net/article/details/136346900#comments_31434710","ab":"new"}'>YOLOv8改进 | 独家创新篇 | 结合SOTA思想利用双主干网络改进YOLOv8（全网独家创新，最重磅的更新）</a>
                <p class="comment ellipsis">
                    <a href="https://blog.csdn.net/WTYuong" class="user-name" target="_blank">是Yu欸: </a>
                    <span class="code-comments">这是一篇高质量的好文，深度理解和清晰的表达方式使复杂的技术概念变得容易理解，值得收藏点赞。博主用心很有耐心，更有对知识的热忱和热爱，写了这么实用有效的分享，期盼博主能够光顾我的博客，给予宝贵的指导！</span>
                </p>
            </li>
        </ul>
    </div>
</div>
<div id="asideNewNps" class="aside-box common-nps-box">
    <h3 class="aside-title">您愿意向朋友推荐“博客详情页”吗？</h3>
    <div class="aside-content">
        <ul class="newnps-list">
            <li class="newnps-item" data-type="强烈不推荐">
                <div class="newnps-img-box">
                    <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel1.png" alt="">
                    <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey1.png" alt="">
                </div>
                <div class="newnps-text">强烈不推荐</div>
            </li>
            <li class="newnps-item" data-type="不推荐">
                <div class="newnps-img-box">
                    <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel2.png" alt="">
                    <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey2.png" alt="">
                </div>
                <div class="newnps-text">不推荐</div>
            </li>
            <li class="newnps-item" data-type="一般般">
                <div class="newnps-img-box">
                    <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel3.png" alt="">
                    <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey3.png" alt="">
                </div>
                <div class="newnps-text">一般般</div>
            </li>
            <li class="newnps-item" data-type="推荐">
                <div class="newnps-img-box">
                    <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel4.png" alt="">
                    <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey4.png" alt="">
                </div>
                <div class="newnps-text">推荐</div>
            </li>
            <li class="newnps-item" data-type="强烈推荐">
                <div class="newnps-img-box">
                    <img class="newnps-img active" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeel5.png" alt="">
                    <img class="newnps-img default" src="https://csdnimg.cn/release/blogv2/dist/pc/img/npsFeelGrey5.png" alt="">
                </div>
                <div class="newnps-text">强烈推荐</div>
            </li>
        </ul>
        <div class="newnps-form-box">
        <div class="newnps-form">
            <input type="text" placeholder="请输入建议或反馈后点击提交" class="newnps-input">
            <span class="newnps-btn">提交</span>
        </div>
        </div>
    </div>
</div>
<div id="asideArchive" class="aside-box" style="display:block!important; width:300px;">
    <h3 class="aside-title">最新文章</h3>
    <div class="aside-content">
        <ul class="inf_list clearfix">
            <li class="clearfix">
            <a href="https://snu77.blog.csdn.net/article/details/136346900" target="_blank" data-report-click='{"mod":"popu_382","spm":"1001.2101.3001.4136","dest":"https://snu77.blog.csdn.net/article/details/136346900","ab":"new"}' data-report-view='{"mod":"popu_382","dest":"https://snu77.blog.csdn.net/article/details/136346900","ab":"new"}'>YOLOv8改进 | 独家创新篇 | 结合SOTA思想利用双主干网络改进YOLOv8（全网独家创新，最重磅的更新）</a>
            </li>
            <li class="clearfix">
            <a href="https://snu77.blog.csdn.net/article/details/136282783" target="_blank" data-report-click='{"mod":"popu_382","spm":"1001.2101.3001.4136","dest":"https://snu77.blog.csdn.net/article/details/136282783","ab":"new"}' data-report-view='{"mod":"popu_382","dest":"https://snu77.blog.csdn.net/article/details/136282783","ab":"new"}'>YOLOv5改进 | Conv篇 | 全新的SOATA轻量化下采样操作ADown（轻量又涨点，附手撕结构图）</a>
            </li>
            <li class="clearfix">
            <a href="https://snu77.blog.csdn.net/article/details/136278264" target="_blank" data-report-click='{"mod":"popu_382","spm":"1001.2101.3001.4136","dest":"https://snu77.blog.csdn.net/article/details/136278264","ab":"new"}' data-report-view='{"mod":"popu_382","dest":"https://snu77.blog.csdn.net/article/details/136278264","ab":"new"}'>YOLOv8改进 | Conv篇 | 全新的SOATA轻量化下采样操作ADown（参数量下降百分之二十，附手撕结构图）</a>
            </li>
        </ul>
        <div class="archive-bar"></div>
        <div class="archive-box">
                <div class="archive-title">2024</div> 
                <div class="archive-content">
                    <div class="archive-item">
                        <a href="https://snu77.blog.csdn.net?type=blog&amp;year=2024&amp;month=02" target="_blank" data-report-click='{"mod":"popu_538","spm":"1001.2101.3001.4138","ab":"new","dest":"https://snu77.blog.csdn.net?type=blog&amp;year=2024&amp;month=02"}'>
                        <span class="time">02月</span>
                        <span class="count">55篇</span>
                        </a>
                    </div>
                    <div class="archive-item">
                        <a href="https://snu77.blog.csdn.net?type=blog&amp;year=2024&amp;month=01" target="_blank" data-report-click='{"mod":"popu_538","spm":"1001.2101.3001.4138","ab":"new","dest":"https://snu77.blog.csdn.net?type=blog&amp;year=2024&amp;month=01"}'>
                        <span class="time">01月</span>
                        <span class="count">143篇</span>
                        </a>
                    </div>
                </div>
                <div class="archive-list-item"><a href="https://snu77.blog.csdn.net?type=blog&amp;year=2023&amp;month=12" target="_blank" data-report-click='{"mod":"popu_538","spm":"1001.2101.3001.4138","ab":"new","dest":"https://snu77.blog.csdn.net?type=blog&amp;year=2023&amp;month=12"}'><span class="year">2023年</span><span class="num">138篇</span></a></div>
                <div class="archive-list-item"><a href="https://snu77.blog.csdn.net?type=blog&amp;year=2022&amp;month=11" target="_blank" data-report-click='{"mod":"popu_538","spm":"1001.2101.3001.4138","ab":"new","dest":"https://snu77.blog.csdn.net?type=blog&amp;year=2022&amp;month=11"}'><span class="year">2022年</span><span class="num">1篇</span></a></div>
        </div>
    </div>
</div>
    <!-- 详情页显示目录 -->
<!--文章目录-->
<div id="asidedirectory" class="aside-box">
    <div class='groupfile' id="directory">
        <h3 class="aside-title">目录</h3>
        <div class="align-items-stretch group_item">
            <div class="pos-box">
            <div class="scroll-box">
                <div class="toc-box"></div>
            </div>
            </div>
        </div>
    </div>
</div>
</aside>
<script>
	$("a.flexible-btn").click(function(){
		$(this).parents('div.aside-box').removeClass('flexible-box');
		$(this).parents("p.text-center").remove();
	})
</script>
<script type="text/javascript"  src="https://g.csdnimg.cn/user-tooltip/2.7/user-tooltip.js"></script>
<script type="text/javascript"  src="https://g.csdnimg.cn/user-medal/2.0.0/user-medal.js"></script>        </div>
<div class="recommend-right align-items-stretch clearfix" id="rightAside" data-type="recommend">
    <aside class="recommend-right_aside">
        <div id="recommend-right" >
                        <div class='flex-column aside-box groupfile' id="groupfile">
                <div class="groupfile-div">
                <h3 class="aside-title">目录</h3>
                <div class="align-items-stretch group_item">
                    <div class="pos-box">
                        <div class="scroll-box">
                            <div class="toc-box"></div>
                        </div>
                    </div>
                </div>
                </div>
            </div>
            <div class='aside-box kind_person d-flex flex-column'>
                    <h3 class="aside-title">分类专栏</h3>
                    <div class="align-items-stretch kindof_item" id="kind_person_column">
                        <div class="aside-content">
                            <ul>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12483754.html" data-report-click='{"mod":"popu_826","spm":"1001.2101.3001.4230","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12483754.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/direct/d0d498bd4f0c4e17b48ff54e86b67668.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            YOLOv8有效涨点专栏
                                        </span>
                                            <span class="pay-tag">付费</span>
                                    </a>
                                    <span class="special-column-num">125篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12500428.html" data-report-click='{"mod":"popu_826","spm":"1001.2101.3001.4230","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12500428.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/direct/bce35723af3f466e97009ebf18e827aa.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            RT-DETR有效改进专栏
                                        </span>
                                            <span class="pay-tag">付费</span>
                                    </a>
                                    <span class="special-column-num">61篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12500426.html" data-report-click='{"mod":"popu_826","spm":"1001.2101.3001.4230","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12500426.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/direct/6029d5920130491c8f52a4b3005e5f84.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            YOLOv5改进有效专栏
                                        </span>
                                            <span class="pay-tag">付费</span>
                                    </a>
                                    <span class="special-column-num">106篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12583198.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12583198.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/direct/ba2519e7272a4267a3ded30aaa79eb09.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            YOLOv9有效涨点专栏
                                        </span>
                                    </a>
                                    <span class="special-column-num">2篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12464694.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12464694.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/20201014180756913.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            数据集专栏
                                        </span>
                                    </a>
                                    <span class="special-column-num">3篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12551123.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12551123.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/direct/85c6dd75fec842e7a1a36ea95aa69562.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            YOLOv5/v7有效涨点
                                        </span>
                                    </a>
                                    <span class="special-column-num">1篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12510496.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12510496.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/direct/e44ee41c806043f0a3245f74fd5de1db.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            深度学习100题大战
                                        </span>
                                    </a>
                                    <span class="special-column-num">1篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12486438.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12486438.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/20201014180756738.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            活动专栏
                                        </span>
                                    </a>
                                    <span class="special-column-num">2篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12285732.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12285732.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/20201014180756919.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            目标检测专栏
                                        </span>
                                    </a>
                                    <span class="special-column-num">3篇</span>
                                </li>
                                <li>
                                    <a class="clearfix special-column-name"  href="https://blog.csdn.net/java1314777/category_12441087.html" data-report-click='{"mod":"popu_537","spm":"1001.2101.3001.4137","strategy":"pc付费专栏左侧入口","dest":"https://blog.csdn.net/java1314777/category_12441087.html","ab":"new"}'>
                                        <div class="special-column-bar "></div>
                                        <img src="https://img-blog.csdnimg.cn/direct/5ae08a29357d42a9b849b054be235894.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'">
                                        <div class="img-mantle "></div>
                                        <span class="">
                                            时间序列预测专栏
                                        </span>
                                    </a>
                                    <span class="special-column-num">35篇</span>
                                </li>
                            </ul>
                        </div>
                    </div>
            </div>
        </div>
    </aside>
</div>

<div class="recommend-right1  align-items-stretch clearfix" id="rightAsideConcision" data-type="recommend">
    <aside class="recommend-right_aside">
        <div id="recommend-right-concision" >
            <div class='flex-column aside-box groupfile' id="groupfileConcision">
                <div class="groupfile-div1">
                <h3 class="aside-title">目录</h3>
                <div class="align-items-stretch group_item">
                    <div class="pos-box">
                        <div class="scroll-box">
                            <div class="toc-box"></div>
                        </div>
                    </div>
                </div>
                </div>
            </div>
        </div>
    </aside>
</div>

      </div>
      <div class="mask-dark"></div>
      <div class="skin-boxshadow"></div>
      <div class="directory-boxshadow"></div>
<div class="comment-side-box-shadow comment-side-tit-close" id="commentSideBoxshadow">
<div class="comment-side-content">
	<div class="comment-side-tit">
		<div class="comment-side-tit-count">评论&nbsp;<span class="count">3</span></div>
	<img class="comment-side-tit-close" src="https://csdnimg.cn/release/blogv2/dist/pc/img/closeBt.png"></div>
	<div id="pcCommentSideBox" class="comment-box comment-box-new2 " style="display:block">
    <div class="comment-edit-box d-flex">
      <div class="user-img">
        <a href="https://blog.csdn.net/DreamSun527" target="_blank">
          <img src="https://profile-avatar.csdnimg.cn/default.jpg!1">
        </a>
      </div>
      <form id="commentform">
        <textarea class="comment-content" name="comment_content" id="comment_content" placeholder="欢迎高质量的评论，低质的评论会被折叠" maxlength="1000"></textarea>
        <div class="comment-reward-box" style="background-image: url('https://img-home.csdnimg.cn/images/20230131025301.png');">
          <a class="btn-remove-reward"></a>
          <div class="form-reward-box">
            <div class="info">
              成就一亿技术人!
            </div>
            <div class="price-info">
              拼手气红包<span class="price">6.0元</span>
            </div>
          </div>
        </div>
        <div class="comment-operate-box">
          <div class="comment-operate-l">
            <span id="tip_comment" class="tip">还能输入<em>1000</em>个字符</span>
          </div>
          <div class="comment-operate-c">
            &nbsp;
          </div>
          <div class="comment-operate-r">
            <div class="comment-operate-item comment-reward">
              <img class="comment-operate-img" data-url="https://csdnimg.cn/release/blogv2/dist/pc/img/" src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentReward.png" alt="红包">
              <span class="comment-operate-tip">添加红包</span>
            </div>
            <div class="comment-operate-item comment-emoticon">
              <img class="comment-operate-img" data-url="https://csdnimg.cn/release/blogv2/dist/pc/img/" src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentEmotionIcon.png" alt="表情包">
              <span class="comment-operate-tip">插入表情</span>
              <div class="comment-emoticon-box comment-operate-isshow">
                <div class="comment-emoticon-img-box"></div>
              </div>
            </div>
            <div class="comment-operate-item comment-code">
              <img class="comment-operate-img" data-url="https://csdnimg.cn/release/blogv2/dist/pc/img/" src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentCodeIcon.png" alt="表情包">
              <span class="comment-operate-tip">代码片</span>
              <div class="comment-code-box comment-operate-isshow">
                <ul id="commentCode">
                  <li><a data-code="html">HTML/XML</a></li>
                  <li><a data-code="objc">objective-c</a></li>
                  <li><a data-code="ruby">Ruby</a></li>
                  <li><a data-code="php">PHP</a></li>
                  <li><a data-code="csharp">C</a></li>
                  <li><a data-code="cpp">C++</a></li>
                  <li><a data-code="javascript">JavaScript</a></li>
                  <li><a data-code="python">Python</a></li>
                  <li><a data-code="java">Java</a></li>
                  <li><a data-code="css">CSS</a></li>
                  <li><a data-code="sql">SQL</a></li>
                  <li><a data-code="plain">其它</a></li>
                </ul>
              </div>
            </div>
            <div class="comment-operate-item">
              <input type="hidden" id="comment_replyId" name="comment_replyId">
              <input type="hidden" id="article_id" name="article_id" value="135024120">
              <input type="hidden" id="comment_userId" name="comment_userId" value="">
              <input type="hidden" id="commentId" name="commentId" value="">
              <a data-report-click='{"mod":"1582594662_003","spm":"1001.2101.3001.4227","ab":"new"}'>
              <input type="submit" class="btn-comment btn-comment-input" value="评论">
              </a>
            </div>
          </div>
        </div>
      </form>
    </div>
		<div class="comment-list-container">
			<div class="comment-list-box comment-operate-item">
			</div>
			<div id="lookGoodComment" class="look-good-comment side-look-comment">
				<a class="look-more-comment">查看更多评论<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentArrowDownBlack.png" alt=""></a>
			</div>
			<div id="lookFlodComment" class="look-flod-comment">
					<span class="count"></span>&nbsp;条评论被折叠&nbsp;<a class="look-more-flodcomment">查看</a>
			</div>
			<div class="opt-box text-center">
				<div class="btn btn-sm btn-link-blue" id="btnMoreComment"></div>
			</div>
		</div>
	</div>
	<div id="pcFlodCommentSideBox" class="pc-flodcomment-sidebox">
		<div class="comment-fold-tit"><span id="lookUnFlodComment" class="back"><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentArrowLeftBlack.png" alt=""></span>被折叠的&nbsp;<span class="count"></span>&nbsp;条评论
		 <a href="https://blogdev.blog.csdn.net/article/details/122245662" class="tip" target="_blank">为什么被折叠?</a>
		 <a href="https://bbs.csdn.net/forums/FreeZone" class="park" target="_blank">
		 <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/iconPark.png">到【灌水乐园】发言</a>                                
		</div>
		<div class="comment-fold-content"></div>
		<div id="lookBadComment" class="look-bad-comment side-look-comment">
			<a class="look-more-comment">查看更多评论<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentArrowDownBlack.png" alt=""></a>
		</div>
	</div>
</div>
<div class="comment-rewarddialog-box">
  <div class="form-box">
    <div class="title-box">
      添加红包
      <a class="btn-form-close"></a>
    </div>
    <form id="commentRewardForm">
      <div class="ipt-box">
        <label for="txtName">祝福语</label>
        <div class="ipt-btn-box">
          <input type="text" name="name" id="txtName" autocomplete="off" maxlength="50">
          <a class="btn-ipt btn-random"></a>
        </div>
        <p class="notice">请填写红包祝福语或标题</p>
      </div>
      <div class="ipt-box">
        <label for="txtSendAmount">红包数量</label>
        <div class="ipt-txt-box">
          <input type="text" name="sendAmount" maxlength="4" id="txtSendAmount" placeholder="请填写红包数量(最小10个)" autocomplete="off">
          <span class="after-txt">个</span>
        </div>
        <p class="notice">红包个数最小为10个</p>
      </div>
      <div class="ipt-box">
        <label for="txtMoney">红包总金额</label>
        <div class="ipt-txt-box error">
          <input type="text" name="money" maxlength="5" id="txtMoney" placeholder="请填写总金额(最低5元)" autocomplete="off">
          <span class="after-txt">元</span>
        </div>
        <p class="notice">红包金额最低5元</p>
      </div>
      <div class="balance-info-box">
        <label>余额支付</label>
        <div class="balance-info">
          当前余额<span class="balance">3.43</span>元
          <a href="https://i.csdn.net/#/wallet/balance/recharge" class="link-charge" target="_blank">前往充值 ></a>
        </div>
      </div>
      <div class="opt-box">
        <div class="pay-info">
          需支付：<span class="price">10.00</span>元
        </div>
        <button type="button" class="ml-auto btn-cancel">取消</button>
        <button type="button" class="ml8 btn-submit" disabled="true">确定</button>
      </div>
    </form>
  </div>
</div>
<div class="rr-guide-box">
  <div class="rr-first-box">
    <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/guideRedReward02.png" alt="">
    <button class="btn-guide-known next">下一步</button>
  </div>
  <div class="rr-second-box">
    <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/guideRedReward03.png" alt="">
    <button class="btn-guide-known known">知道了</button>
  </div>
</div>
</div>

<div class="redEnvolope" id="redEnvolope">
  <div class="env-box">
    <div class="env-container">
      <div class="pre-open" id="preOpen">
        <div class="top">
          <header>
            <img class="clearTpaErr" :src="redpacketAuthor.avatar" alt="" />
            <div class="author">成就一亿技术人!</div>
          </header>
          <div class="bot-icon"></div>
        </div>
        <footer>
          <div class="red-openbtn open-start"></div>
          <div class="tip">
            领取后你会自动成为博主和红包主的粉丝
            <a class="rule" target="_blank">规则</a>
          </div>
        </footer>
      </div>
      <div class="opened" id="opened">
        <div class="bot-icon">
          <header>
            <a class="creatorUrl" href="" target="_blank">
              <img class="clearTpaErr" src="https://profile-avatar.csdnimg.cn/default.jpg!2" alt="" />
            </a>
            <div class="author">
              <div class="tt">hope_wisdom</div> 发出的红包
            </div>
          </header>
        </div>
        <div class="receive-box">
          <header></header>
          <div class="receive-list">
          </div>
        </div>
      </div>
    </div>
    <div class="close-btn"></div>
  </div>
</div>
<div id="rewardNew" class="reward-popupbox-new">
	<p class="rewad-title">打赏作者<span class="reward-close"><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/closeBt.png"></span></p>
	<dl class="profile-box">
		<dd>
		<a href="https://snu77.blog.csdn.net" data-report-click='{"mod":"popu_379","dest":"https://snu77.blog.csdn.net","ab":"new"}'>
			<img src="https://profile-avatar.csdnimg.cn/27160f4941a54d07b535ceabcfa4a800_java1314777.jpg!1" class="avatar_pic">
		</a>
		</dd>
		<dt>
			<p class="blog-name">Snu77</p>
			<p class="blog-discript">你的鼓励将是我创作的最大动力</p>
		</dt>
	</dl>
	<div class="reward-box-new">
			<div class="reward-content"><div class="reward-right"></div></div>
	</div>
	<div class="money-box">
    <span class="choose-money choosed" data-id="1">¥1</span>
    <span class="choose-money " data-id="2">¥2</span>
    <span class="choose-money " data-id="4">¥4</span>
    <span class="choose-money " data-id="6">¥6</span>
    <span class="choose-money " data-id="10">¥10</span>
    <span class="choose-money " data-id="20">¥20</span>
	</div>
	<div class="sure-box">
		<div class="sure-box-money">
			<div class="code-box">
				<div class="code-num-box">
					<span class="code-name">扫码支付：</span><span class="code-num">¥1</span>
				</div>
				<div class="code-img-box">
					<div class="renovate">
					<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/pay-time-out.png">
					<span>获取中</span>
					</div>
				</div>
				<div class="code-pay-box">
					<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newWeiXin.png" alt="">
					<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newZhiFuBao.png" alt="">
					<span>扫码支付</span>
				</div>
			</div>
		</div>
		<div class="sure-box-blance">
			<p class="tip">您的余额不足，请更换扫码支付或<a target="_blank" data-report-click='{"mod":"1597646289_003","spm":"1001.2101.3001.4302"}' href="https://i.csdn.net/#/wallet/balance/recharge?utm_source=RewardVip" class="go-invest">充值</a></p>
			<p class="is-have-money"><a class="reward-sure">打赏作者</a></p>
		</div>
	</div>
</div>
      
      <div class="pay-code">
      <div class="pay-money">实付<span class="pay-money-span" data-nowprice='' data-oldprice=''>元</span></div>
      <div class="content-blance"><a class="blance-bt" href="javascript:;">使用余额支付</a></div>
      <div class="content-code">
        <div id="payCode" data-id="">
          <div class="renovate">
            <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/pay-time-out.png">
            <span>点击重新获取</span>
          </div>
        </div>
        <div class="pay-style"><span><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/weixin.png"></span><span><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/zhifubao.png"></span><span><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/jingdong.png"></span><span class="text">扫码支付</span></div>
      </div>
      <div class="bt-close">
        <svg t="1567152543821" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="10924" xmlns:xlink="http://www.w3.org/1999/xlink" width="12" height="12">
          <defs>
            <style type="text/css"></style>
          </defs>
          <path d="M512 438.378667L806.506667 143.893333a52.032 52.032 0 1 1 73.6 73.621334L585.621333 512l294.485334 294.485333a52.074667 52.074667 0 0 1-73.6 73.642667L512 585.621333 217.514667 880.128a52.053333 52.053333 0 1 1-73.621334-73.642667L438.378667 512 143.893333 217.514667a52.053333 52.053333 0 1 1 73.621334-73.621334L512 438.378667z" fill="" p-id="10925"></path>
        </svg>
      </div>
      <div class="pay-balance">
        <input type="radio" class="pay-code-radio" data-type="details">
        <span class="span">钱包余额</span>
          <span class="balance" style="color:#FC5531;font-size:14px;">0</span>
          <div class="pay-code-tile">
            <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/pay-help.png" alt="">
            <div class="pay-code-content">
              <div class="span">
                <p class="title">抵扣说明：</p>
                <p> 1.余额是钱包充值的虚拟货币，按照1:1的比例进行支付金额的抵扣。<br> 2.余额无法直接购买下载，可以购买VIP、付费专栏及课程。</p>
              </div>
            </div>
          </div>
      </div>
      <a class="pay-balance-con" href="https://i.csdn.net/#/wallet/balance/recharge" target="_blank"><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/recharge.png" alt=""><span>余额充值</span></a>
    </div>
    <div style="display:none;">
      <img src="" onerror='setTimeout(function(){if(!/(csdn.net|iteye.com|baiducontent.com|googleusercontent.com|360webcache.com|sogoucdn.com|bingj.com|baidu.com)$/.test(window.location.hostname)){window.location.href="\x68\x74\x74\x70\x73\x3a\x2f\x2f\x77\x77\x77\x2e\x63\x73\x64\x6e\x2e\x6e\x65\x74"}},3000);'>
    </div>
    <div class="keyword-dec-box" id="keywordDecBox"></div>
  </body>
    <!-- 富文本柱状图  -->
    <link rel="stylesheet" href="https://csdnimg.cn/release/blog_editor_html/release1.6.12/ckeditor/plugins/chart/chart.css" />
    <script type="text/javascript" src="https://csdnimg.cn/release/blog_editor_html/release1.6.12/ckeditor/plugins/chart/lib/chart.min.js"></script>
    <script type="text/javascript" src="https://csdnimg.cn/release/blog_editor_html/release1.6.12/ckeditor/plugins/chart/widget2chart.js"></script>
  <script src="https://csdnimg.cn/release/blogv2/dist/components/js/axios-83fa28cedf.min.js" type="text/javascript"></script>
  <script src="https://csdnimg.cn/release/blogv2/dist/components/js/pc_wap_highlight-8defd55d6e.min.js" type="text/javascript"></script>
  <script src="https://csdnimg.cn/release/blogv2/dist/components/js/pc_wap_common-be82269d23.min.js" type="text/javascript"></script>
  <script src="https://csdnimg.cn/release/blogv2/dist/components/js/edit_copy_code-27143fd02b.min.js" type="text/javascript"></script>
  <link rel="stylesheet" href="https://csdnimg.cn/release/blog_editor_html/release1.6.12/ckeditor/plugins/codesnippet/lib/highlight/styles/tomorrow-night.css">
  <script src="https://g.csdnimg.cn/user-accusation/1.0.6/user-accusation.js" type="text/javascript"></script>
  <script>
    // 全局声明
    if (window.csdn === undefined) {
      window.csdn = {};
    }
    window.csdn.sideToolbar = {
      options: {
        report: {
          isShow: true,
        },
        qr: {
          isShow: false,
        },
        guide: {
          isShow: true
        }
      }
    }
    $(function() {
      $(document).on('click', "a.option-box[data-type='report']", function() {
        window.csdn.loginBox.key({
          biz: 'blog',
          subBiz: 'other_service',
          cb: function() {
            window.csdn.feedback({
              "type": 'blog',
              "rtype": 'article',
              "rid": articleId,
              "reportedName": username,
              "submitOptions": {
                "title": articleTitle,
                "contentUrl": articleDetailUrl
              },
              "callback": function() {
                showToast({
                  text: "感谢您的举报，我们会尽快审核！",
                  bottom: '10%',
                  zindex: 9000,
                  speed: 500,
                  time: 1500
                })
              }
            })
          }
        })
      });
    })
  </script>
    <script src="https://g.csdnimg.cn/baidu-search/1.0.12/baidu-search.js" type="text/javascript"></script>
  <script src="https://csdnimg.cn/release/download/old_static/js/qrcode.js"></script>
  <script src="https://g.csdnimg.cn/lib/qrcode/1.0.0/qrcode.min.js"></script>
  <script src="https://g.csdnimg.cn/user-ordercart/3.0.1/user-ordercart.js" type="text/javascript"></script>
  <script src="https://g.csdnimg.cn/user-ordertip/5.0.3/user-ordertip.js" type="text/javascript"></script>
  <script src="https://g.csdnimg.cn/order-payment/4.0.5/order-payment.js" type="text/javascript"></script>
  <script src="https://csdnimg.cn/release/blogv2/dist/pc/js/common-a425354f6a.min.js" type="text/javascript"></script>
  <script src="https://csdnimg.cn/release/blogv2/dist/pc/js/detail-0655e5d8db.min.js" type="text/javascript"></script>
  <script src="https://csdnimg.cn/release/blogv2/dist/pc/js/column-35b87614d0.min.js" type="text/javascript"></script>
  <script src="https://g.csdnimg.cn/side-toolbar/3.4/side-toolbar.js" type="text/javascript"></script>
    <script>
    window.csdn.extensionBox = window.csdn.extensionBox ? window.csdn.extensionBox : {};
    window.csdn.extensionBox.extensionBoxParams = {
      inited: function() {
        var extensionBox = document.getElementById('blogExtensionBox'); // 位置dom元素
        window.csdn.extensionBox.show({
          isdark: true, // 是否黑皮肤
          voteusername: "java1314777",
          posDom: extensionBox, // 插入位置 selectorString || 位置dom元素
          codyFn: () => {
            //复制成功回调函数
            showToast({
              text: '复制成功（作者已获得对应原力分）!',
              bottom: '10%', //toast距离页面底部的距离
              zindex: 9000, //为了防止被其他控件遮盖，z-index默认为2
              speed: 500, //toast的显示速度
              time: 1500 //toast显示多久以后消失
            });
          }
        });
      }
    }
    </script>
    <script src="https://g.csdnimg.cn/extension-box/1.1.7/extension-box.js" type="text/javascript"></script>
  <script src="https://g.csdnimg.cn/copyright/1.0.4/copyright.js" type="text/javascript"></script>
  <script>
    $(".MathJax").remove();
    if ($('div.markdown_views pre.prettyprint code.hljs').length > 0) {
      $('div.markdown_views')[0].className = 'markdown_views';
    }
  </script>
  <script type="text/javascript" src="https://csdnimg.cn/release/blog_mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      "HTML-CSS": {
        linebreaks: { automatic: true, width: "94%container" },
        imageFont: null
      },
      tex2jax: {
      preview: "none",
      ignoreClass:"title-article"
      },
      mml2jax: {
      preview: 'none'
      }
    });
  </script>
<script type="text/javascript" crossorigin src="https://g.csdnimg.cn/common/csdn-login-box/csdn-login-box.js"></script></html>